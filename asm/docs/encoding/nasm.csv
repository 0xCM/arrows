; Derived from insns.dat, the table of instructions for the Netwide Assembler. See license

Basic Instructions
---------------------------------------------------------------------------------------------------------------
| Class      | Operands                | Code                        | Flags                      |
| AAA        | void                    | [37]                        | 8086,NOLONG                |
| AAD        | void                    | [d5 0a]                     | 8086,NOLONG                |
| AAD        | imm                     | [i: d5 ib,u]                | 8086,SB,NOLONG             |
| AAM        | void                    | [d4 0a]                     | 8086,NOLONG                |
| AAM        | imm                     | [i: d4 ib,u]                | 8086,SB,NOLONG             |
| AAS        | void                    | [3f]                        | 8086,NOLONG                |
| ADC        | mem,reg8                | [mr: hle 10 /r]             | 8086,SM,LOCK               |
| ADC        | reg8,reg8               | [mr: 10 /r]                 | 8086                       |
| ADC        | mem,reg16               | [mr: hle o16 11 /r]         | 8086,SM,LOCK               |
| ADC        | reg16,reg16             | [mr: o16 11 /r]             | 8086                       |
| ADC        | mem,reg32               | [mr: hle o32 11 /r]         | 386,SM,LOCK                |
| ADC        | reg32,reg32             | [mr: o32 11 /r]             | 386                        |
| ADC        | mem,reg64               | [mr: hle o64 11 /r]         | X64,SM,LOCK                |
| ADC        | reg64,reg64             | [mr: o64 11 /r]             | X64                        |
| ADC        | reg8,mem                | [rm: 12 /r]                 | 8086,SM                    |
| ADC        | reg8,reg8               | [rm: 12 /r]                 | 8086                       |
| ADC        | reg16,mem               | [rm: o16 13 /r]             | 8086,SM                    |
| ADC        | reg16,reg16             | [rm: o16 13 /r]             | 8086                       |
| ADC        | reg32,mem               | [rm: o32 13 /r]             | 386,SM                     |
| ADC        | reg32,reg32             | [rm: o32 13 /r]             | 386                        |
| ADC        | reg64,mem               | [rm: o64 13 /r]             | X64,SM                     |
| ADC        | reg64,reg64             | [rm: o64 13 /r]             | X64                        |
| ADC        | rm16,imm8               | [mi: hle o16 83 /2 ib,s]    | 8086,LOCK                  |
| ADC        | rm32,imm8               | [mi: hle o32 83 /2 ib,s]    | 386,LOCK                   |
| ADC        | rm64,imm8               | [mi: hle o64 83 /2 ib,s]    | X64,LOCK                   |
| ADC        | reg_al,imm              | [-i: 14 ib]                 | 8086,SM                    |
| ADC        | reg_ax,sbyteword        | [mi: o16 83 /2 ib,s]        | 8086,SM,ND                 |
| ADC        | reg_ax,imm              | [-i: o16 15 iw]             | 8086,SM                    |
| ADC        | reg_eax,sbytedword      | [mi: o32 83 /2 ib,s]        | 386,SM,ND                  |
| ADC        | reg_eax,imm             | [-i: o32 15 id]             | 386,SM                     |
| ADC        | reg_rax,sbytedword      | [mi: o64 83 /2 ib,s]        | X64,SM,ND                  |
| ADC        | reg_rax,imm             | [-i: o64 15 id,s]           | X64,SM                     |
| ADC        | rm8,imm                 | [mi: hle 80 /2 ib]          | 8086,SM,LOCK               |
| ADC        | rm16,sbyteword          | [mi: hle o16 83 /2 ib,s]    | 8086,SM,LOCK,ND            |
| ADC        | rm16,imm                | [mi: hle o16 81 /2 iw]      | 8086,SM,LOCK               |
| ADC        | rm32,sbytedword         | [mi: hle o32 83 /2 ib,s]    | 386,SM,LOCK,ND             |
| ADC        | rm32,imm                | [mi: hle o32 81 /2 id]      | 386,SM,LOCK                |
| ADC        | rm64,sbytedword         | [mi: hle o64 83 /2 ib,s]    | X64,SM,LOCK,ND             |
| ADC        | rm64,imm                | [mi: hle o64 81 /2 id,s]    | X64,SM,LOCK                |
| ADC        | mem,imm8                | [mi: hle 80 /2 ib]          | 8086,SM,LOCK,ND            |
| ADC        | mem,sbyteword16         | [mi: hle o16 83 /2 ib,s]    | 8086,SM,LOCK,ND            |
| ADC        | mem,imm16               | [mi: hle o16 81 /2 iw]      | 8086,SM,LOCK               |
| ADC        | mem,sbytedword32        | [mi: hle o32 83 /2 ib,s]    | 386,SM,LOCK,ND             |
| ADC        | mem,imm32               | [mi: hle o32 81 /2 id]      | 386,SM,LOCK                |
| ADC        | rm8,imm                 | [mi: hle 82 /2 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| ADD        | mem,reg8                | [mr: hle 00 /r]             | 8086,SM,LOCK               |
| ADD        | reg8,reg8               | [mr: 00 /r]                 | 8086                       |
| ADD        | mem,reg16               | [mr: hle o16 01 /r]         | 8086,SM,LOCK               |
| ADD        | reg16,reg16             | [mr: o16 01 /r]             | 8086                       |
| ADD        | mem,reg32               | [mr: hle o32 01 /r]         | 386,SM,LOCK                |
| ADD        | reg32,reg32             | [mr: o32 01 /r]             | 386                        |
| ADD        | mem,reg64               | [mr: hle o64 01 /r]         | X64,SM,LOCK                |
| ADD        | reg64,reg64             | [mr: o64 01 /r]             | X64                        |
| ADD        | reg8,mem                | [rm: 02 /r]                 | 8086,SM                    |
| ADD        | reg8,reg8               | [rm: 02 /r]                 | 8086                       |
| ADD        | reg16,mem               | [rm: o16 03 /r]             | 8086,SM                    |
| ADD        | reg16,reg16             | [rm: o16 03 /r]             | 8086                       |
| ADD        | reg32,mem               | [rm: o32 03 /r]             | 386,SM                     |
| ADD        | reg32,reg32             | [rm: o32 03 /r]             | 386                        |
| ADD        | reg64,mem               | [rm: o64 03 /r]             | X64,SM                     |
| ADD        | reg64,reg64             | [rm: o64 03 /r]             | X64                        |
| ADD        | rm16,imm8               | [mi: hle o16 83 /0 ib,s]    | 8086,LOCK                  |
| ADD        | rm32,imm8               | [mi: hle o32 83 /0 ib,s]    | 386,LOCK                   |
| ADD        | rm64,imm8               | [mi: hle o64 83 /0 ib,s]    | X64,LOCK                   |
| ADD        | reg_al,imm              | [-i: 04 ib]                 | 8086,SM                    |
| ADD        | reg_ax,sbyteword        | [mi: o16 83 /0 ib,s]        | 8086,SM,ND                 |
| ADD        | reg_ax,imm              | [-i: o16 05 iw]             | 8086,SM                    |
| ADD        | reg_eax,sbytedword      | [mi: o32 83 /0 ib,s]        | 386,SM,ND                  |
| ADD        | reg_eax,imm             | [-i: o32 05 id]             | 386,SM                     |
| ADD        | reg_rax,sbytedword      | [mi: o64 83 /0 ib,s]        | X64,SM,ND                  |
| ADD        | reg_rax,imm             | [-i: o64 05 id,s]           | X64,SM                     |
| ADD        | rm8,imm                 | [mi: hle 80 /0 ib]          | 8086,SM,LOCK               |
| ADD        | rm16,sbyteword          | [mi: hle o16 83 /0 ib,s]    | 8086,SM,LOCK,ND            |
| ADD        | rm16,imm                | [mi: hle o16 81 /0 iw]      | 8086,SM,LOCK               |
| ADD        | rm32,sbytedword         | [mi: hle o32 83 /0 ib,s]    | 386,SM,LOCK,ND             |
| ADD        | rm32,imm                | [mi: hle o32 81 /0 id]      | 386,SM,LOCK                |
| ADD        | rm64,sbytedword         | [mi: hle o64 83 /0 ib,s]    | X64,SM,LOCK,ND             |
| ADD        | rm64,imm                | [mi: hle o64 81 /0 id,s]    | X64,SM,LOCK                |
| ADD        | mem,imm8                | [mi: hle 80 /0 ib]          | 8086,SM,LOCK               |
| ADD        | mem,sbyteword16         | [mi: hle o16 83 /0 ib,s]    | 8086,SM,LOCK,ND            |
| ADD        | mem,imm16               | [mi: hle o16 81 /0 iw]      | 8086,SM,LOCK               |
| ADD        | mem,sbytedword32        | [mi: hle o32 83 /0 ib,s]    | 386,SM,LOCK,ND             |
| ADD        | mem,imm32               | [mi: hle o32 81 /0 id]      | 386,SM,LOCK                |
| ADD        | rm8,imm                 | [mi: hle 82 /0 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| AND        | mem,reg8                | [mr: hle 20 /r]             | 8086,SM,LOCK               |
| AND        | reg8,reg8               | [mr: 20 /r]                 | 8086                       |
| AND        | mem,reg16               | [mr: hle o16 21 /r]         | 8086,SM,LOCK               |
| AND        | reg16,reg16             | [mr: o16 21 /r]             | 8086                       |
| AND        | mem,reg32               | [mr: hle o32 21 /r]         | 386,SM,LOCK                |
| AND        | reg32,reg32             | [mr: o32 21 /r]             | 386                        |
| AND        | mem,reg64               | [mr: hle o64 21 /r]         | X64,SM,LOCK                |
| AND        | reg64,reg64             | [mr: o64 21 /r]             | X64                        |
| AND        | reg8,mem                | [rm: 22 /r]                 | 8086,SM                    |
| AND        | reg8,reg8               | [rm: 22 /r]                 | 8086                       |
| AND        | reg16,mem               | [rm: o16 23 /r]             | 8086,SM                    |
| AND        | reg16,reg16             | [rm: o16 23 /r]             | 8086                       |
| AND        | reg32,mem               | [rm: o32 23 /r]             | 386,SM                     |
| AND        | reg32,reg32             | [rm: o32 23 /r]             | 386                        |
| AND        | reg64,mem               | [rm: o64 23 /r]             | X64,SM                     |
| AND        | reg64,reg64             | [rm: o64 23 /r]             | X64                        |
| AND        | rm16,imm8               | [mi: hle o16 83 /4 ib,s]    | 8086,LOCK                  |
| AND        | rm32,imm8               | [mi: hle o32 83 /4 ib,s]    | 386,LOCK                   |
| AND        | rm64,imm8               | [mi: hle o64 83 /4 ib,s]    | X64,LOCK                   |
| AND        | reg_al,imm              | [-i: 24 ib]                 | 8086,SM                    |
| AND        | reg_ax,sbyteword        | [mi: o16 83 /4 ib,s]        | 8086,SM,ND                 |
| AND        | reg_ax,imm              | [-i: o16 25 iw]             | 8086,SM                    |
| AND        | reg_eax,sbytedword      | [mi: o32 83 /4 ib,s]        | 386,SM,ND                  |
| AND        | reg_eax,imm             | [-i: o32 25 id]             | 386,SM                     |
| AND        | reg_rax,sbytedword      | [mi: o64 83 /4 ib,s]        | X64,SM,ND                  |
| AND        | reg_rax,imm             | [-i: o64 25 id,s]           | X64,SM                     |
| AND        | rm8,imm                 | [mi: hle 80 /4 ib]          | 8086,SM,LOCK               |
| AND        | rm16,sbyteword          | [mi: hle o16 83 /4 ib,s]    | 8086,SM,LOCK,ND            |
| AND        | rm16,imm                | [mi: hle o16 81 /4 iw]      | 8086,SM,LOCK               |
| AND        | rm32,sbytedword         | [mi: hle o32 83 /4 ib,s]    | 386,SM,LOCK,ND             |
| AND        | rm32,imm                | [mi: hle o32 81 /4 id]      | 386,SM,LOCK                |
| AND        | rm64,sbytedword         | [mi: hle o64 83 /4 ib,s]    | X64,SM,LOCK,ND             |
| AND        | rm64,imm                | [mi: hle o64 81 /4 id,s]    | X64,SM,LOCK                |
| AND        | mem,imm8                | [mi: hle 80 /4 ib]          | 8086,SM,LOCK               |
| AND        | mem,sbyteword16         | [mi: hle o16 83 /4 ib,s]    | 8086,SM,LOCK,ND            |
| AND        | mem,imm16               | [mi: hle o16 81 /4 iw]      | 8086,SM,LOCK               |
| AND        | mem,sbytedword32        | [mi: hle o32 83 /4 ib,s]    | 386,SM,LOCK,ND             |
| AND        | mem,imm32               | [mi: hle o32 81 /4 id]      | 386,SM,LOCK                |
| AND        | rm8,imm                 | [mi: hle 82 /4 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| ARPL       | mem,reg16               | [mr: 63 /r]                 | 286,PROT,SM,NOLONG         |
| ARPL       | reg16,reg16             | [mr: 63 /r]                 | 286,PROT,NOLONG            |
| BB0_RESET  | void                    | [0f 3a]                     | PENT,CYRIX,ND,OBSOLETE     |
| BB1_RESET  | void                    | [0f 3b]                     | PENT,CYRIX,ND,OBSOLETE     |
| BOUND      | reg16,mem               | [rm: o16 62 /r]             | 186,NOLONG                 |
| BOUND      | reg32,mem               | [rm: o32 62 /r]             | 386,NOLONG                 |
| BSF        | reg16,mem               | [rm: o16 nof3 0f bc /r]     | 386,SM                     |
| BSF        | reg16,reg16             | [rm: o16 nof3 0f bc /r]     | 386                        |
| BSF        | reg32,mem               | [rm: o32 nof3 0f bc /r]     | 386,SM                     |
| BSF        | reg32,reg32             | [rm: o32 nof3 0f bc /r]     | 386                        |
| BSF        | reg64,mem               | [rm: o64 nof3 0f bc /r]     | X64,SM                     |
| BSF        | reg64,reg64             | [rm: o64 nof3 0f bc /r]     | X64                        |
| BSR        | reg16,mem               | [rm: o16 nof3 0f bd /r]     | 386,SM                     |
| BSR        | reg16,reg16             | [rm: o16 nof3 0f bd /r]     | 386                        |
| BSR        | reg32,mem               | [rm: o32 nof3 0f bd /r]     | 386,SM                     |
| BSR        | reg32,reg32             | [rm: o32 nof3 0f bd /r]     | 386                        |
| BSR        | reg64,mem               | [rm: o64 nof3 0f bd /r]     | X64,SM                     |
| BSR        | reg64,reg64             | [rm: o64 nof3 0f bd /r]     | X64                        |
| BSWAP      | reg32                   | [r: o32 0f c8+r]            | 486                        |
| BSWAP      | reg64                   | [r: o64 0f c8+r]            | X64                        |
| BT         | mem,reg16               | [mr: o16 0f a3 /r]          | 386,SM                     |
| BT         | reg16,reg16             | [mr: o16 0f a3 /r]          | 386                        |
| BT         | mem,reg32               | [mr: o32 0f a3 /r]          | 386,SM                     |
| BT         | reg32,reg32             | [mr: o32 0f a3 /r]          | 386                        |
| BT         | mem,reg64               | [mr: o64 0f a3 /r]          | X64,SM                     |
| BT         | reg64,reg64             | [mr: o64 0f a3 /r]          | X64                        |
| BT         | rm16,imm                | [mi: o16 0f ba /4 ib,u]     | 386,SB                     |
| BT         | rm32,imm                | [mi: o32 0f ba /4 ib,u]     | 386,SB                     |
| BT         | rm64,imm                | [mi: o64 0f ba /4 ib,u]     | X64,SB                     |
| BTC        | mem,reg16               | [mr: hle o16 0f bb /r]      | 386,SM,LOCK                |
| BTC        | reg16,reg16             | [mr: o16 0f bb /r]          | 386                        |
| BTC        | mem,reg32               | [mr: hle o32 0f bb /r]      | 386,SM,LOCK                |
| BTC        | reg32,reg32             | [mr: o32 0f bb /r]          | 386                        |
| BTC        | mem,reg64               | [mr: hle o64 0f bb /r]      | X64,SM,LOCK                |
| BTC        | reg64,reg64             | [mr: o64 0f bb /r]          | X64                        |
| BTC        | rm16,imm                | [mi: hle o16 0f ba /7 ib,u] | 386,SB,LOCK                |
| BTC        | rm32,imm                | [mi: hle o32 0f ba /7 ib,u] | 386,SB,LOCK                |
| BTC        | rm64,imm                | [mi: hle o64 0f ba /7 ib,u] | X64,SB,LOCK                |
| BTR        | mem,reg16               | [mr: hle o16 0f b3 /r]      | 386,SM,LOCK                |
| BTR        | reg16,reg16             | [mr: o16 0f b3 /r]          | 386                        |
| BTR        | mem,reg32               | [mr: hle o32 0f b3 /r]      | 386,SM,LOCK                |
| BTR        | reg32,reg32             | [mr: o32 0f b3 /r]          | 386                        |
| BTR        | mem,reg64               | [mr: hle o64 0f b3 /r]      | X64,SM,LOCK                |
| BTR        | reg64,reg64             | [mr: o64 0f b3 /r]          | X64                        |
| BTR        | rm16,imm                | [mi: hle o16 0f ba /6 ib,u] | 386,SB,LOCK                |
| BTR        | rm32,imm                | [mi: hle o32 0f ba /6 ib,u] | 386,SB,LOCK                |
| BTR        | rm64,imm                | [mi: hle o64 0f ba /6 ib,u] | X64,SB,LOCK                |
| BTS        | mem,reg16               | [mr: hle o16 0f ab /r]      | 386,SM,LOCK                |
| BTS        | reg16,reg16             | [mr: o16 0f ab /r]          | 386                        |
| BTS        | mem,reg32               | [mr: hle o32 0f ab /r]      | 386,SM,LOCK                |
| BTS        | reg32,reg32             | [mr: o32 0f ab /r]          | 386                        |
| BTS        | mem,reg64               | [mr: hle o64 0f ab /r]      | X64,SM,LOCK                |
| BTS        | reg64,reg64             | [mr: o64 0f ab /r]          | X64                        |
| BTS        | rm16,imm                | [mi: hle o16 0f ba /5 ib,u] | 386,SB,LOCK                |
| BTS        | rm32,imm                | [mi: hle o32 0f ba /5 ib,u] | 386,SB,LOCK                |
| BTS        | rm64,imm                | [mi: hle o64 0f ba /5 ib,u] | X64,SB,LOCK                |
| CALL       | imm                     | [i: odf e8 rel]             | 8086,BND                   |
| CALL       | imm^near                | [i: odf e8 rel]             | 8086,ND,BND                |
| CALL       | imm^far                 | [i: odf 9a iwd seg]         | 8086,ND,NOLONG             |
| CALL       | imm16                   | [i: o16 e8 rel]             | 8086,NOLONG,BND            |
| CALL       | imm16^near              | [i: o16 e8 rel]             | 8086,ND,NOLONG,BND         |
| CALL       | imm16^far               | [i: o16 9a iwd seg]         | 8086,ND,NOLONG             |
| CALL       | imm32                   | [i: o32 e8 rel]             | 386,NOLONG,BND             |
| CALL       | imm32^near              | [i: o32 e8 rel]             | 386,ND,NOLONG,BND          |
| CALL       | imm32^far               | [i: o32 9a iwd seg]         | 386,ND,NOLONG              |
| CALL       | imm64                   | [i: o64nw e8 rel]           | X64,BND                    |
| CALL       | imm64^near              | [i: o64nw e8 rel]           | X64,ND,BND                 |
| CALL       | imm:imm                 | [ji: odf 9a iwd iw]         | 8086,NOLONG                |
| CALL       | imm16:imm               | [ji: o16 9a iw iw]          | 8086,NOLONG                |
| CALL       | imm:imm16               | [ji: o16 9a iw iw]          | 8086,NOLONG                |
| CALL       | imm32:imm               | [ji: o32 9a id iw]          | 386,NOLONG                 |
| CALL       | imm:imm32               | [ji: o32 9a id iw]          | 386,NOLONG                 |
| CALL       | mem^far                 | [m: odf ff /3]              | 8086,NOLONG                |
| CALL       | mem^far                 | [m: o64 ff /3]              | X64                        |
| CALL       | mem16^far               | [m: o16 ff /3]              | 8086                       |
| CALL       | mem32^far               | [m: o32 ff /3]              | 386                        |
| CALL       | mem64^far               | [m: o64 ff /3]              | X64                        |
| CALL       | mem^near                | [m: odf ff /2]              | 8086,ND,BND                |
| CALL       | rm16^near               | [m: o16 ff /2]              | 8086,NOLONG,ND,BND         |
| CALL       | rm32^near               | [m: o32 ff /2]              | 386,NOLONG,ND,BND          |
| CALL       | rm64^near               | [m: o64nw ff /2]            | X64,ND,BND                 |
| CALL       | mem                     | [m: odf ff /2]              | 8086,BND                   |
| CALL       | rm16                    | [m: o16 ff /2]              | 8086,NOLONG,BND            |
| CALL       | rm32                    | [m: o32 ff /2]              | 386,NOLONG,BND             |
| CALL       | rm64                    | [m: o64nw ff /2]            | X64,BND                    |
| CBW        | void                    | [o16 98]                    | 8086                       |
| CDQ        | void                    | [o32 99]                    | 386                        |
| CDQE       | void                    | [o64 98]                    | X64                        |
| CLC        | void                    | [f8]                        | 8086                       |
| CLD        | void                    | [fc]                        | 8086                       |
| CLI        | void                    | [fa]                        | 8086                       |
| CLTS       | void                    | [0f 06]                     | 286,PRIV                   |
| CMC        | void                    | [f5]                        | 8086                       |
| CMP        | mem,reg8                | [mr: 38 /r]                 | 8086,SM                    |
| CMP        | reg8,reg8               | [mr: 38 /r]                 | 8086                       |
| CMP        | mem,reg16               | [mr: o16 39 /r]             | 8086,SM                    |
| CMP        | reg16,reg16             | [mr: o16 39 /r]             | 8086                       |
| CMP        | mem,reg32               | [mr: o32 39 /r]             | 386,SM                     |
| CMP        | reg32,reg32             | [mr: o32 39 /r]             | 386                        |
| CMP        | mem,reg64               | [mr: o64 39 /r]             | X64,SM                     |
| CMP        | reg64,reg64             | [mr: o64 39 /r]             | X64                        |
| CMP        | reg8,mem                | [rm: 3a /r]                 | 8086,SM                    |
| CMP        | reg8,reg8               | [rm: 3a /r]                 | 8086                       |
| CMP        | reg16,mem               | [rm: o16 3b /r]             | 8086,SM                    |
| CMP        | reg16,reg16             | [rm: o16 3b /r]             | 8086                       |
| CMP        | reg32,mem               | [rm: o32 3b /r]             | 386,SM                     |
| CMP        | reg32,reg32             | [rm: o32 3b /r]             | 386                        |
| CMP        | reg64,mem               | [rm: o64 3b /r]             | X64,SM                     |
| CMP        | reg64,reg64             | [rm: o64 3b /r]             | X64                        |
| CMP        | rm16,imm8               | [mi: o16 83 /7 ib,s]        | 8086                       |
| CMP        | rm32,imm8               | [mi: o32 83 /7 ib,s]        | 386                        |
| CMP        | rm64,imm8               | [mi: o64 83 /7 ib,s]        | X64                        |
| CMP        | reg_al,imm              | [-i: 3c ib]                 | 8086,SM                    |
| CMP        | reg_ax,sbyteword        | [mi: o16 83 /7 ib,s]        | 8086,SM,ND                 |
| CMP        | reg_ax,imm              | [-i: o16 3d iw]             | 8086,SM                    |
| CMP        | reg_eax,sbytedword      | [mi: o32 83 /7 ib,s]        | 386,SM,ND                  |
| CMP        | reg_eax,imm             | [-i: o32 3d id]             | 386,SM                     |
| CMP        | reg_rax,sbytedword      | [mi: o64 83 /7 ib,s]        | X64,SM,ND                  |
| CMP        | reg_rax,imm             | [-i: o64 3d id,s]           | X64,SM                     |
| CMP        | rm8,imm                 | [mi: 80 /7 ib]              | 8086,SM                    |
| CMP        | rm16,sbyteword          | [mi: o16 83 /7 ib,s]        | 8086,SM,ND                 |
| CMP        | rm16,imm                | [mi: o16 81 /7 iw]          | 8086,SM                    |
| CMP        | rm32,sbytedword         | [mi: o32 83 /7 ib,s]        | 386,SM,ND                  |
| CMP        | rm32,imm                | [mi: o32 81 /7 id]          | 386,SM                     |
| CMP        | rm64,sbytedword         | [mi: o64 83 /7 ib,s]        | X64,SM,ND                  |
| CMP        | rm64,imm                | [mi: o64 81 /7 id,s]        | X64,SM                     |
| CMP        | mem,imm8                | [mi: 80 /7 ib]              | 8086,SM                    |
| CMP        | mem,sbyteword16         | [mi: o16 83 /7 ib,s]        | 8086,SM,ND                 |
| CMP        | mem,imm16               | [mi: o16 81 /7 iw]          | 8086,SM                    |
| CMP        | mem,sbytedword32        | [mi: o32 83 /7 ib,s]        | 386,SM,ND                  |
| CMP        | mem,imm32               | [mi: o32 81 /7 id]          | 386,SM                     |
| CMP        | rm8,imm                 | [mi: 82 /7 ib]              | 8086,SM,ND,NOLONG          |
| CMPSB      | void                    | [repe a6]                   | 8086                       |
| CMPSD      | void                    | [repe o32 a7]               | 386                        |
| CMPSQ      | void                    | [repe o64 a7]               | X64                        |
| CMPSW      | void                    | [repe o16 a7]               | 8086                       |
| CMPXCHG    | mem,reg8                | [mr: hle 0f b0 /r]          | PENT,SM,LOCK               |
| CMPXCHG    | reg8,reg8               | [mr: 0f b0 /r]              | PENT                       |
| CMPXCHG    | mem,reg16               | [mr: hle o16 0f b1 /r]      | PENT,SM,LOCK               |
| CMPXCHG    | reg16,reg16             | [mr: o16 0f b1 /r]          | PENT                       |
| CMPXCHG    | mem,reg32               | [mr: hle o32 0f b1 /r]      | PENT,SM,LOCK               |
| CMPXCHG    | reg32,reg32             | [mr: o32 0f b1 /r]          | PENT                       |
| CMPXCHG    | mem,reg64               | [mr: hle o64 0f b1 /r]      | X64,SM,LOCK                |
| CMPXCHG    | reg64,reg64             | [mr: o64 0f b1 /r]          | X64                        |
| CMPXCHG8B  | mem                     | [m: hle norexw 0f c7 /1]    | PENT,LOCK                  |
| CMPXCHG16B | mem                     | [m: o64 0f c7 /1]           | X64,LOCK                   |
| CPUID      | void                    | [0f a2]                     | PENT                       |
| CPU_READ   | void                    | [0f 3d]                     | PENT,CYRIX                 |
| CPU_WRITE  | void                    | [0f 3c]                     | PENT,CYRIX                 |
| CQO        | void                    | [o64 99]                    | X64                        |
| CWD        | void                    | [o16 99]                    | 8086                       |
| CWDE       | void                    | [o32 98]                    | 386                        |
| DAA        | void                    | [27]                        | 8086,NOLONG                |
| DAS        | void                    | [2f]                        | 8086,NOLONG                |
| DEC        | reg16                   | [r: o16 48+r]               | 8086,NOLONG                |
| DEC        | reg32                   | [r: o32 48+r]               | 386,NOLONG                 |
| DEC        | rm8                     | [m: hle fe /1]              | 8086,LOCK                  |
| DEC        | rm16                    | [m: hle o16 ff /1]          | 8086,LOCK                  |
| DEC        | rm32                    | [m: hle o32 ff /1]          | 386,LOCK                   |
| DEC        | rm64                    | [m: hle o64 ff /1]          | X64,LOCK                   |
| DIV        | rm8                     | [m: f6 /6]                  | 8086                       |
| DIV        | rm16                    | [m: o16 f7 /6]              | 8086                       |
| DIV        | rm32                    | [m: o32 f7 /6]              | 386                        |
| DIV        | rm64                    | [m: o64 f7 /6]              | X64                        |
| DMINT      | void                    | [0f 39]                     | P6,CYRIX                   |
| EMMS       | void                    | [0f 77]                     | PENT,MMX                   |
| ENTER      | imm,imm                 | [ij: c8 iw ib,u]            | 186                        |
| EQU        | imm ignore 8086         |                             |                            |
| EQU        | imm:imm  ignore 8086    |                             |                            |
| F2XM1      | void                    | [d9 f0]                     | 8086,FPU                   |
| FABS       | void                    | [d9 e1]                     | 8086,FPU                   |
| FADD       | mem32                   | [m: d8 /0]                  | 8086,FPU                   |
| FADD       | mem64                   | [m: dc /0]                  | 8086,FPU                   |
| FADD       | fpureg^to               | [r: dc c0+r]                | 8086,FPU                   |
| FADD       | fpureg                  | [r: d8 c0+r]                | 8086,FPU                   |
| FADD       | fpureg,fpu0             | [r-: dc c0+r]               | 8086,FPU                   |
| FADD       | fpu0,fpureg             | [-r: d8 c0+r]               | 8086,FPU                   |
| FADD       | void                    | [de c1]                     | 8086,FPU,ND                |
| FADDP      | fpureg                  | [r: de c0+r]                | 8086,FPU                   |
| FADDP      | fpureg,fpu0             | [r-: de c0+r]               | 8086,FPU                   |
| FADDP      | void                    | [de c1]                     | 8086,FPU,ND                |
| FBLD       | mem80                   | [m: df /4]                  | 8086,FPU                   |
| FBLD       | mem                     | [m: df /4]                  | 8086,FPU                   |
| FBSTP      | mem80                   | [m: df /6]                  | 8086,FPU                   |
| FBSTP      | mem                     | [m: df /6]                  | 8086,FPU                   |
| FCHS       | void                    | [d9 e0]                     | 8086,FPU                   |
| FCLEX      | void                    | [wait db e2]                | 8086,FPU                   |
| FCMOVB     | fpureg                  | [r: da c0+r]                | P6,FPU                     |
| FCMOVB     | fpu0,fpureg             | [-r: da c0+r]               | P6,FPU                     |
| FCMOVB     | void                    | [da c1]                     | P6,FPU,ND                  |
| FCMOVBE    | fpureg                  | [r: da d0+r]                | P6,FPU                     |
| FCMOVBE    | fpu0,fpureg             | [-r: da d0+r]               | P6,FPU                     |
| FCMOVBE    | void                    | [da d1]                     | P6,FPU,ND                  |
| FCMOVE     | fpureg                  | [r: da c8+r]                | P6,FPU                     |
| FCMOVE     | fpu0,fpureg             | [-r: da c8+r]               | P6,FPU                     |
| FCMOVE     | void                    | [da c9]                     | P6,FPU,ND                  |
| FCMOVNB    | fpureg                  | [r: db c0+r]                | P6,FPU                     |
| FCMOVNB    | fpu0,fpureg             | [-r: db c0+r]               | P6,FPU                     |
| FCMOVNB    | void                    | [db c1]                     | P6,FPU,ND                  |
| FCMOVNBE   | fpureg                  | [r: db d0+r]                | P6,FPU                     |
| FCMOVNBE   | fpu0,fpureg             | [-r: db d0+r]               | P6,FPU                     |
| FCMOVNBE   | void                    | [db d1]                     | P6,FPU,ND                  |
| FCMOVNE    | fpureg                  | [r: db c8+r]                | P6,FPU                     |
| FCMOVNE    | fpu0,fpureg             | [-r: db c8+r]               | P6,FPU                     |
| FCMOVNE    | void                    | [db c9]                     | P6,FPU,ND                  |
| FCMOVNU    | fpureg                  | [r: db d8+r]                | P6,FPU                     |
| FCMOVNU    | fpu0,fpureg             | [-r: db d8+r]               | P6,FPU                     |
| FCMOVNU    | void                    | [db d9]                     | P6,FPU,ND                  |
| FCMOVU     | fpureg                  | [r: da d8+r]                | P6,FPU                     |
| FCMOVU     | fpu0,fpureg             | [-r: da d8+r]               | P6,FPU                     |
| FCMOVU     | void                    | [da d9]                     | P6,FPU,ND                  |
| FCOM       | mem32                   | [m: d8 /2]                  | 8086,FPU                   |
| FCOM       | mem64                   | [m: dc /2]                  | 8086,FPU                   |
| FCOM       | fpureg                  | [r: d8 d0+r]                | 8086,FPU                   |
| FCOM       | fpu0,fpureg             | [-r: d8 d0+r]               | 8086,FPU                   |
| FCOM       | void                    | [d8 d1]                     | 8086,FPU,ND                |
| FCOMI      | fpureg                  | [r: db f0+r]                | P6,FPU                     |
| FCOMI      | fpu0,fpureg             | [-r: db f0+r]               | P6,FPU                     |
| FCOMI      | void                    | [db f1]                     | P6,FPU,ND                  |
| FCOMIP     | fpureg                  | [r: df f0+r]                | P6,FPU                     |
| FCOMIP     | fpu0,fpureg             | [-r: df f0+r]               | P6,FPU                     |
| FCOMIP     | void                    | [df f1]                     | P6,FPU,ND                  |
| FCOMP      | mem32                   | [m: d8 /3]                  | 8086,FPU                   |
| FCOMP      | mem64                   | [m: dc /3]                  | 8086,FPU                   |
| FCOMP      | fpureg                  | [r: d8 d8+r]                | 8086,FPU                   |
| FCOMP      | fpu0,fpureg             | [-r: d8 d8+r]               | 8086,FPU                   |
| FCOMP      | void                    | [d8 d9]                     | 8086,FPU,ND                |
| FCOMPP     | void                    | [de d9]                     | 8086,FPU                   |
| FCOS       | void                    | [d9 ff]                     | 386,FPU                    |
| FDECSTP    | void                    | [d9 f6]                     | 8086,FPU                   |
| FDISI      | void                    | [wait db e1]                | 8086,FPU                   |
| FDIV       | mem32                   | [m: d8 /6]                  | 8086,FPU                   |
| FDIV       | mem64                   | [m: dc /6]                  | 8086,FPU                   |
| FDIV       | fpureg^to               | [r: dc f8+r]                | 8086,FPU                   |
| FDIV       | fpureg                  | [r: d8 f0+r]                | 8086,FPU                   |
| FDIV       | fpureg,fpu0             | [r-: dc f8+r]               | 8086,FPU                   |
| FDIV       | fpu0,fpureg             | [-r: d8 f0+r]               | 8086,FPU                   |
| FDIV       | void                    | [de f9]                     | 8086,FPU,ND                |
| FDIVP      | fpureg                  | [r: de f8+r]                | 8086,FPU                   |
| FDIVP      | fpureg,fpu0             | [r-: de f8+r]               | 8086,FPU                   |
| FDIVP      | void                    | [de f9]                     | 8086,FPU,ND                |
| FDIVR      | mem32                   | [m: d8 /7]                  | 8086,FPU                   |
| FDIVR      | mem64                   | [m: dc /7]                  | 8086,FPU                   |
| FDIVR      | fpureg^to               | [r: dc f0+r]                | 8086,FPU                   |
| FDIVR      | fpureg,fpu0             | [r-: dc f0+r]               | 8086,FPU                   |
| FDIVR      | fpureg                  | [r: d8 f8+r]                | 8086,FPU                   |
| FDIVR      | fpu0,fpureg             | [-r: d8 f8+r]               | 8086,FPU                   |
| FDIVR      | void                    | [de f1]                     | 8086,FPU,ND                |
| FDIVRP     | fpureg                  | [r: de f0+r]                | 8086,FPU                   |
| FDIVRP     | fpureg,fpu0             | [r-: de f0+r]               | 8086,FPU                   |
| FDIVRP     | void                    | [de f1]                     | 8086,FPU,ND                |
| FEMMS      | void                    | [0f 0e]                     | PENT,3DNOW                 |
| FENI       | void                    | [wait db e0]                | 8086,FPU                   |
| FFREE      | fpureg                  | [r: dd c0+r]                | 8086,FPU                   |
| FFREE      | void                    | [dd c1]                     | 8086,FPU                   |
| FFREEP     | fpureg                  | [r: df c0+r]                | 286,FPU,UNDOC              |
| FFREEP     | void                    | [df c1]                     | 286,FPU,UNDOC              |
| FIADD      | mem32                   | [m: da /0]                  | 8086,FPU                   |
| FIADD      | mem16                   | [m: de /0]                  | 8086,FPU                   |
| FICOM      | mem32                   | [m: da /2]                  | 8086,FPU                   |
| FICOM      | mem16                   | [m: de /2]                  | 8086,FPU                   |
| FICOMP     | mem32                   | [m: da /3]                  | 8086,FPU                   |
| FICOMP     | mem16                   | [m: de /3]                  | 8086,FPU                   |
| FIDIV      | mem32                   | [m: da /6]                  | 8086,FPU                   |
| FIDIV      | mem16                   | [m: de /6]                  | 8086,FPU                   |
| FIDIVR     | mem32                   | [m: da /7]                  | 8086,FPU                   |
| FIDIVR     | mem16                   | [m: de /7]                  | 8086,FPU                   |
| FILD       | mem32                   | [m: db /0]                  | 8086,FPU                   |
| FILD       | mem16                   | [m: df /0]                  | 8086,FPU                   |
| FILD       | mem64                   | [m: df /5]                  | 8086,FPU                   |
| FIMUL      | mem32                   | [m: da /1]                  | 8086,FPU                   |
| FIMUL      | mem16                   | [m: de /1]                  | 8086,FPU                   |
| FINCSTP    | void                    | [d9 f7]                     | 8086,FPU                   |
| FINIT      | void                    | [wait db e3]                | 8086,FPU                   |
| FIST       | mem32                   | [m: db /2]                  | 8086,FPU                   |
| FIST       | mem16                   | [m: df /2]                  | 8086,FPU                   |
| FISTP      | mem32                   | [m: db /3]                  | 8086,FPU                   |
| FISTP      | mem16                   | [m: df /3]                  | 8086,FPU                   |
| FISTP      | mem64                   | [m: df /7]                  | 8086,FPU                   |
| FISTTP     | mem16                   | [m: df /1]                  | FPU                        |
| FISTTP     | mem32                   | [m: db /1]                  | FPU                        |
| FISTTP     | mem64                   | [m: dd /1]                  | FPU                        |
| FISUB      | mem32                   | [m: da /4]                  | 8086,FPU                   |
| FISUB      | mem16                   | [m: de /4]                  | 8086,FPU                   |
| FISUBR     | mem32                   | [m: da /5]                  | 8086,FPU                   |
| FISUBR     | mem16                   | [m: de /5]                  | 8086,FPU                   |
| FLD        | mem32                   | [m: d9 /0]                  | 8086,FPU                   |
| FLD        | mem64                   | [m: dd /0]                  | 8086,FPU                   |
| FLD        | mem80                   | [m: db /5]                  | 8086,FPU                   |
| FLD        | fpureg                  | [r: d9 c0+r]                | 8086,FPU                   |
| FLD        | void                    | [d9 c1]                     | 8086,FPU,ND                |
| FLD1       | void                    | [d9 e8]                     | 8086,FPU                   |
| FLDCW      | mem                     | [m: d9 /5]                  | 8086,FPU,SW                |
| FLDENV     | mem                     | [m: d9 /4]                  | 8086,FPU                   |
| FLDL2E     | void                    | [d9 ea]                     | 8086,FPU                   |
| FLDL2T     | void                    | [d9 e9]                     | 8086,FPU                   |
| FLDLG2     | void                    | [d9 ec]                     | 8086,FPU                   |
| FLDLN2     | void                    | [d9 ed]                     | 8086,FPU                   |
| FLDPI      | void                    | [d9 eb]                     | 8086,FPU                   |
| FLDZ       | void                    | [d9 ee]                     | 8086,FPU                   |
| FMUL       | mem32                   | [m: d8 /1]                  | 8086,FPU                   |
| FMUL       | mem64                   | [m: dc /1]                  | 8086,FPU                   |
| FMUL       | fpureg^to               | [r: dc c8+r]                | 8086,FPU                   |
| FMUL       | fpureg,fpu0             | [r-: dc c8+r]               | 8086,FPU                   |
| FMUL       | fpureg                  | [r: d8 c8+r]                | 8086,FPU                   |
| FMUL       | fpu0,fpureg             | [-r: d8 c8+r]               | 8086,FPU                   |
| FMUL       | void                    | [de c9]                     | 8086,FPU,ND                |
| FMULP      | fpureg                  | [r: de c8+r]                | 8086,FPU                   |
| FMULP      | fpureg,fpu0             | [r-: de c8+r]               | 8086,FPU                   |
| FMULP      | void                    | [de c9]                     | 8086,FPU,ND                |
| FNCLEX     | void                    | [db e2]                     | 8086,FPU                   |
| FNDISI     | void                    | [db e1]                     | 8086,FPU                   |
| FNENI      | void                    | [db e0]                     | 8086,FPU                   |
| FNINIT     | void                    | [db e3]                     | 8086,FPU                   |
| FNOP       | void                    | [d9 d0]                     | 8086,FPU                   |
| FNSAVE     | mem                     | [m: dd /6]                  | 8086,FPU                   |
| FNSTCW     | mem                     | [m: d9 /7]                  | 8086,FPU,SW                |
| FNSTENV    | mem                     | [m: d9 /6]                  | 8086,FPU                   |
| FNSTSW     | mem                     | [m: dd /7]                  | 8086,FPU,SW                |
| FNSTSW     | reg_ax                  | [-: df e0]                  | 286,FPU                    |
| FPATAN     | void                    | [d9 f3]                     | 8086,FPU                   |
| FPREM      | void                    | [d9 f8]                     | 8086,FPU                   |
| FPREM1     | void                    | [d9 f5]                     | 386,FPU                    |
| FPTAN      | void                    | [d9 f2]                     | 8086,FPU                   |
| FRNDINT    | void                    | [d9 fc]                     | 8086,FPU                   |
| FRSTOR     | mem                     | [m: dd /4]                  | 8086,FPU                   |
| FSAVE      | mem                     | [m: wait dd /6]             | 8086,FPU                   |
| FSCALE     | void                    | [d9 fd]                     | 8086,FPU                   |
| FSETPM     | void                    | [db e4]                     | 286,FPU                    |
| FSIN       | void                    | [d9 fe]                     | 386,FPU                    |
| FSINCOS    | void                    | [d9 fb]                     | 386,FPU                    |
| FSQRT      | void                    | [d9 fa]                     | 8086,FPU                   |
| FST        | mem32                   | [m: d9 /2]                  | 8086,FPU                   |
| FST        | mem64                   | [m: dd /2]                  | 8086,FPU                   |
| FST        | fpureg                  | [r: dd d0+r]                | 8086,FPU                   |
| FST        | void                    | [dd d1]                     | 8086,FPU,ND                |
| FSTCW      | mem                     | [m: wait d9 /7]             | 8086,FPU,SW                |
| FSTENV     | mem                     | [m: wait d9 /6]             | 8086,FPU                   |
| FSTP       | mem32                   | [m: d9 /3]                  | 8086,FPU                   |
| FSTP       | mem64                   | [m: dd /3]                  | 8086,FPU                   |
| FSTP       | mem80                   | [m: db /7]                  | 8086,FPU                   |
| FSTP       | fpureg                  | [r: dd d8+r]                | 8086,FPU                   |
| FSTP       | void                    | [dd d9]                     | 8086,FPU,ND                |
| FSTSW      | mem                     | [m: wait dd /7]             | 8086,FPU,SW                |
| FSTSW      | reg_ax                  | [-: wait df e0]             | 286,FPU                    |
| FSUB       | mem32                   | [m: d8 /4]                  | 8086,FPU                   |
| FSUB       | mem64                   | [m: dc /4]                  | 8086,FPU                   |
| FSUB       | fpureg^to               | [r: dc e8+r]                | 8086,FPU                   |
| FSUB       | fpureg,fpu0             | [r-: dc e8+r]               | 8086,FPU                   |
| FSUB       | fpureg                  | [r: d8 e0+r]                | 8086,FPU                   |
| FSUB       | fpu0,fpureg             | [-r: d8 e0+r]               | 8086,FPU                   |
| FSUB       | void                    | [de e9]                     | 8086,FPU,ND                |
| FSUBP      | fpureg                  | [r: de e8+r]                | 8086,FPU                   |
| FSUBP      | fpureg,fpu0             | [r-: de e8+r]               | 8086,FPU                   |
| FSUBP      | void                    | [de e9]                     | 8086,FPU,ND                |
| FSUBR      | mem32                   | [m: d8 /5]                  | 8086,FPU                   |
| FSUBR      | mem64                   | [m: dc /5]                  | 8086,FPU                   |
| FSUBR      | fpureg^to               | [r: dc e0+r]                | 8086,FPU                   |
| FSUBR      | fpureg,fpu0             | [r-: dc e0+r]               | 8086,FPU                   |
| FSUBR      | fpureg                  | [r: d8 e8+r]                | 8086,FPU                   |
| FSUBR      | fpu0,fpureg             | [-r: d8 e8+r]               | 8086,FPU                   |
| FSUBR      | void                    | [de e1]                     | 8086,FPU,ND                |
| FSUBRP     | fpureg                  | [r: de e0+r]                | 8086,FPU                   |
| FSUBRP     | fpureg,fpu0             | [r-: de e0+r]               | 8086,FPU                   |
| FSUBRP     | void                    | [de e1]                     | 8086,FPU,ND                |
| FTST       | void                    | [d9 e4]                     | 8086,FPU                   |
| FUCOM      | fpureg                  | [r: dd e0+r]                | 386,FPU                    |
| FUCOM      | fpu0,fpureg             | [-r: dd e0+r]               | 386,FPU                    |
| FUCOM      | void                    | [dd e1]                     | 386,FPU,ND                 |
| FUCOMI     | fpureg                  | [r: db e8+r]                | P6,FPU                     |
| FUCOMI     | fpu0,fpureg             | [-r: db e8+r]               | P6,FPU                     |
| FUCOMI     | void                    | [db e9]                     | P6,FPU,ND                  |
| FUCOMIP    | fpureg                  | [r: df e8+r]                | P6,FPU                     |
| FUCOMIP    | fpu0,fpureg             | [-r: df e8+r]               | P6,FPU                     |
| FUCOMIP    | void                    | [df e9]                     | P6,FPU,ND                  |
| FUCOMP     | fpureg                  | [r: dd e8+r]                | 386,FPU                    |
| FUCOMP     | fpu0,fpureg             | [-r: dd e8+r]               | 386,FPU                    |
| FUCOMP     | void                    | [dd e9]                     | 386,FPU,ND                 |
| FUCOMPP    | void                    | [da e9]                     | 386,FPU                    |
| FXAM       | void                    | [d9 e5]                     | 8086,FPU                   |
| FXCH       | fpureg                  | [r: d9 c8+r]                | 8086,FPU                   |
| FXCH       | fpureg,fpu0             | [r-: d9 c8+r]               | 8086,FPU                   |
| FXCH       | fpu0,fpureg             | [-r: d9 c8+r]               | 8086,FPU                   |
| FXCH       | void                    | [d9 c9]                     | 8086,FPU,ND                |
| FXTRACT    | void                    | [d9 f4]                     | 8086,FPU                   |
| FYL2X      | void                    | [d9 f1]                     | 8086,FPU                   |
| FYL2XP1    | void                    | [d9 f9]                     | 8086,FPU                   |
| HLT        | void                    | [f4]                        | 8086,PRIV                  |
| IBTS       | mem,reg16               | [mr: o16 0f a7 /r]          | 386,SW,UNDOC,ND,OBSOLETE   |
| IBTS       | reg16,reg16             | [mr: o16 0f a7 /r]          | 386,UNDOC,ND,OBSOLETE      |
| IBTS       | mem,reg32               | [mr: o32 0f a7 /r]          | 386,SD,UNDOC,ND,OBSOLETE   |
| IBTS       | reg32,reg32             | [mr: o32 0f a7 /r]          | 386,UNDOC,ND,OBSOLETE      |
| ICEBP      | void                    | [f1]                        | 386,ND                     |
| IDIV       | rm8                     | [m: f6 /7]                  | 8086                       |
| IDIV       | rm16                    | [m: o16 f7 /7]              | 8086                       |
| IDIV       | rm32                    | [m: o32 f7 /7]              | 386                        |
| IDIV       | rm64                    | [m: o64 f7 /7]              | X64                        |
| IMUL       | rm8                     | [m: f6 /5]                  | 8086                       |
| IMUL       | rm16                    | [m: o16 f7 /5]              | 8086                       |
| IMUL       | rm32                    | [m: o32 f7 /5]              | 386                        |
| IMUL       | rm64                    | [m: o64 f7 /5]              | X64                        |
| IMUL       | reg16,mem               | [rm: o16 0f af /r]          | 386,SM                     |
| IMUL       | reg16,reg16             | [rm: o16 0f af /r]          | 386                        |
| IMUL       | reg32,mem               | [rm: o32 0f af /r]          | 386,SM                     |
| IMUL       | reg32,reg32             | [rm: o32 0f af /r]          | 386                        |
| IMUL       | reg64,mem               | [rm: o64 0f af /r]          | X64,SM                     |
| IMUL       | reg64,reg64             | [rm: o64 0f af /r]          | X64                        |
| IMUL       | reg16,mem,imm8          | [rmi: o16 6b /r ib,s]       | 186,SM                     |
| IMUL       | reg16,mem,sbyteword     | [rmi: o16 6b /r ib,s]       | 186,SM,ND                  |
| IMUL       | reg16,mem,imm16         | [rmi: o16 69 /r iw]         | 186,SM                     |
| IMUL       | reg16,mem,imm           | [rmi: o16 69 /r iw]         | 186,SM,ND                  |
| IMUL       | reg16,reg16,imm8        | [rmi: o16 6b /r ib,s]       | 186                        |
| IMUL       | reg16,reg16,sbyteword   | [rmi: o16 6b /r ib,s]       | 186,SM,ND                  |
| IMUL       | reg16,reg16,imm16       | [rmi: o16 69 /r iw]         | 186                        |
| IMUL       | reg16,reg16,imm         | [rmi: o16 69 /r iw]         | 186,SM,ND                  |
| IMUL       | reg32,mem,imm8          | [rmi: o32 6b /r ib,s]       | 386,SM                     |
| IMUL       | reg32,mem,sbytedword    | [rmi: o32 6b /r ib,s]       | 386,SM,ND                  |
| IMUL       | reg32,mem,imm32         | [rmi: o32 69 /r id]         | 386,SM                     |
| IMUL       | reg32,mem,imm           | [rmi: o32 69 /r id]         | 386,SM,ND                  |
| IMUL       | reg32,reg32,imm8        | [rmi: o32 6b /r ib,s]       | 386                        |
| IMUL       | reg32,reg32,sbytedword  | [rmi: o32 6b /r ib,s]       | 386,SM,ND                  |
| IMUL       | reg32,reg32,imm32       | [rmi: o32 69 /r id]         | 386                        |
| IMUL       | reg32,reg32,imm         | [rmi: o32 69 /r id]         | 386,SM,ND                  |
| IMUL       | reg64,mem,imm8          | [rmi: o64 6b /r ib,s]       | X64,SM                     |
| IMUL       | reg64,mem,sbytedword    | [rmi: o64 6b /r ib,s]       | X64,SM,ND                  |
| IMUL       | reg64,mem,imm32         | [rmi: o64 69 /r id]         | X64,SM                     |
| IMUL       | reg64,mem,imm           | [rmi: o64 69 /r id,s]       | X64,SM,ND                  |
| IMUL       | reg64,reg64,imm8        | [rmi: o64 6b /r ib,s]       | X64                        |
| IMUL       | reg64,reg64,sbytedword  | [rmi: o64 6b /r ib,s]       | X64,SM,ND                  |
| IMUL       | reg64,reg64,imm32       | [rmi: o64 69 /r id]         | X64                        |
| IMUL       | reg64,reg64,imm         | [rmi: o64 69 /r id,s]       | X64,SM,ND                  |
| IMUL       | reg16,imm8              | [r+mi: o16 6b /r ib,s]      | 186                        |
| IMUL       | reg16,sbyteword         | [r+mi: o16 6b /r ib,s]      | 186,SM,ND                  |
| IMUL       | reg16,imm16             | [r+mi: o16 69 /r iw]        | 186                        |
| IMUL       | reg16,imm               | [r+mi: o16 69 /r iw]        | 186,SM,ND                  |
| IMUL       | reg32,imm8              | [r+mi: o32 6b /r ib,s]      | 386                        |
| IMUL       | reg32,sbytedword        | [r+mi: o32 6b /r ib,s]      | 386,SM,ND                  |
| IMUL       | reg32,imm32             | [r+mi: o32 69 /r id]        | 386                        |
| IMUL       | reg32,imm               | [r+mi: o32 69 /r id]        | 386,SM,ND                  |
| IMUL       | reg64,imm8              | [r+mi: o64 6b /r ib,s]      | X64                        |
| IMUL       | reg64,sbytedword        | [r+mi: o64 6b /r ib,s]      | X64,SM,ND                  |
| IMUL       | reg64,imm32             | [r+mi: o64 69 /r id,s]      | X64                        |
| IMUL       | reg64,imm               | [r+mi: o64 69 /r id,s]      | X64,SM,ND                  |
| IN         | reg_al,imm              | [-i: e4 ib,u]               | 8086,SB                    |
| IN         | reg_ax,imm              | [-i: o16 e5 ib,u]           | 8086,SB                    |
| IN         | reg_eax,imm             | [-i: o32 e5 ib,u]           | 386,SB                     |
| IN         | reg_al,reg_dx           | [--: ec]                    | 8086                       |
| IN         | reg_ax,reg_dx           | [--: o16 ed]                | 8086                       |
| IN         | reg_eax,reg_dx          | [--: o32 ed]                | 386                        |
| INC        | reg16                   | [r: o16 40+r]               | 8086,NOLONG                |
| INC        | reg32                   | [r: o32 40+r]               | 386,NOLONG                 |
| INC        | rm8                     | [m: hle fe /0]              | 8086,LOCK                  |
| INC        | rm16                    | [m: hle o16 ff /0]          | 8086,LOCK                  |
| INC        | rm32                    | [m: hle o32 ff /0]          | 386,LOCK                   |
| INC        | rm64                    | [m: hle o64 ff /0]          | X64,LOCK                   |
| INSB       | void                    | [6c]                        | 186                        |
| INSD       | void                    | [o32 6d]                    | 386                        |
| INSW       | void                    | [o16 6d]                    | 186                        |
| INT        | imm                     | [i: cd ib,u]                | 8086,SB                    |
| INT01      | void                    | [f1]                        | 386,ND                     |
| INT1       | void                    | [f1]                        | 386                        |
| INT03      | void                    | [cc]                        | 8086,ND                    |
| INT3       | void                    | [cc]                        | 8086                       |
| INTO       | void                    | [ce]                        | 8086,NOLONG                |
| INVD       | void                    | [0f 08]                     | 486,PRIV                   |
| INVPCID    | reg32,mem128            | [rm: 66 0f 38 82 /r]        | FUTURE,INVPCID,PRIV,NOLONG |
| INVPCID    | reg64,mem128            | [rm: 66 0f 38 82 /r]        | FUTURE,INVPCID,PRIV,LONG   |
| INVLPG     | mem                     | [m: 0f 01 /7]               | 486,PRIV                   |
| INVLPGA    | reg_ax,reg_ecx          | [--: a16 0f 01 df]          | X86_64,AMD,NOLONG          |
| INVLPGA    | reg_eax,reg_ecx         | [--: a32 0f 01 df]          | X86_64,AMD                 |
| INVLPGA    | reg_rax,reg_ecx         | [--: o64nw a64 0f 01 df]    | X64,AMD                    |
| INVLPGA    | void                    | [0f 01 df]                  | X86_64,AMD                 |
| IRET       | void                    | [odf cf]                    | 8086                       |
| IRETD      | void                    | [o32 cf]                    | 386                        |
| IRETQ      | void                    | [o64 cf]                    | X64                        |
| IRETW      | void                    | [o16 cf]                    | 8086                       |
| JCXZ       | imm                     | [i: a16 e3 rel8]            | 8086,NOLONG                |
| JECXZ      | imm                     | [i: a32 e3 rel8]            | 386                        |
| JRCXZ      | imm                     | [i: a64 e3 rel8]            | X64                        |
| JMP        | imm^short               | [i: eb rel8]                | 8086                       |
| JMP        | imm                     | [i: jmp8 eb rel8]           | 8086,ND                    |
| JMP        | imm                     | [i: odf e9 rel]             | 8086,BND                   |
| JMP        | imm^near                | [i: odf e9 rel]             | 8086,ND,BND                |
| JMP        | imm^far                 | [i: odf ea iwd seg]         | 8086,ND,NOLONG             |
| JMP        | imm16                   | [i: o16 e9 rel]             | 8086,NOLONG,BND            |
| JMP        | imm16^near              | [i: o16 e9 rel]             | 8086,ND,NOLONG,BND         |
| JMP        | imm16^far               | [i: o16 ea iwd seg]         | 8086,ND,NOLONG             |
| JMP        | imm32                   | [i: o32 e9 rel]             | 386,NOLONG,BND             |
| JMP        | imm32^near              | [i: o32 e9 rel]             | 386,ND,NOLONG,BND          |
| JMP        | imm32^far               | [i: o32 ea iwd seg]         | 386,ND,NOLONG              |
| JMP        | imm64                   | [i: o64nw e9 rel]           | X64,BND                    |
| JMP        | imm64^near              | [i: o64nw e9 rel]           | X64,ND,BND                 |
| JMP        | imm:imm                 | [ji: odf ea iwd iw]         | 8086,NOLONG                |
| JMP        | imm16:imm               | [ji: o16 ea iw iw]          | 8086,NOLONG                |
| JMP        | imm:imm16               | [ji: o16 ea iw iw]          | 8086,NOLONG                |
| JMP        | imm32:imm               | [ji: o32 ea id iw]          | 386,NOLONG                 |
| JMP        | imm:imm32               | [ji: o32 ea id iw]          | 386,NOLONG                 |
| JMP        | mem^far                 | [m: odf ff /5]              | 8086,NOLONG                |
| JMP        | mem^far                 | [m: o64 ff /5]              | X64                        |
| JMP        | mem16^far               | [m: o16 ff /5]              | 8086                       |
| JMP        | mem32^far               | [m: o32 ff /5]              | 386                        |
| JMP        | mem64^far               | [m: o64 ff /5]              | X64                        |
| JMP        | mem^near                | [m: odf ff /4]              | 8086,ND,BND                |
| JMP        | rm16^near               | [m: o16 ff /4]              | 8086,NOLONG,ND,BND         |
| JMP        | rm32^near               | [m: o32 ff /4]              | 386,NOLONG,ND,BND          |
| JMP        | rm64^near               | [m: o64nw ff /4]            | X64,ND,BND                 |
| JMP        | mem                     | [m: odf ff /4]              | 8086,BND                   |
| JMP        | rm16                    | [m: o16 ff /4]              | 8086,NOLONG,BND            |
| JMP        | rm32                    | [m: o32 ff /4]              | 386,NOLONG,BND             |
| JMP        | rm64                    | [m: o64nw ff /4]            | X64,BND                    |
| JMPE       | imm                     | [i: odf 0f b8 rel]          | IA64                       |
| JMPE       | imm16                   | [i: o16 0f b8 rel]          | IA64                       |
| JMPE       | imm32                   | [i: o32 0f b8 rel]          | IA64                       |
| JMPE       | rm16                    | [m: o16 0f 00 /6]           | IA64                       |
| JMPE       | rm32                    | [m: o32 0f 00 /6]           | IA64                       |
| LAHF       | void                    | [9f]                        | 8086                       |
| LAR        | reg16,mem               | [rm: o16 0f 02 /r]          | 286,PROT,SW                |
| LAR        | reg16,reg16             | [rm: o16 0f 02 /r]          | 286,PROT                   |
| LAR        | reg16,reg32             | [rm: o16 0f 02 /r]          | 386,PROT                   |
| LAR        | reg16,reg64             | [rm: o16 o64nw 0f 02 /r]    | X64,PROT,ND                |
| LAR        | reg32,mem               | [rm: o32 0f 02 /r]          | 386,PROT,SW                |
| LAR        | reg32,reg16             | [rm: o32 0f 02 /r]          | 386,PROT                   |
| LAR        | reg32,reg32             | [rm: o32 0f 02 /r]          | 386,PROT                   |
| LAR        | reg32,reg64             | [rm: o32 o64nw 0f 02 /r]    | X64,PROT,ND                |
| LAR        | reg64,mem               | [rm: o64 0f 02 /r]          | X64,PROT,SW                |
| LAR        | reg64,reg16             | [rm: o64 0f 02 /r]          | X64,PROT                   |
| LAR        | reg64,reg32             | [rm: o64 0f 02 /r]          | X64,PROT                   |
| LAR        | reg64,reg64             | [rm: o64 0f 02 /r]          | X64,PROT                   |
| LDS        | reg16,mem               | [rm: o16 c5 /r]             | 8086,NOLONG                |
| LDS        | reg32,mem               | [rm: o32 c5 /r]             | 386,NOLONG                 |
| LEA        | reg16,mem               | [rm: o16 8d /r]             | 8086                       |
| LEA        | reg32,mem               | [rm: o32 8d /r]             | 386                        |
| LEA        | reg64,mem               | [rm: o64 8d /r]             | X64                        |
| LEAVE      | void                    | [c9]                        | 186                        |
| LES        | reg16,mem               | [rm: o16 c4 /r]             | 8086,NOLONG                |
| LES        | reg32,mem               | [rm: o32 c4 /r]             | 386,NOLONG                 |
| LFENCE     | void                    | [np 0f ae e8]               | X64,AMD                    |
| LFS        | reg16,mem               | [rm: o16 0f b4 /r]          | 386                        |
| LFS        | reg32,mem               | [rm: o32 0f b4 /r]          | 386                        |
| LFS        | reg64,mem               | [rm: o64 0f b4 /r]          | X64                        |
| LGDT       | mem                     | [m: 0f 01 /2]               | 286,PRIV                   |
| LGS        | reg16,mem               | [rm: o16 0f b5 /r]          | 386                        |
| LGS        | reg32,mem               | [rm: o32 0f b5 /r]          | 386                        |
| LGS        | reg64,mem               | [rm: o64 0f b5 /r]          | X64                        |
| LIDT       | mem                     | [m: 0f 01 /3]               | 286,PRIV                   |
| LLDT       | mem                     | [m: 0f 00 /2]               | 286,PROT,PRIV              |
| LLDT       | mem16                   | [m: 0f 00 /2]               | 286,PROT,PRIV              |
| LLDT       | reg16                   | [m: 0f 00 /2]               | 286,PROT,PRIV              |
| LMSW       | mem                     | [m: 0f 01 /6]               | 286,PRIV                   |
| LMSW       | mem16                   | [m: 0f 01 /6]               | 286,PRIV                   |
| LMSW       | reg16                   | [m: 0f 01 /6]               | 286,PRIV                   |
| LOADALL    | void                    | [0f 07]                     | 386,UNDOC,ND,OBSOLETE      |
| LOADALL286 | void                    | [0f 05]                     | 286,UNDOC,ND,OBSOLETE      |
| LODSB      | void                    | [ac]                        | 8086                       |
| LODSD      | void                    | [o32 ad]                    | 386                        |
| LODSQ      | void                    | [o64 ad]                    | X64                        |
| LODSW      | void                    | [o16 ad]                    | 8086                       |
| LOOP       | imm                     | [i: adf e2 rel8]            | 8086                       |
| LOOP       | imm,reg_cx              | [i-: a16 e2 rel8]           | 8086,NOLONG                |
| LOOP       | imm,reg_ecx             | [i-: a32 e2 rel8]           | 386                        |
| LOOP       | imm,reg_rcx             | [i-: a64 e2 rel8]           | X64                        |
| LOOPE      | imm                     | [i: adf e1 rel8]            | 8086                       |
| LOOPE      | imm,reg_cx              | [i-: a16 e1 rel8]           | 8086,NOLONG                |
| LOOPE      | imm,reg_ecx             | [i-: a32 e1 rel8]           | 386                        |
| LOOPE      | imm,reg_rcx             | [i-: a64 e1 rel8]           | X64                        |
| LOOPNE     | imm                     | [i: adf e0 rel8]            | 8086                       |
| LOOPNE     | imm,reg_cx              | [i-: a16 e0 rel8]           | 8086,NOLONG                |
| LOOPNE     | imm,reg_ecx             | [i-: a32 e0 rel8]           | 386                        |
| LOOPNE     | imm,reg_rcx             | [i-: a64 e0 rel8]           | X64                        |
| LOOPNZ     | imm                     | [i: adf e0 rel8]            | 8086                       |
| LOOPNZ     | imm,reg_cx              | [i-: a16 e0 rel8]           | 8086,NOLONG                |
| LOOPNZ     | imm,reg_ecx             | [i-: a32 e0 rel8]           | 386                        |
| LOOPNZ     | imm,reg_rcx             | [i-: a64 e0 rel8]           | X64                        |
| LOOPZ      | imm                     | [i: adf e1 rel8]            | 8086                       |
| LOOPZ      | imm,reg_cx              | [i-: a16 e1 rel8]           | 8086,NOLONG                |
| LOOPZ      | imm,reg_ecx             | [i-: a32 e1 rel8]           | 386                        |
| LOOPZ      | imm,reg_rcx             | [i-: a64 e1 rel8]           | X64                        |
| LSL        | reg16,mem               | [rm: o16 0f 03 /r]          | 286,PROT,SW                |
| LSL        | reg16,reg16             | [rm: o16 0f 03 /r]          | 286,PROT                   |
| LSL        | reg16,reg32             | [rm: o16 0f 03 /r]          | 386,PROT                   |
| LSL        | reg16,reg64             | [rm: o16 o64nw 0f 03 /r]    | X64,PROT,ND                |
| LSL        | reg32,mem               | [rm: o32 0f 03 /r]          | 386,PROT,SW                |
| LSL        | reg32,reg16             | [rm: o32 0f 03 /r]          | 386,PROT                   |
| LSL        | reg32,reg32             | [rm: o32 0f 03 /r]          | 386,PROT                   |
| LSL        | reg32,reg64             | [rm: o32 o64nw 0f 03 /r]    | X64,PROT,ND                |
| LSL        | reg64,mem               | [rm: o64 0f 03 /r]          | X64,PROT,SW                |
| LSL        | reg64,reg16             | [rm: o64 0f 03 /r]          | X64,PROT                   |
| LSL        | reg64,reg32             | [rm: o64 0f 03 /r]          | X64,PROT                   |
| LSL        | reg64,reg64             | [rm: o64 0f 03 /r]          | X64,PROT                   |
| LSS        | reg16,mem               | [rm: o16 0f b2 /r]          | 386                        |
| LSS        | reg32,mem               | [rm: o32 0f b2 /r]          | 386                        |
| LSS        | reg64,mem               | [rm: o64 0f b2 /r]          | X64                        |
| LTR        | mem                     | [m: 0f 00 /3]               | 286,PROT,PRIV              |
| LTR        | mem16                   | [m: 0f 00 /3]               | 286,PROT,PRIV              |
| LTR        | reg16                   | [m: 0f 00 /3]               | 286,PROT,PRIV              |
| MFENCE     | void                    | [np 0f ae f0]               | X64,AMD                    |
| MONITOR    | void                    | [0f 01 c8]                  | PRESCOTT                   |
| MONITOR    | reg_eax,reg_ecx,reg_edx | [---: 0f 01 c8]             | NOLONG,ND                  |
| MONITOR    | reg_rax,reg_ecx,reg_edx | [---: 0f 01 c8]             | X64,ND                     |
| MONITORX   | void                    | [0f 01 fa]                  | AMD                        |
| MONITORX   | reg_rax,reg_ecx,reg_edx | [---: 0f 01 fa]             | X64,AMD,ND                 |
| MONITORX   | reg_eax,reg_ecx,reg_edx | [---: 0f 01 fa]             | AMD,ND                     |
| MONITORX   | reg_ax,reg_ecx,reg_edx  | [---: 0f 01 fa]             | AMD,ND                     |
| MOV        | mem,reg_sreg            | [mr: 8c /r]                 | 8086,SW                    |
| MOV        | reg16,reg_sreg          | [mr: o16 8c /r]             | 8086                       |
| MOV        | reg32,reg_sreg          | [mr: o32 8c /r]             | 386                        |
| MOV        | reg64,reg_sreg          | [mr: o64nw 8c /r]           | X64,OPT,ND                 |
| MOV        | rm64,reg_sreg           | [mr: o64 8c /r]             | X64                        |
| MOV        | reg_sreg,mem            | [rm: 8e /r]                 | 8086,SW                    |
| MOV        | reg_sreg,reg16          | [rm: 8e /r]                 | 8086,OPT,ND                |
| MOV        | reg_sreg,reg32          | [rm: 8e /r]                 | 386,OPT,ND                 |
| MOV        | reg_sreg,reg64          | [rm: o64nw 8e /r]           | X64,OPT,ND                 |
| MOV        | reg_sreg,reg16          | [rm: o16 8e /r]             | 8086                       |
| MOV        | reg_sreg,reg32          | [rm: o32 8e /r]             | 386                        |
| MOV        | reg_sreg,rm64           | [rm: o64 8e /r]             | X64                        |
| MOV        | reg_al,mem_offs         | [-i: a0 iwdq]               | 8086,SM                    |
| MOV        | reg_ax,mem_offs         | [-i: o16 a1 iwdq]           | 8086,SM                    |
| MOV        | reg_eax,mem_offs        | [-i: o32 a1 iwdq]           | 386,SM                     |
| MOV        | reg_rax,mem_offs        | [-i: o64 a1 iwdq]           | X64,SM                     |
| MOV        | mem_offs,reg_al         | [i-: a2 iwdq]               | 8086,SM,NOHLE              |
| MOV        | mem_offs,reg_ax         | [i-: o16 a3 iwdq]           | 8086,SM,NOHLE              |
| MOV        | mem_offs,reg_eax        | [i-: o32 a3 iwdq]           | 386,SM,NOHLE               |
| MOV        | mem_offs,reg_rax        | [i-: o64 a3 iwdq]           | X64,SM,NOHLE               |
| MOV        | reg32,reg_creg          | [mr: rex.l 0f 20 /r]        | 386,PRIV,NOLONG            |
| MOV        | reg64,reg_creg          | [mr: o64nw 0f 20 /r]        | X64,PRIV                   |
| MOV        | reg_creg,reg32          | [rm: rex.l 0f 22 /r]        | 386,PRIV,NOLONG            |
| MOV        | reg_creg,reg64          | [rm: o64nw 0f 22 /r]        | X64,PRIV                   |
| MOV        | reg32,reg_dreg          | [mr: 0f 21 /r]              | 386,PRIV,NOLONG            |
| MOV        | reg64,reg_dreg          | [mr: o64nw 0f 21 /r]        | X64,PRIV                   |
| MOV        | reg_dreg,reg32          | [rm: 0f 23 /r]              | 386,PRIV,NOLONG            |
| MOV        | reg_dreg,reg64          | [rm: o64nw 0f 23 /r]        | X64,PRIV                   |
| MOV        | reg32,reg_treg          | [mr: 0f 24 /r]              | 386,NOLONG,ND              |
| MOV        | reg_treg,reg32          | [rm: 0f 26 /r]              | 386,NOLONG,ND              |
| MOV        | mem,reg8                | [mr: hlexr 88 /r]           | 8086,SM                    |
| MOV        | reg8,reg8               | [mr: 88 /r]                 | 8086                       |
| MOV        | mem,reg16               | [mr: hlexr o16 89 /r]       | 8086,SM                    |
| MOV        | reg16,reg16             | [mr: o16 89 /r]             | 8086                       |
| MOV        | mem,reg32               | [mr: hlexr o32 89 /r]       | 386,SM                     |
| MOV        | reg32,reg32             | [mr: o32 89 /r]             | 386                        |
| MOV        | mem,reg64               | [mr: hlexr o64 89 /r]       | X64,SM                     |
| MOV        | reg64,reg64             | [mr: o64 89 /r]             | X64                        |
| MOV        | reg8,mem                | [rm: 8a /r]                 | 8086,SM                    |
| MOV        | reg8,reg8               | [rm: 8a /r]                 | 8086                       |
| MOV        | reg16,mem               | [rm: o16 8b /r]             | 8086,SM                    |
| MOV        | reg16,reg16             | [rm: o16 8b /r]             | 8086                       |
| MOV        | reg32,mem               | [rm: o32 8b /r]             | 386,SM                     |
| MOV        | reg32,reg32             | [rm: o32 8b /r]             | 386                        |
| MOV        | reg64,mem               | [rm: o64 8b /r]             | X64,SM                     |
| MOV        | reg64,reg64             | [rm: o64 8b /r]             | X64                        |
| MOV        | reg8,imm                | [ri: b0+r ib]               | 8086,SM                    |
| MOV        | reg16,imm               | [ri: o16 b8+r iw]           | 8086,SM                    |
| MOV        | reg32,imm               | [ri: o32 b8+r id]           | 386,SM                     |
| MOV        | reg64,udword            | [ri: o64nw b8+r id]         | X64,SM,OPT,ND              |
| MOV        | reg64,sdword            | [mi: o64 c7 /0 id,s]        | X64,SM,OPT,ND              |
| MOV        | reg64,imm               | [ri: o64 b8+r iq]           | X64,SM                     |
| MOV        | rm8,imm                 | [mi: hlexr c6 /0 ib]        | 8086,SM                    |
| MOV        | rm16,imm                | [mi: hlexr o16 c7 /0 iw]    | 8086,SM                    |
| MOV        | rm32,imm                | [mi: hlexr o32 c7 /0 id]    | 386,SM                     |
| MOV        | rm64,imm                | [mi: hlexr o64 c7 /0 id,s]  | X64,SM                     |
| MOV        | rm64,imm32              | [mi: hlexr o64 c7 /0 id,s]  | X64                        |
| MOV        | mem,imm8                | [mi: hlexr c6 /0 ib]        | 8086,SM                    |
| MOV        | mem,imm16               | [mi: hlexr o16 c7 /0 iw]    | 8086,SM                    |
| MOV        | mem,imm32               | [mi: hlexr o32 c7 /0 id]    | 386,SM                     |
| MOVD       | mmxreg,rm32             | [rm: np 0f 6e /r]           | PENT,MMX,SD                |
| MOVD       | rm32,mmxreg             | [mr: np 0f 7e /r]           | PENT,MMX,SD                |
| MOVD       | mmxreg,rm64             | [rm: np o64 0f 6e /r]       | X64,MMX,SX,ND              |
| MOVD       | rm64,mmxreg             | [mr: np o64 0f 7e /r]       | X64,MMX,SX,ND              |
| MOVQ       | mmxreg,mmxrm            | [rm: np 0f 6f /r]           | PENT,MMX,SQ                |
| MOVQ       | mmxrm,mmxreg            | [mr: np 0f 7f /r]           | PENT,MMX,SQ                |
| MOVQ       | mmxreg,rm64             | [rm: np o64 0f 6e /r]       | X64,MMX                    |
| MOVQ       | rm64,mmxreg             | [mr: np o64 0f 7e /r]       | X64,MMX                    |
| MOVSB      | void                    | [a4]                        | 8086                       |
| MOVSD      | void                    | [o32 a5]                    | 386                        |
| MOVSQ      | void                    | [o64 a5]                    | X64                        |
| MOVSW      | void                    | [o16 a5]                    | 8086                       |
| MOVSX      | reg16,mem               | [rm: o16 0f be /r]          | 386,SB                     |
| MOVSX      | reg16,reg8              | [rm: o16 0f be /r]          | 386                        |
| MOVSX      | reg32,rm8               | [rm: o32 0f be /r]          | 386                        |
| MOVSX      | reg32,rm16              | [rm: o32 0f bf /r]          | 386                        |
| MOVSX      | reg64,rm8               | [rm: o64 0f be /r]          | X64                        |
| MOVSX      | reg64,rm16              | [rm: o64 0f bf /r]          | X64                        |
| MOVSXD     | reg64,rm32              | [rm: o64 63 /r]             | X64                        |
| MOVSX      | reg64,rm32              | [rm: o64 63 /r]             | X64,ND                     |
| MOVZX      | reg16,mem               | [rm: o16 0f b6 /r]          | 386,SB                     |
| MOVZX      | reg16,reg8              | [rm: o16 0f b6 /r]          | 386                        |
| MOVZX      | reg32,rm8               | [rm: o32 0f b6 /r]          | 386                        |
| MOVZX      | reg32,rm16              | [rm: o32 0f b7 /r]          | 386                        |
| MOVZX      | reg64,rm8               | [rm: o64 0f b6 /r]          | X64                        |
| MOVZX      | reg64,rm16              | [rm: o64 0f b7 /r]          | X64                        |
| MUL        | rm8                     | [m: f6 /4]                  | 8086                       |
| MUL        | rm16                    | [m: o16 f7 /4]              | 8086                       |
| MUL        | rm32                    | [m: o32 f7 /4]              | 386                        |
| MUL        | rm64                    | [m: o64 f7 /4]              | X64                        |
| MWAIT      | void                    | [0f 01 c9]                  | PRESCOTT                   |
| MWAIT      | reg_eax,reg_ecx         | [--: 0f 01 c9]              | ND                         |
| MWAITX     | void                    | [0f 01 fb]                  | AMD                        |
| MWAITX     | reg_eax,reg_ecx         | [--: 0f 01 fb]              | AMD,ND                     |
| NEG        | rm8                     | [m: hle f6 /3]              | 8086,LOCK                  |
| NEG        | rm16                    | [m: hle o16 f7 /3]          | 8086,LOCK                  |
| NEG        | rm32                    | [m: hle o32 f7 /3]          | 386,LOCK                   |
| NEG        | rm64                    | [m: hle o64 f7 /3]          | X64,LOCK                   |
| NOP        | void                    | [norexb nof3 90]            | 8086                       |
| NOP        | rm16                    | [m: o16 0f 1f /0]           | P6                         |
| NOP        | rm32                    | [m: o32 0f 1f /0]           | P6                         |
| NOP        | rm64                    | [m: o64 0f 1f /0]           | X64                        |
| NOT        | rm8                     | [m: hle f6 /2]              | 8086,LOCK                  |
| NOT        | rm16                    | [m: hle o16 f7 /2]          | 8086,LOCK                  |
| NOT        | rm32                    | [m: hle o32 f7 /2]          | 386,LOCK                   |
| NOT        | rm64                    | [m: hle o64 f7 /2]          | X64,LOCK                   |
| OR         | mem,reg8                | [mr: hle 08 /r]             | 8086,SM,LOCK               |
| OR         | reg8,reg8               | [mr: 08 /r]                 | 8086                       |
| OR         | mem,reg16               | [mr: hle o16 09 /r]         | 8086,SM,LOCK               |
| OR         | reg16,reg16             | [mr: o16 09 /r]             | 8086                       |
| OR         | mem,reg32               | [mr: hle o32 09 /r]         | 386,SM,LOCK                |
| OR         | reg32,reg32             | [mr: o32 09 /r]             | 386                        |
| OR         | mem,reg64               | [mr: hle o64 09 /r]         | X64,SM,LOCK                |
| OR         | reg64,reg64             | [mr: o64 09 /r]             | X64                        |
| OR         | reg8,mem                | [rm: 0a /r]                 | 8086,SM                    |
| OR         | reg8,reg8               | [rm: 0a /r]                 | 8086                       |
| OR         | reg16,mem               | [rm: o16 0b /r]             | 8086,SM                    |
| OR         | reg16,reg16             | [rm: o16 0b /r]             | 8086                       |
| OR         | reg32,mem               | [rm: o32 0b /r]             | 386,SM                     |
| OR         | reg32,reg32             | [rm: o32 0b /r]             | 386                        |
| OR         | reg64,mem               | [rm: o64 0b /r]             | X64,SM                     |
| OR         | reg64,reg64             | [rm: o64 0b /r]             | X64                        |
| OR         | rm16,imm8               | [mi: hle o16 83 /1 ib,s]    | 8086,LOCK                  |
| OR         | rm32,imm8               | [mi: hle o32 83 /1 ib,s]    | 386,LOCK                   |
| OR         | rm64,imm8               | [mi: hle o64 83 /1 ib,s]    | X64,LOCK                   |
| OR         | reg_al,imm              | [-i: 0c ib]                 | 8086,SM                    |
| OR         | reg_ax,sbyteword        | [mi: o16 83 /1 ib,s]        | 8086,SM,ND                 |
| OR         | reg_ax,imm              | [-i: o16 0d iw]             | 8086,SM                    |
| OR         | reg_eax,sbytedword      | [mi: o32 83 /1 ib,s]        | 386,SM,ND                  |
| OR         | reg_eax,imm             | [-i: o32 0d id]             | 386,SM                     |
| OR         | reg_rax,sbytedword      | [mi: o64 83 /1 ib,s]        | X64,SM,ND                  |
| OR         | reg_rax,imm             | [-i: o64 0d id,s]           | X64,SM                     |
| OR         | rm8,imm                 | [mi: hle 80 /1 ib]          | 8086,SM,LOCK               |
| OR         | rm16,sbyteword          | [mi: hle o16 83 /1 ib,s]    | 8086,SM,LOCK,ND            |
| OR         | rm16,imm                | [mi: hle o16 81 /1 iw]      | 8086,SM,LOCK               |
| OR         | rm32,sbytedword         | [mi: hle o32 83 /1 ib,s]    | 386,SM,LOCK,ND             |
| OR         | rm32,imm                | [mi: hle o32 81 /1 id]      | 386,SM,LOCK                |
| OR         | rm64,sbytedword         | [mi: hle o64 83 /1 ib,s]    | X64,SM,LOCK,ND             |
| OR         | rm64,imm                | [mi: hle o64 81 /1 id,s]    | X64,SM,LOCK                |
| OR         | mem,imm8                | [mi: hle 80 /1 ib]          | 8086,SM,LOCK               |
| OR         | mem,sbyteword16         | [mi: hle o16 83 /1 ib,s]    | 8086,SM,LOCK,ND            |
| OR         | mem,imm16               | [mi: hle o16 81 /1 iw]      | 8086,SM,LOCK               |
| OR         | mem,sbytedword32        | [mi: hle o32 83 /1 ib,s]    | 386,SM,LOCK,ND             |
| OR         | mem,imm32               | [mi: hle o32 81 /1 id]      | 386,SM,LOCK                |
| OR         | rm8,imm                 | [mi: hle 82 /1 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| OUT        | imm,reg_al              | [i-: e6 ib,u]               | 8086,SB                    |
| OUT        | imm,reg_ax              | [i-: o16 e7 ib,u]           | 8086,SB                    |
| OUT        | imm,reg_eax             | [i-: o32 e7 ib,u]           | 386,SB                     |
| OUT        | reg_dx,reg_al           | [--: ee]                    | 8086                       |
| OUT        | reg_dx,reg_ax           | [--: o16 ef]                | 8086                       |
| OUT        | reg_dx,reg_eax          | [--: o32 ef]                | 386                        |
| OUTSB      | void                    | [6e]                        | 186                        |
| OUTSD      | void                    | [o32 6f]                    | 386                        |
| OUTSW      | void                    | [o16 6f]                    | 186                        |
| PACKSSDW   | mmxreg,mmxrm            | [rm: np o64nw 0f 6b /r]     | PENT,MMX,SQ                |
| PACKSSWB   | mmxreg,mmxrm            | [rm: np o64nw 0f 63 /r]     | PENT,MMX,SQ                |
| PACKUSWB   | mmxreg,mmxrm            | [rm: np o64nw 0f 67 /r]     | PENT,MMX,SQ                |
| PADDB      | mmxreg,mmxrm            | [rm: np o64nw 0f fc /r]     | PENT,MMX,SQ                |
| PADDD      | mmxreg,mmxrm            | [rm: np o64nw 0f fe /r]     | PENT,MMX,SQ                |
| PADDSB     | mmxreg,mmxrm            | [rm: np o64nw 0f ec /r]     | PENT,MMX,SQ                |
| PADDSIW    | mmxreg,mmxrm            | [rm: o64nw 0f 51 /r]        | PENT,MMX,SQ,CYRIX          |
| PADDSW     | mmxreg,mmxrm            | [rm: np o64nw 0f ed /r]     | PENT,MMX,SQ                |
| PADDUSB    | mmxreg,mmxrm            | [rm: np o64nw 0f dc /r]     | PENT,MMX,SQ                |
| PADDUSW    | mmxreg,mmxrm            | [rm: np o64nw 0f dd /r]     | PENT,MMX,SQ                |
| PADDW      | mmxreg,mmxrm            | [rm: np o64nw 0f fd /r]     | PENT,MMX,SQ                |
| PAND       | mmxreg,mmxrm            | [rm: np o64nw 0f db /r]     | PENT,MMX,SQ                |
| PANDN      | mmxreg,mmxrm            | [rm: np o64nw 0f df /r]     | PENT,MMX,SQ                |
| PAUSE      | void                    | [f3i 90]                    | 8086                       |
| PAVEB      | mmxreg,mmxrm            | [rm: o64nw 0f 50 /r]        | PENT,MMX,SQ,CYRIX          |
| PAVGUSB    | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r bf]     | PENT,3DNOW,SQ              |
| PCMPEQB    | mmxreg,mmxrm            | [rm: np o64nw 0f 74 /r]     | PENT,MMX,SQ                |
| PCMPEQD    | mmxreg,mmxrm            | [rm: np o64nw 0f 76 /r]     | PENT,MMX,SQ                |
| PCMPEQW    | mmxreg,mmxrm            | [rm: np o64nw 0f 75 /r]     | PENT,MMX,SQ                |
| PCMPGTB    | mmxreg,mmxrm            | [rm: np o64nw 0f 64 /r]     | PENT,MMX,SQ                |
| PCMPGTD    | mmxreg,mmxrm            | [rm: np o64nw 0f 66 /r]     | PENT,MMX,SQ                |
| PCMPGTW    | mmxreg,mmxrm            | [rm: np o64nw 0f 65 /r]     | PENT,MMX,SQ                |
| PDISTIB    | mmxreg,mem              | [rm: 0f 54 /r]              | PENT,MMX,SM,CYRIX          |
| PF2ID      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 1d]     | PENT,3DNOW,SQ              |
| PFACC      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r ae]     | PENT,3DNOW,SQ              |
| PFADD      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 9e]     | PENT,3DNOW,SQ              |
| PFCMPEQ    | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r b0]     | PENT,3DNOW,SQ              |
| PFCMPGE    | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 90]     | PENT,3DNOW,SQ              |
| PFCMPGT    | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r a0]     | PENT,3DNOW,SQ              |
| PFMAX      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r a4]     | PENT,3DNOW,SQ              |
| PFMIN      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 94]     | PENT,3DNOW,SQ              |
| PFMUL      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r b4]     | PENT,3DNOW,SQ              |
| PFRCP      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 96]     | PENT,3DNOW,SQ              |
| PFRCPIT1   | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r a6]     | PENT,3DNOW,SQ              |
| PFRCPIT2   | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r b6]     | PENT,3DNOW,SQ              |
| PFRSQIT1   | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r a7]     | PENT,3DNOW,SQ              |
| PFRSQRT    | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 97]     | PENT,3DNOW,SQ              |
| PFSUB      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 9a]     | PENT,3DNOW,SQ              |
| PFSUBR     | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r aa]     | PENT,3DNOW,SQ              |
| PI2FD      | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r 0d]     | PENT,3DNOW,SQ              |
| PMACHRIW   | mmxreg,mem              | [rm: 0f 5e /r]              | PENT,MMX,SM,CYRIX          |
| PMADDWD    | mmxreg,mmxrm            | [rm: np o64nw 0f f5 /r]     | PENT,MMX,SQ                |
| PMAGW      | mmxreg,mmxrm            | [rm: o64nw 0f 52 /r]        | PENT,MMX,SQ,CYRIX          |
| PMULHRIW   | mmxreg,mmxrm            | [rm: o64nw 0f 5d /r]        | PENT,MMX,SQ,CYRIX          |
| PMULHRWA   | mmxreg,mmxrm            | [rm: o64nw 0f 0f /r b7]     | PENT,3DNOW,SQ              |
| PMULHRWC   | mmxreg,mmxrm            | [rm: o64nw 0f 59 /r]        | PENT,MMX,SQ,CYRIX          |
| PMULHW     | mmxreg,mmxrm            | [rm: np o64nw 0f e5 /r]     | PENT,MMX,SQ                |
| PMULLW     | mmxreg,mmxrm            | [rm: np o64nw 0f d5 /r]     | PENT,MMX,SQ                |
| PMVGEZB    | mmxreg,mem              | [rm: 0f 5c /r]              | PENT,MMX,SQ,CYRIX          |
| PMVLZB     | mmxreg,mem              | [rm: 0f 5b /r]              | PENT,MMX,SQ,CYRIX          |
| PMVNZB     | mmxreg,mem              | [rm: 0f 5a /r]              | PENT,MMX,SQ,CYRIX          |
| PMVZB      | mmxreg,mem              | [rm: 0f 58 /r]              | PENT,MMX,SQ,CYRIX          |
| POP        | reg16                   | [r: o16 58+r]               | 8086                       |
| POP        | reg32                   | [r: o32 58+r]               | 386,NOLONG                 |
| POP        | reg64                   | [r: o64nw 58+r]             | X64                        |
| POP        | rm16                    | [m: o16 8f /0]              | 8086                       |
| POP        | rm32                    | [m: o32 8f /0]              | 386,NOLONG                 |
| POP        | rm64                    | [m: o64nw 8f /0]            | X64                        |
| POP        | reg_es                  | [-: 07]                     | 8086,NOLONG                |
| POP        | reg_cs                  | [-: 0f]                     | 8086,UNDOC,ND,OBSOLETE     |
| POP        | reg_ss                  | [-: 17]                     | 8086,NOLONG                |
| POP        | reg_ds                  | [-: 1f]                     | 8086,NOLONG                |
| POP        | reg_fs                  | [-: 0f a1]                  | 386                        |
| POP        | reg_gs                  | [-: 0f a9]                  | 386                        |
| POPA       | void                    | [odf 61]                    | 186,NOLONG                 |
| POPAD      | void                    | [o32 61]                    | 386,NOLONG                 |
| POPAW      | void                    | [o16 61]                    | 186,NOLONG                 |
| POPF       | void                    | [odf 9d]                    | 8086                       |
| POPFD      | void                    | [o32 9d]                    | 386,NOLONG                 |
| POPFQ      | void                    | [o32 9d]                    | X64                        |
| POPFW      | void                    | [o16 9d]                    | 8086                       |
| POR        | mmxreg,mmxrm            | [rm: np o64nw 0f eb /r]     | PENT,MMX,SQ                |
| PREFETCH   | mem                     | [m: 0f 0d /0]               | PENT,3DNOW,SQ              |
| PREFETCHW  | mem                     | [m: 0f 0d /1]               | PENT,3DNOW,SQ              |
| PSLLD      | mmxreg,mmxrm            | [rm: np o64nw 0f f2 /r]     | PENT,MMX,SQ                |
| PSLLD      | mmxreg,imm              | [mi: np 0f 72 /6 ib,u]      | PENT,MMX                   |
| PSLLQ      | mmxreg,mmxrm            | [rm: np o64nw 0f f3 /r]     | PENT,MMX,SQ                |
| PSLLQ      | mmxreg,imm              | [mi: np 0f 73 /6 ib,u]      | PENT,MMX                   |
| PSLLW      | mmxreg,mmxrm            | [rm: np o64nw 0f f1 /r]     | PENT,MMX,SQ                |
| PSLLW      | mmxreg,imm              | [mi: np 0f 71 /6 ib,u]      | PENT,MMX                   |
| PSRAD      | mmxreg,mmxrm            | [rm: np o64nw 0f e2 /r]     | PENT,MMX,SQ                |
| PSRAD      | mmxreg,imm              | [mi: np 0f 72 /4 ib,u]      | PENT,MMX                   |
| PSRAW      | mmxreg,mmxrm            | [rm: np o64nw 0f e1 /r]     | PENT,MMX,SQ                |
| PSRAW      | mmxreg,imm              | [mi: np 0f 71 /4 ib,u]      | PENT,MMX                   |
| PSRLD      | mmxreg,mmxrm            | [rm: np o64nw 0f d2 /r]     | PENT,MMX,SQ                |
| PSRLD      | mmxreg,imm              | [mi: np 0f 72 /2 ib,u]      | PENT,MMX                   |
| PSRLQ      | mmxreg,mmxrm            | [rm: np o64nw 0f d3 /r]     | PENT,MMX,SQ                |
| PSRLQ      | mmxreg,imm              | [mi: np 0f 73 /2 ib,u]      | PENT,MMX                   |
| PSRLW      | mmxreg,mmxrm            | [rm: np o64nw 0f d1 /r]     | PENT,MMX,SQ                |
| PSRLW      | mmxreg,imm              | [mi: np 0f 71 /2 ib,u]      | PENT,MMX                   |
| PSUBB      | mmxreg,mmxrm            | [rm: np o64nw 0f f8 /r]     | PENT,MMX,SQ                |
| PSUBD      | mmxreg,mmxrm            | [rm: np o64nw 0f fa /r]     | PENT,MMX,SQ                |
| PSUBSB     | mmxreg,mmxrm            | [rm: np o64nw 0f e8 /r]     | PENT,MMX,SQ                |
| PSUBSIW    | mmxreg,mmxrm            | [rm: o64nw 0f 55 /r]        | PENT,MMX,SQ,CYRIX          |
| PSUBSW     | mmxreg,mmxrm            | [rm: np o64nw 0f e9 /r]     | PENT,MMX,SQ                |
| PSUBUSB    | mmxreg,mmxrm            | [rm: np o64nw 0f d8 /r]     | PENT,MMX,SQ                |
| PSUBUSW    | mmxreg,mmxrm            | [rm: np o64nw 0f d9 /r]     | PENT,MMX,SQ                |
| PSUBW      | mmxreg,mmxrm            | [rm: np o64nw 0f f9 /r]     | PENT,MMX,SQ                |
| PUNPCKHBW  | mmxreg,mmxrm            | [rm: np o64nw 0f 68 /r]     | PENT,MMX,SQ                |
| PUNPCKHDQ  | mmxreg,mmxrm            | [rm: np o64nw 0f 6a /r]     | PENT,MMX,SQ                |
| PUNPCKHWD  | mmxreg,mmxrm            | [rm: np o64nw 0f 69 /r]     | PENT,MMX,SQ                |
| PUNPCKLBW  | mmxreg,mmxrm            | [rm: np o64nw 0f 60 /r]     | PENT,MMX,SQ                |
| PUNPCKLDQ  | mmxreg,mmxrm            | [rm: np o64nw 0f 62 /r]     | PENT,MMX,SQ                |
| PUNPCKLWD  | mmxreg,mmxrm            | [rm: np o64nw 0f 61 /r]     | PENT,MMX,SQ                |
| PUSH       | reg16                   | [r: o16 50+r]               | 8086                       |
| PUSH       | reg32                   | [r: o32 50+r]               | 386,NOLONG                 |
| PUSH       | reg64                   | [r: o64nw 50+r]             | X64                        |
| PUSH       | rm16                    | [m: o16 ff /6]              | 8086                       |
| PUSH       | rm32                    | [m: o32 ff /6]              | 386,NOLONG                 |
| PUSH       | rm64                    | [m: o64nw ff /6]            | X64                        |
| PUSH       | reg_es                  | [-: 06]                     | 8086,NOLONG                |
| PUSH       | reg_cs                  | [-: 0e]                     | 8086,NOLONG                |
| PUSH       | reg_ss                  | [-: 16]                     | 8086,NOLONG                |
| PUSH       | reg_ds                  | [-: 1e]                     | 8086,NOLONG                |
| PUSH       | reg_fs                  | [-: 0f a0]                  | 386                        |
| PUSH       | reg_gs                  | [-: 0f a8]                  | 386                        |
| PUSH       | imm8                    | [i: 6a ib,s]                | 186                        |
| PUSH       | sbyteword16             | [i: o16 6a ib,s]            | 186,AR0,SIZE,ND            |
| PUSH       | imm16                   | [i: o16 68 iw]              | 186,AR0,SIZE               |
| PUSH       | sbytedword32            | [i: o32 6a ib,s]            | 386,NOLONG,AR0,SIZE,ND     |
| PUSH       | imm32                   | [i: o32 68 id]              | 386,NOLONG,AR0,SIZE        |
| PUSH       | sbytedword32            | [i: o32 6a ib,s]            | 386,NOLONG,SD,ND           |
| PUSH       | imm32                   | [i: o32 68 id]              | 386,NOLONG,SD              |
| PUSH       | sbytedword64            | [i: o64nw 6a ib,s]          | X64,AR0,SIZE,ND            |
| PUSH       | imm64                   | [i: o64nw 68 id,s]          | X64,AR0,SIZE               |
| PUSH       | sbytedword32            | [i: o64nw 6a ib,s]          | X64,AR0,SIZE,ND            |
| PUSH       | imm32                   | [i: o64nw 68 id,s]          | X64,AR0,SIZE               |
| PUSHA      | void                    | [odf 60]                    | 186,NOLONG                 |
| PUSHAD     | void                    | [o32 60]                    | 386,NOLONG                 |
| PUSHAW     | void                    | [o16 60]                    | 186,NOLONG                 |
| PUSHF      | void                    | [odf 9c]                    | 8086                       |
| PUSHFD     | void                    | [o32 9c]                    | 386,NOLONG                 |
| PUSHFQ     | void                    | [o32 9c]                    | X64                        |
| PUSHFW     | void                    | [o16 9c]                    | 8086                       |
| PXOR       | mmxreg,mmxrm            | [rm: np o64nw 0f ef /r]     | PENT,MMX,SQ                |
| RCL        | rm8,unity               | [m-: d0 /2]                 | 8086                       |
| RCL        | rm8,reg_cl              | [m-: d2 /2]                 | 8086                       |
| RCL        | rm8,imm8                | [mi: c0 /2 ib,u]            | 186                        |
| RCL        | rm16,unity              | [m-: o16 d1 /2]             | 8086                       |
| RCL        | rm16,reg_cl             | [m-: o16 d3 /2]             | 8086                       |
| RCL        | rm16,imm8               | [mi: o16 c1 /2 ib,u]        | 186                        |
| RCL        | rm32,unity              | [m-: o32 d1 /2]             | 386                        |
| RCL        | rm32,reg_cl             | [m-: o32 d3 /2]             | 386                        |
| RCL        | rm32,imm8               | [mi: o32 c1 /2 ib,u]        | 386                        |
| RCL        | rm64,unity              | [m-: o64 d1 /2]             | X64                        |
| RCL        | rm64,reg_cl             | [m-: o64 d3 /2]             | X64                        |
| RCL        | rm64,imm8               | [mi: o64 c1 /2 ib,u]        | X64                        |
| RCR        | rm8,unity               | [m-: d0 /3]                 | 8086                       |
| RCR        | rm8,reg_cl              | [m-: d2 /3]                 | 8086                       |
| RCR        | rm8,imm8                | [mi: c0 /3 ib,u]            | 186                        |
| RCR        | rm16,unity              | [m-: o16 d1 /3]             | 8086                       |
| RCR        | rm16,reg_cl             | [m-: o16 d3 /3]             | 8086                       |
| RCR        | rm16,imm8               | [mi: o16 c1 /3 ib,u]        | 186                        |
| RCR        | rm32,unity              | [m-: o32 d1 /3]             | 386                        |
| RCR        | rm32,reg_cl             | [m-: o32 d3 /3]             | 386                        |
| RCR        | rm32,imm8               | [mi: o32 c1 /3 ib,u]        | 386                        |
| RCR        | rm64,unity              | [m-: o64 d1 /3]             | X64                        |
| RCR        | rm64,reg_cl             | [m-: o64 d3 /3]             | X64                        |
| RCR        | rm64,imm8               | [mi: o64 c1 /3 ib,u]        | X64                        |
| RDSHR      | rm32                    | [m: o32 0f 36 /0]           | P6,CYRIX,SMM               |
| RDMSR      | void                    | [0f 32]                     | PENT,PRIV                  |
| RDPMC      | void                    | [0f 33]                     | P6                         |
| RDTSC      | void                    | [0f 31]                     | PENT                       |
| RDTSCP     | void                    | [0f 01 f9]                  | X86_64                     |
| RET        | void                    | [c3]                        | 8086,BND                   |
| RET        | imm                     | [i: c2 iw]                  | 8086,SW,BND                |
| RETF       | void                    | [cb]                        | 8086                       |
| RETF       | imm                     | [i: ca iw]                  | 8086,SW                    |
| RETN       | void                    | [c3]                        | 8086,BND                   |
| RETN       | imm                     | [i: c2 iw]                  | 8086,SW,BND                |
| RETW       | void                    | [o16 c3]                    | 8086,BND                   |
| RETW       | imm                     | [i: c2 iw]                  | 8086,SW,BND                |
| RETFW      | void                    | [o16 cb]                    | 8086                       |
| RETFW      | imm                     | [i: o16 ca iw]              | 8086,SW                    |
| RETNW      | void                    | [o16 c3]                    | 8086,BND                   |
| RETNW      | imm                     | [i: o16 c2 iw]              | 8086,SW,BND                |
| RETD       | void                    | [o32 c3]                    | 8086,BND,NOLONG            |
| RETD       | imm                     | [i: o32 c2 iw]              | 8086,SW,BND,NOLONG         |
| RETFD      | void                    | [o32 cb]                    | 8086                       |
| RETFD      | imm                     | [i: o32 ca iw]              | 8086,SW                    |
| RETND      | void                    | [o32 c3]                    | 8086,BND,NOLONG            |
| RETND      | imm                     | [i: o32 c2 iw]              | 8086,SW,BND,NOLONG         |
| RETQ       | void                    | [o64nw c3]                  | X64,BND                    |
| RETQ       | imm                     | [i: o64nw c2 iw]            | X64,SW,BND                 |
| RETFQ      | void                    | [o64 cb]                    | X64                        |
| RETFQ      | imm                     | [i: o64 ca iw]              | X64,SW                     |
| RETNQ      | void                    | [o64nw c3]                  | X64,BND                    |
| RETNQ      | imm                     | [i: o64nw c2 iw]            | X64,SW,BND                 |
| ROL        | rm8,unity               | [m-: d0 /0]                 | 8086                       |
| ROL        | rm8,reg_cl              | [m-: d2 /0]                 | 8086                       |
| ROL        | rm8,imm8                | [mi: c0 /0 ib,u]            | 186                        |
| ROL        | rm16,unity              | [m-: o16 d1 /0]             | 8086                       |
| ROL        | rm16,reg_cl             | [m-: o16 d3 /0]             | 8086                       |
| ROL        | rm16,imm8               | [mi: o16 c1 /0 ib,u]        | 186                        |
| ROL        | rm32,unity              | [m-: o32 d1 /0]             | 386                        |
| ROL        | rm32,reg_cl             | [m-: o32 d3 /0]             | 386                        |
| ROL        | rm32,imm8               | [mi: o32 c1 /0 ib,u]        | 386                        |
| ROL        | rm64,unity              | [m-: o64 d1 /0]             | X64                        |
| ROL        | rm64,reg_cl             | [m-: o64 d3 /0]             | X64                        |
| ROL        | rm64,imm8               | [mi: o64 c1 /0 ib,u]        | X64                        |
| ROR        | rm8,unity               | [m-: d0 /1]                 | 8086                       |
| ROR        | rm8,reg_cl              | [m-: d2 /1]                 | 8086                       |
| ROR        | rm8,imm8                | [mi: c0 /1 ib,u]            | 186                        |
| ROR        | rm16,unity              | [m-: o16 d1 /1]             | 8086                       |
| ROR        | rm16,reg_cl             | [m-: o16 d3 /1]             | 8086                       |
| ROR        | rm16,imm8               | [mi: o16 c1 /1 ib,u]        | 186                        |
| ROR        | rm32,unity              | [m-: o32 d1 /1]             | 386                        |
| ROR        | rm32,reg_cl             | [m-: o32 d3 /1]             | 386                        |
| ROR        | rm32,imm8               | [mi: o32 c1 /1 ib,u]        | 386                        |
| ROR        | rm64,unity              | [m-: o64 d1 /1]             | X64                        |
| ROR        | rm64,reg_cl             | [m-: o64 d3 /1]             | X64                        |
| ROR        | rm64,imm8               | [mi: o64 c1 /1 ib,u]        | X64                        |
| RDM        | void                    | [0f 3a]                     | P6,CYRIX,ND                |
| RSDC       | reg_sreg,mem80          | [rm: 0f 79 /r]              | 486,CYRIX,SMM              |
| RSLDT      | mem80                   | [m: 0f 7b /0]               | 486,CYRIX,SMM              |
| RSM        | void                    | [0f aa]                     | PENT,SMM                   |
| RSTS       | mem80                   | [m: 0f 7d /0]               | 486,CYRIX,SMM              |
| SAHF       | void                    | [9e]                        | 8086                       |
| SAL        | rm8,unity               | [m-: d0 /4]                 | 8086,ND                    |
| SAL        | rm8,reg_cl              | [m-: d2 /4]                 | 8086,ND                    |
| SAL        | rm8,imm8                | [mi: c0 /4 ib,u]            | 186,ND                     |
| SAL        | rm16,unity              | [m-: o16 d1 /4]             | 8086,ND                    |
| SAL        | rm16,reg_cl             | [m-: o16 d3 /4]             | 8086,ND                    |
| SAL        | rm16,imm8               | [mi: o16 c1 /4 ib,u]        | 186,ND                     |
| SAL        | rm32,unity              | [m-: o32 d1 /4]             | 386,ND                     |
| SAL        | rm32,reg_cl             | [m-: o32 d3 /4]             | 386,ND                     |
| SAL        | rm32,imm8               | [mi: o32 c1 /4 ib,u]        | 386,ND                     |
| SAL        | rm64,unity              | [m-: o64 d1 /4]             | X64,ND                     |
| SAL        | rm64,reg_cl             | [m-: o64 d3 /4]             | X64,ND                     |
| SAL        | rm64,imm8               | [mi: o64 c1 /4 ib,u]        | X64,ND                     |
| SALC       | void                    | [d6]                        | 8086,UNDOC                 |
| SAR        | rm8,unity               | [m-: d0 /7]                 | 8086                       |
| SAR        | rm8,reg_cl              | [m-: d2 /7]                 | 8086                       |
| SAR        | rm8,imm8                | [mi: c0 /7 ib,u]            | 186                        |
| SAR        | rm16,unity              | [m-: o16 d1 /7]             | 8086                       |
| SAR        | rm16,reg_cl             | [m-: o16 d3 /7]             | 8086                       |
| SAR        | rm16,imm8               | [mi: o16 c1 /7 ib,u]        | 186                        |
| SAR        | rm32,unity              | [m-: o32 d1 /7]             | 386                        |
| SAR        | rm32,reg_cl             | [m-: o32 d3 /7]             | 386                        |
| SAR        | rm32,imm8               | [mi: o32 c1 /7 ib,u]        | 386                        |
| SAR        | rm64,unity              | [m-: o64 d1 /7]             | X64                        |
| SAR        | rm64,reg_cl             | [m-: o64 d3 /7]             | X64                        |
| SAR        | rm64,imm8               | [mi: o64 c1 /7 ib,u]        | X64                        |
| SBB        | mem,reg8                | [mr: hle 18 /r]             | 8086,SM,LOCK               |
| SBB        | reg8,reg8               | [mr: 18 /r]                 | 8086                       |
| SBB        | mem,reg16               | [mr: hle o16 19 /r]         | 8086,SM,LOCK               |
| SBB        | reg16,reg16             | [mr: o16 19 /r]             | 8086                       |
| SBB        | mem,reg32               | [mr: hle o32 19 /r]         | 386,SM,LOCK                |
| SBB        | reg32,reg32             | [mr: o32 19 /r]             | 386                        |
| SBB        | mem,reg64               | [mr: hle o64 19 /r]         | X64,SM,LOCK                |
| SBB        | reg64,reg64             | [mr: o64 19 /r]             | X64                        |
| SBB        | reg8,mem                | [rm: 1a /r]                 | 8086,SM                    |
| SBB        | reg8,reg8               | [rm: 1a /r]                 | 8086                       |
| SBB        | reg16,mem               | [rm: o16 1b /r]             | 8086,SM                    |
| SBB        | reg16,reg16             | [rm: o16 1b /r]             | 8086                       |
| SBB        | reg32,mem               | [rm: o32 1b /r]             | 386,SM                     |
| SBB        | reg32,reg32             | [rm: o32 1b /r]             | 386                        |
| SBB        | reg64,mem               | [rm: o64 1b /r]             | X64,SM                     |
| SBB        | reg64,reg64             | [rm: o64 1b /r]             | X64                        |
| SBB        | rm16,imm8               | [mi: hle o16 83 /3 ib,s]    | 8086,LOCK                  |
| SBB        | rm32,imm8               | [mi: hle o32 83 /3 ib,s]    | 386,LOCK                   |
| SBB        | rm64,imm8               | [mi: hle o64 83 /3 ib,s]    | X64,LOCK                   |
| SBB        | reg_al,imm              | [-i: 1c ib]                 | 8086,SM                    |
| SBB        | reg_ax,sbyteword        | [mi: o16 83 /3 ib,s]        | 8086,SM,ND                 |
| SBB        | reg_ax,imm              | [-i: o16 1d iw]             | 8086,SM                    |
| SBB        | reg_eax,sbytedword      | [mi: o32 83 /3 ib,s]        | 386,SM,ND                  |
| SBB        | reg_eax,imm             | [-i: o32 1d id]             | 386,SM                     |
| SBB        | reg_rax,sbytedword      | [mi: o64 83 /3 ib,s]        | X64,SM,ND                  |
| SBB        | reg_rax,imm             | [-i: o64 1d id,s]           | X64,SM                     |
| SBB        | rm8,imm                 | [mi: hle 80 /3 ib]          | 8086,SM,LOCK               |
| SBB        | rm16,sbyteword          | [mi: hle o16 83 /3 ib,s]    | 8086,SM,LOCK,ND            |
| SBB        | rm16,imm                | [mi: hle o16 81 /3 iw]      | 8086,SM,LOCK               |
| SBB        | rm32,sbytedword         | [mi: hle o32 83 /3 ib,s]    | 386,SM,LOCK,ND             |
| SBB        | rm32,imm                | [mi: hle o32 81 /3 id]      | 386,SM,LOCK                |
| SBB        | rm64,sbytedword         | [mi: hle o64 83 /3 ib,s]    | X64,SM,LOCK,ND             |
| SBB        | rm64,imm                | [mi: hle o64 81 /3 id,s]    | X64,SM,LOCK                |
| SBB        | mem,imm8                | [mi: hle 80 /3 ib]          | 8086,SM,LOCK               |
| SBB        | mem,sbyteword16         | [mi: hle o16 83 /3 ib,s]    | 8086,SM,LOCK,ND            |
| SBB        | mem,imm16               | [mi: hle o16 81 /3 iw]      | 8086,SM,LOCK               |
| SBB        | mem,sbytedword32        | [mi: hle o32 83 /3 ib,s]    | 386,SM,LOCK,ND             |
| SBB        | mem,imm32               | [mi: hle o32 81 /3 id]      | 386,SM,LOCK                |
| SBB        | rm8,imm                 | [mi: hle 82 /3 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| SCASB      | void                    | [repe ae]                   | 8086                       |
| SCASD      | void                    | [repe o32 af]               | 386                        |
| SCASQ      | void                    | [repe o64 af]               | X64                        |
| SCASW      | void                    | [repe o16 af]               | 8086                       |
| SFENCE     | void                    | [np 0f ae f8]               | X64,AMD                    |
| SGDT       | mem                     | [m: 0f 01 /0]               | 286                        |
| SHL        | rm8,unity               | [m-: d0 /4]                 | 8086                       |
| SHL        | rm8,reg_cl              | [m-: d2 /4]                 | 8086                       |
| SHL        | rm8,imm8                | [mi: c0 /4 ib,u]            | 186                        |
| SHL        | rm16,unity              | [m-: o16 d1 /4]             | 8086                       |
| SHL        | rm16,reg_cl             | [m-: o16 d3 /4]             | 8086                       |
| SHL        | rm16,imm8               | [mi: o16 c1 /4 ib,u]        | 186                        |
| SHL        | rm32,unity              | [m-: o32 d1 /4]             | 386                        |
| SHL        | rm32,reg_cl             | [m-: o32 d3 /4]             | 386                        |
| SHL        | rm32,imm8               | [mi: o32 c1 /4 ib,u]        | 386                        |
| SHL        | rm64,unity              | [m-: o64 d1 /4]             | X64                        |
| SHL        | rm64,reg_cl             | [m-: o64 d3 /4]             | X64                        |
| SHL        | rm64,imm8               | [mi: o64 c1 /4 ib,u]        | X64                        |
| SHLD       | mem,reg16,imm           | [mri: o16 0f a4 /r ib,u]    | 386,SM2,SB,AR2             |
| SHLD       | reg16,reg16,imm         | [mri: o16 0f a4 /r ib,u]    | 386,SM2,SB,AR2             |
| SHLD       | mem,reg32,imm           | [mri: o32 0f a4 /r ib,u]    | 386,SM2,SB,AR2             |
| SHLD       | reg32,reg32,imm         | [mri: o32 0f a4 /r ib,u]    | 386,SM2,SB,AR2             |
| SHLD       | mem,reg64,imm           | [mri: o64 0f a4 /r ib,u]    | X64,SM2,SB,AR2             |
| SHLD       | reg64,reg64,imm         | [mri: o64 0f a4 /r ib,u]    | X64,SM2,SB,AR2             |
| SHLD       | mem,reg16,reg_cl        | [mr-: o16 0f a5 /r]         | 386,SM                     |
| SHLD       | reg16,reg16,reg_cl      | [mr-: o16 0f a5 /r]         | 386                        |
| SHLD       | mem,reg32,reg_cl        | [mr-: o32 0f a5 /r]         | 386,SM                     |
| SHLD       | reg32,reg32,reg_cl      | [mr-: o32 0f a5 /r]         | 386                        |
| SHLD       | mem,reg64,reg_cl        | [mr-: o64 0f a5 /r]         | X64,SM                     |
| SHLD       | reg64,reg64,reg_cl      | [mr-: o64 0f a5 /r]         | X64                        |
| SHR        | rm8,unity               | [m-: d0 /5]                 | 8086                       |
| SHR        | rm8,reg_cl              | [m-: d2 /5]                 | 8086                       |
| SHR        | rm8,imm8                | [mi: c0 /5 ib,u]            | 186                        |
| SHR        | rm16,unity              | [m-: o16 d1 /5]             | 8086                       |
| SHR        | rm16,reg_cl             | [m-: o16 d3 /5]             | 8086                       |
| SHR        | rm16,imm8               | [mi: o16 c1 /5 ib,u]        | 186                        |
| SHR        | rm32,unity              | [m-: o32 d1 /5]             | 386                        |
| SHR        | rm32,reg_cl             | [m-: o32 d3 /5]             | 386                        |
| SHR        | rm32,imm8               | [mi: o32 c1 /5 ib,u]        | 386                        |
| SHR        | rm64,unity              | [m-: o64 d1 /5]             | X64                        |
| SHR        | rm64,reg_cl             | [m-: o64 d3 /5]             | X64                        |
| SHR        | rm64,imm8               | [mi: o64 c1 /5 ib,u]        | X64                        |
| SHRD       | mem,reg16,imm           | [mri: o16 0f ac /r ib,u]    | 386,SM2,SB,AR2             |
| SHRD       | reg16,reg16,imm         | [mri: o16 0f ac /r ib,u]    | 386,SM2,SB,AR2             |
| SHRD       | mem,reg32,imm           | [mri: o32 0f ac /r ib,u]    | 386,SM2,SB,AR2             |
| SHRD       | reg32,reg32,imm         | [mri: o32 0f ac /r ib,u]    | 386,SM2,SB,AR2             |
| SHRD       | mem,reg64,imm           | [mri: o64 0f ac /r ib,u]    | X64,SM2,SB,AR2             |
| SHRD       | reg64,reg64,imm         | [mri: o64 0f ac /r ib,u]    | X64,SM2,SB,AR2             |
| SHRD       | mem,reg16,reg_cl        | [mr-: o16 0f ad /r]         | 386,SM                     |
| SHRD       | reg16,reg16,reg_cl      | [mr-: o16 0f ad /r]         | 386                        |
| SHRD       | mem,reg32,reg_cl        | [mr-: o32 0f ad /r]         | 386,SM                     |
| SHRD       | reg32,reg32,reg_cl      | [mr-: o32 0f ad /r]         | 386                        |
| SHRD       | mem,reg64,reg_cl        | [mr-: o64 0f ad /r]         | X64,SM                     |
| SHRD       | reg64,reg64,reg_cl      | [mr-: o64 0f ad /r]         | X64                        |
| SIDT       | mem                     | [m: 0f 01 /1]               | 286                        |
| SLDT       | mem                     | [m: 0f 00 /0]               | 286                        |
| SLDT       | mem16                   | [m: 0f 00 /0]               | 286                        |
| SLDT       | reg16                   | [m: o16 0f 00 /0]           | 286                        |
| SLDT       | reg32                   | [m: o32 0f 00 /0]           | 386                        |
| SLDT       | reg64                   | [m: o64nw 0f 00 /0]         | X64,ND                     |
| SLDT       | reg64                   | [m: o64 0f 00 /0]           | X64                        |
| SKINIT     | void                    | [0f 01 de]                  | X64                        |
| SMI        | void                    | [f1]                        | 386,UNDOC                  |
| SMINT      | void                    | [0f 38]                     | P6,CYRIX,ND                |
| SMSW       | mem                     | [m: 0f 01 /4]               | 286                        |
| SMSW       | mem16                   | [m: 0f 01 /4]               | 286                        |
| SMSW       | reg16                   | [m: o16 0f 01 /4]           | 286                        |
| SMSW       | reg32                   | [m: o32 0f 01 /4]           | 386                        |
| SMSW       | reg64                   | [m: o64 0f 01 /4]           | X64                        |
| STC        | void                    | [f9]                        | 8086                       |
| STD        | void                    | [fd]                        | 8086                       |
| STI        | void                    | [fb]                        | 8086                       |
| STOSB      | void                    | [aa]                        | 8086                       |
| STOSD      | void                    | [o32 ab]                    | 386                        |
| STOSQ      | void                    | [o64 ab]                    | X64                        |
| STOSW      | void                    | [o16 ab]                    | 8086                       |
| STR        | mem                     | [m: 0f 00 /1]               | 286,PROT                   |
| STR        | mem16                   | [m: 0f 00 /1]               | 286,PROT                   |
| STR        | reg16                   | [m: o16 0f 00 /1]           | 286,PROT                   |
| STR        | reg32                   | [m: o32 0f 00 /1]           | 386,PROT                   |
| STR        | reg64                   | [m: o64 0f 00 /1]           | X64                        |
| SUB        | mem,reg8                | [mr: hle 28 /r]             | 8086,SM,LOCK               |
| SUB        | reg8,reg8               | [mr: 28 /r]                 | 8086                       |
| SUB        | mem,reg16               | [mr: hle o16 29 /r]         | 8086,SM,LOCK               |
| SUB        | reg16,reg16             | [mr: o16 29 /r]             | 8086                       |
| SUB        | mem,reg32               | [mr: hle o32 29 /r]         | 386,SM,LOCK                |
| SUB        | reg32,reg32             | [mr: o32 29 /r]             | 386                        |
| SUB        | mem,reg64               | [mr: hle o64 29 /r]         | X64,SM,LOCK                |
| SUB        | reg64,reg64             | [mr: o64 29 /r]             | X64                        |
| SUB        | reg8,mem                | [rm: 2a /r]                 | 8086,SM                    |
| SUB        | reg8,reg8               | [rm: 2a /r]                 | 8086                       |
| SUB        | reg16,mem               | [rm: o16 2b /r]             | 8086,SM                    |
| SUB        | reg16,reg16             | [rm: o16 2b /r]             | 8086                       |
| SUB        | reg32,mem               | [rm: o32 2b /r]             | 386,SM                     |
| SUB        | reg32,reg32             | [rm: o32 2b /r]             | 386                        |
| SUB        | reg64,mem               | [rm: o64 2b /r]             | X64,SM                     |
| SUB        | reg64,reg64             | [rm: o64 2b /r]             | X64                        |
| SUB        | rm16,imm8               | [mi: hle o16 83 /5 ib,s]    | 8086,LOCK                  |
| SUB        | rm32,imm8               | [mi: hle o32 83 /5 ib,s]    | 386,LOCK                   |
| SUB        | rm64,imm8               | [mi: hle o64 83 /5 ib,s]    | X64,LOCK                   |
| SUB        | reg_al,imm              | [-i: 2c ib]                 | 8086,SM                    |
| SUB        | reg_ax,sbyteword        | [mi: o16 83 /5 ib,s]        | 8086,SM,ND                 |
| SUB        | reg_ax,imm              | [-i: o16 2d iw]             | 8086,SM                    |
| SUB        | reg_eax,sbytedword      | [mi: o32 83 /5 ib,s]        | 386,SM,ND                  |
| SUB        | reg_eax,imm             | [-i: o32 2d id]             | 386,SM                     |
| SUB        | reg_rax,sbytedword      | [mi: o64 83 /5 ib,s]        | X64,SM,ND                  |
| SUB        | reg_rax,imm             | [-i: o64 2d id,s]           | X64,SM                     |
| SUB        | rm8,imm                 | [mi: hle 80 /5 ib]          | 8086,SM,LOCK               |
| SUB        | rm16,sbyteword          | [mi: hle o16 83 /5 ib,s]    | 8086,SM,LOCK,ND            |
| SUB        | rm16,imm                | [mi: hle o16 81 /5 iw]      | 8086,SM,LOCK               |
| SUB        | rm32,sbytedword         | [mi: hle o32 83 /5 ib,s]    | 386,SM,LOCK,ND             |
| SUB        | rm32,imm                | [mi: hle o32 81 /5 id]      | 386,SM,LOCK                |
| SUB        | rm64,sbytedword         | [mi: hle o64 83 /5 ib,s]    | X64,SM,LOCK,ND             |
| SUB        | rm64,imm                | [mi: hle o64 81 /5 id,s]    | X64,SM,LOCK                |
| SUB        | mem,imm8                | [mi: hle 80 /5 ib]          | 8086,SM,LOCK               |
| SUB        | mem,sbyteword16         | [mi: hle o16 83 /5 ib,s]    | 8086,SM,LOCK,ND            |
| SUB        | mem,imm16               | [mi: hle o16 81 /5 iw]      | 8086,SM,LOCK               |
| SUB        | mem,sbytedword32        | [mi: hle o32 83 /5 ib,s]    | 386,SM,LOCK,ND             |
| SUB        | mem,imm32               | [mi: hle o32 81 /5 id]      | 386,SM,LOCK                |
| SUB        | rm8,imm                 | [mi: hle 82 /5 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| SVDC       | mem80,reg_sreg          | [mr: 0f 78 /r]              | 486,CYRIX,SMM              |
| SVLDT      | mem80                   | [m: 0f 7a /0]               | 486,CYRIX,SMM,ND           |
| SVTS       | mem80                   | [m: 0f 7c /0]               | 486,CYRIX,SMM              |
| SWAPGS     | void                    | [0f 01 f8]                  | X64                        |
| SYSCALL    | void                    | [0f 05]                     | P6,AMD                     |
| SYSENTER   | void                    | [0f 34]                     | P6                         |
| SYSEXIT    | void                    | [0f 35]                     | P6,PRIV                    |
| SYSRET     | void                    | [0f 07]                     | P6,PRIV,AMD                |
| TEST       | mem,reg8                | [mr: 84 /r]                 | 8086,SM                    |
| TEST       | reg8,reg8               | [mr: 84 /r]                 | 8086                       |
| TEST       | mem,reg16               | [mr: o16 85 /r]             | 8086,SM                    |
| TEST       | reg16,reg16             | [mr: o16 85 /r]             | 8086                       |
| TEST       | mem,reg32               | [mr: o32 85 /r]             | 386,SM                     |
| TEST       | reg32,reg32             | [mr: o32 85 /r]             | 386                        |
| TEST       | mem,reg64               | [mr: o64 85 /r]             | X64,SM                     |
| TEST       | reg64,reg64             | [mr: o64 85 /r]             | X64                        |
| TEST       | reg8,mem                | [rm: 84 /r]                 | 8086,SM                    |
| TEST       | reg16,mem               | [rm: o16 85 /r]             | 8086,SM                    |
| TEST       | reg32,mem               | [rm: o32 85 /r]             | 386,SM                     |
| TEST       | reg64,mem               | [rm: o64 85 /r]             | X64,SM                     |
| TEST       | reg_al,imm              | [-i: a8 ib]                 | 8086,SM                    |
| TEST       | reg_ax,imm              | [-i: o16 a9 iw]             | 8086,SM                    |
| TEST       | reg_eax,imm             | [-i: o32 a9 id]             | 386,SM                     |
| TEST       | reg_rax,imm             | [-i: o64 a9 id,s]           | X64,SM                     |
| TEST       | rm8,imm                 | [mi: f6 /0 ib]              | 8086,SM                    |
| TEST       | rm16,imm                | [mi: o16 f7 /0 iw]          | 8086,SM                    |
| TEST       | rm32,imm                | [mi: o32 f7 /0 id]          | 386,SM                     |
| TEST       | rm64,imm                | [mi: o64 f7 /0 id,s]        | X64,SM                     |
| TEST       | mem,imm8                | [mi: f6 /0 ib]              | 8086,SM                    |
| TEST       | mem,imm16               | [mi: o16 f7 /0 iw]          | 8086,SM                    |
| TEST       | mem,imm32               | [mi: o32 f7 /0 id]          | 386,SM                     |
| UD0        | void                    | [0f ff]                     | 186,OBSOLETE               |
| UD0        | reg16,rm16              | [rm: o16 0f ff /r]          | 186                        |
| UD0        | reg32,rm32              | [rm: o32 0f ff /r]          | 186                        |
| UD0        | reg64,rm64              | [rm: o64 0f ff /r]          | 186                        |
| UD1        | reg,rm16                | [rm: o16 0f b9 /r]          | 186                        |
| UD1        | reg,rm32                | [rm: o32 0f b9 /r]          | 186                        |
| UD1        | reg,rm64                | [rm: o64 0f b9 /r]          | 186                        |
| UD1        | void                    | [0f b9]                     | 186,ND                     |
| UD2B       | void                    | [0f b9]                     | 186,ND                     |
| UD2B       | reg,rm16                | [rm: o16 0f b9 /r]          | 186,ND                     |
| UD2B       | reg,rm32                | [rm: o32 0f b9 /r]          | 186,ND                     |
| UD2B       | reg,rm64                | [rm: o64 0f b9 /r]          | 186,ND                     |
| UD2        | void                    | [0f 0b]                     | 186                        |
| UD2A       | void                    | [0f 0b]                     | 186,ND                     |
| UMOV       | mem,reg8                | [mr: np 0f 10 /r]           | 386,UNDOC,SM,ND            |
| UMOV       | reg8,reg8               | [mr: np 0f 10 /r]           | 386,UNDOC,ND               |
| UMOV       | mem,reg16               | [mr: np o16 0f 11 /r]       | 386,UNDOC,SM,ND            |
| UMOV       | reg16,reg16             | [mr: np o16 0f 11 /r]       | 386,UNDOC,ND               |
| UMOV       | mem,reg32               | [mr: np o32 0f 11 /r]       | 386,UNDOC,SM,ND            |
| UMOV       | reg32,reg32             | [mr: np o32 0f 11 /r]       | 386,UNDOC,ND               |
| UMOV       | reg8,mem                | [rm: np 0f 12 /r]           | 386,UNDOC,SM,ND            |
| UMOV       | reg8,reg8               | [rm: np 0f 12 /r]           | 386,UNDOC,ND               |
| UMOV       | reg16,mem               | [rm: np o16 0f 13 /r]       | 386,UNDOC,SM,ND            |
| UMOV       | reg16,reg16             | [rm: np o16 0f 13 /r]       | 386,UNDOC,ND               |
| UMOV       | reg32,mem               | [rm: np o32 0f 13 /r]       | 386,UNDOC,SM,ND            |
| UMOV       | reg32,reg32             | [rm: np o32 0f 13 /r]       | 386,UNDOC,ND               |
| VERR       | mem                     | [m: 0f 00 /4]               | 286,PROT                   |
| VERR       | mem16                   | [m: 0f 00 /4]               | 286,PROT                   |
| VERR       | reg16                   | [m: 0f 00 /4]               | 286,PROT                   |
| VERW       | mem                     | [m: 0f 00 /5]               | 286,PROT                   |
| VERW       | mem16                   | [m: 0f 00 /5]               | 286,PROT                   |
| VERW       | reg16                   | [m: 0f 00 /5]               | 286,PROT                   |
| FWAIT      | void                    | [wait]                      | 8086                       |
| WBINVD     | void                    | [0f 09]                     | 486,PRIV                   |
| WRSHR      | rm32                    | [m: o32 0f 37 /0]           | P6,CYRIX,SMM               |
| WRMSR      | void                    | [0f 30]                     | PENT,PRIV                  |
| XADD       | mem,reg8                | [mr: hle 0f c0 /r]          | 486,SM,LOCK                |
| XADD       | reg8,reg8               | [mr: 0f c0 /r]              | 486                        |
| XADD       | mem,reg16               | [mr: hle o16 0f c1 /r]      | 486,SM,LOCK                |
| XADD       | reg16,reg16             | [mr: o16 0f c1 /r]          | 486                        |
| XADD       | mem,reg32               | [mr: hle o32 0f c1 /r]      | 486,SM,LOCK                |
| XADD       | reg32,reg32             | [mr: o32 0f c1 /r]          | 486                        |
| XADD       | mem,reg64               | [mr: hle o64 0f c1 /r]      | X64,SM,LOCK                |
| XADD       | reg64,reg64             | [mr: o64 0f c1 /r]          | X64                        |
| XBTS       | reg16,mem               | [rm: o16 0f a6 /r]          | 386,SW,UNDOC,ND            |
| XBTS       | reg16,reg16             | [rm: o16 0f a6 /r]          | 386,UNDOC,ND               |
| XBTS       | reg32,mem               | [rm: o32 0f a6 /r]          | 386,SD,UNDOC,ND            |
| XBTS       | reg32,reg32             | [rm: o32 0f a6 /r]          | 386,UNDOC,ND               |
| XCHG       | reg_ax,reg16            | [-r: o16 90+r]              | 8086                       |
| XCHG       | reg_eax,reg32na         | [-r: o32 90+r]              | 386                        |
| XCHG       | reg_rax,reg64           | [-r: o64 90+r]              | X64                        |
| XCHG       | reg16,reg_ax            | [r-: o16 90+r]              | 8086                       |
| XCHG       | reg32na,reg_eax         | [r-: o32 90+r]              | 386                        |
| XCHG       | reg64,reg_rax           | [r-: o64 90+r]              | X64                        |
| XCHG       | reg_eax,reg_eax         | [--: o32 90]                | 386,NOLONG                 |
| XCHG       | reg8,mem                | [rm: hlenl 86 /r]           | 8086,SM,LOCK               |
| XCHG       | reg8,reg8               | [rm: 86 /r]                 | 8086                       |
| XCHG       | reg16,mem               | [rm: hlenl o16 87 /r]       | 8086,SM,LOCK               |
| XCHG       | reg16,reg16             | [rm: o16 87 /r]             | 8086                       |
| XCHG       | reg32,mem               | [rm: hlenl o32 87 /r]       | 386,SM,LOCK                |
| XCHG       | reg32,reg32             | [rm: o32 87 /r]             | 386                        |
| XCHG       | reg64,mem               | [rm: hlenl o64 87 /r]       | X64,SM,LOCK                |
| XCHG       | reg64,reg64             | [rm: o64 87 /r]             | X64                        |
| XCHG       | mem,reg8                | [mr: hlenl 86 /r]           | 8086,SM,LOCK               |
| XCHG       | reg8,reg8               | [mr: 86 /r]                 | 8086                       |
| XCHG       | mem,reg16               | [mr: hlenl o16 87 /r]       | 8086,SM,LOCK               |
| XCHG       | reg16,reg16             | [mr: o16 87 /r]             | 8086                       |
| XCHG       | mem,reg32               | [mr: hlenl o32 87 /r]       | 386,SM,LOCK                |
| XCHG       | reg32,reg32             | [mr: o32 87 /r]             | 386                        |
| XCHG       | mem,reg64               | [mr: hlenl o64 87 /r]       | X64,SM,LOCK                |
| XCHG       | reg64,reg64             | [mr: o64 87 /r]             | X64                        |
| XLATB      | void                    | [d7]                        | 8086                       |
| XLAT       | void                    | [d7]                        | 8086                       |
| XOR        | mem,reg8                | [mr: hle 30 /r]             | 8086,SM,LOCK               |
| XOR        | reg8,reg8               | [mr: 30 /r]                 | 8086                       |
| XOR        | mem,reg16               | [mr: hle o16 31 /r]         | 8086,SM,LOCK               |
| XOR        | reg16,reg16             | [mr: o16 31 /r]             | 8086                       |
| XOR        | mem,reg32               | [mr: hle o32 31 /r]         | 386,SM,LOCK                |
| XOR        | reg32,reg32             | [mr: o32 31 /r]             | 386                        |
| XOR        | mem,reg64               | [mr: hle o64 31 /r]         | X64,SM,LOCK                |
| XOR        | reg64,reg64             | [mr: o64 31 /r]             | X64                        |
| XOR        | reg8,mem                | [rm: 32 /r]                 | 8086,SM                    |
| XOR        | reg8,reg8               | [rm: 32 /r]                 | 8086                       |
| XOR        | reg16,mem               | [rm: o16 33 /r]             | 8086,SM                    |
| XOR        | reg16,reg16             | [rm: o16 33 /r]             | 8086                       |
| XOR        | reg32,mem               | [rm: o32 33 /r]             | 386,SM                     |
| XOR        | reg32,reg32             | [rm: o32 33 /r]             | 386                        |
| XOR        | reg64,mem               | [rm: o64 33 /r]             | X64,SM                     |
| XOR        | reg64,reg64             | [rm: o64 33 /r]             | X64                        |
| XOR        | rm16,imm8               | [mi: hle o16 83 /6 ib,s]    | 8086,LOCK                  |
| XOR        | rm32,imm8               | [mi: hle o32 83 /6 ib,s]    | 386,LOCK                   |
| XOR        | rm64,imm8               | [mi: hle o64 83 /6 ib,s]    | X64,LOCK                   |
| XOR        | reg_al,imm              | [-i: 34 ib]                 | 8086,SM                    |
| XOR        | reg_ax,sbyteword        | [mi: o16 83 /6 ib,s]        | 8086,SM,ND                 |
| XOR        | reg_ax,imm              | [-i: o16 35 iw]             | 8086,SM                    |
| XOR        | reg_eax,sbytedword      | [mi: o32 83 /6 ib,s]        | 386,SM,ND                  |
| XOR        | reg_eax,imm             | [-i: o32 35 id]             | 386,SM                     |
| XOR        | reg_rax,sbytedword      | [mi: o64 83 /6 ib,s]        | X64,SM,ND                  |
| XOR        | reg_rax,imm             | [-i: o64 35 id,s]           | X64,SM                     |
| XOR        | rm8,imm                 | [mi: hle 80 /6 ib]          | 8086,SM,LOCK               |
| XOR        | rm16,sbyteword          | [mi: hle o16 83 /6 ib,s]    | 8086,SM,LOCK,ND            |
| XOR        | rm16,imm                | [mi: hle o16 81 /6 iw]      | 8086,SM,LOCK               |
| XOR        | rm32,sbytedword         | [mi: hle o32 83 /6 ib,s]    | 386,SM,LOCK,ND             |
| XOR        | rm32,imm                | [mi: hle o32 81 /6 id]      | 386,SM,LOCK                |
| XOR        | rm64,sbytedword         | [mi: hle o64 83 /6 ib,s]    | X64,SM,LOCK,ND             |
| XOR        | rm64,imm                | [mi: hle o64 81 /6 id,s]    | X64,SM,LOCK                |
| XOR        | mem,imm8                | [mi: hle 80 /6 ib]          | 8086,SM,LOCK               |
| XOR        | mem,sbyteword16         | [mi: hle o16 83 /6 ib,s]    | 8086,SM,LOCK,ND            |
| XOR        | mem,imm16               | [mi: hle o16 81 /6 iw]      | 8086,SM,LOCK               |
| XOR        | mem,sbytedword32        | [mi: hle o32 83 /6 ib,s]    | 386,SM,LOCK,ND             |
| XOR        | mem,imm32               | [mi: hle o32 81 /6 id]      | 386,SM,LOCK                |
| XOR        | rm8,imm                 | [mi: hle 82 /6 ib]          | 8086,SM,LOCK,ND,NOLONG     |
| CMOVcc     | reg16,mem               | [rm: o16 0f 40+c /r]        | P6,SM                      |
| CMOVcc     | reg16,reg16             | [rm: o16 0f 40+c /r]        | P6                         |
| CMOVcc     | reg32,mem               | [rm: o32 0f 40+c /r]        | P6,SM                      |
| CMOVcc     | reg32,reg32             | [rm: o32 0f 40+c /r]        | P6                         |
| CMOVcc     | reg64,mem               | [rm: o64 0f 40+c /r]        | X64,SM                     |
| CMOVcc     | reg64,reg64             | [rm: o64 0f 40+c /r]        | X64                        |
| Jcc        | imm^near                | [i: odf 0f 80+c rel]        | 386,BND                    |
| Jcc        | imm16^near              | [i: o16 0f 80+c rel]        | 386,NOLONG,BND             |
| Jcc        | imm32^near              | [i: o32 0f 80+c rel]        | 386,NOLONG,BND             |
| Jcc        | imm64^near              | [i: o64nw 0f 80+c rel]      | X64,BND                    |
| Jcc        | imm^short               | [i: 70+c rel8]              | 8086,ND,BND                |
| Jcc        | imm                     | [i: jcc8 70+c rel8]         | 8086,ND,BND                |
| Jcc        | imm                     | [i: 0f 80+c rel]            | 386,ND,BND                 |
| Jcc        | imm                     | [i: 71+c jlen e9 rel]       | 8086,ND,BND                |
| Jcc        | imm                     | [i: 70+c rel8]              | 8086,BND                   |
| SETcc      | mem                     | [m: 0f 90+c /0]             | 386,SB                     |
| SETcc      | reg8                    | [m: 0f 90+c /0]             | 386                        |

SSE
-------------------------------------------------------------------------------------------------------------------------------------
| ADDPS           | xmmreg,xmmrm128       | [rm: np 0f 58 /r]                 | SSE                 |
| ADDSS           | xmmreg,xmmrm32        | [rm: f3 0f 58 /r]                 | SSE                 |
| ANDNPS          | xmmreg,xmmrm128       | [rm: np 0f 55 /r]                 | SSE                 |
| ANDPS           | xmmreg,xmmrm128       | [rm: np 0f 54 /r]                 | SSE                 |
| CMPEQPS         | xmmreg,xmmrm128       | [rm: np 0f c2 /r 00]              | SSE                 |
| CMPEQSS         | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 00]              | SSE                 |
| CMPLEPS         | xmmreg,xmmrm128       | [rm: np 0f c2 /r 02]              | SSE                 |
| CMPLESS         | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 02]              | SSE                 |
| CMPLTPS         | xmmreg,xmmrm128       | [rm: np 0f c2 /r 01]              | SSE                 |
| CMPLTSS         | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 01]              | SSE                 |
| CMPNEQPS        | xmmreg,xmmrm128       | [rm: np 0f c2 /r 04]              | SSE                 |
| CMPNEQSS        | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 04]              | SSE                 |
| CMPNLEPS        | xmmreg,xmmrm128       | [rm: np 0f c2 /r 06]              | SSE                 |
| CMPNLESS        | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 06]              | SSE                 |
| CMPNLTPS        | xmmreg,xmmrm128       | [rm: np 0f c2 /r 05]              | SSE                 |
| CMPNLTSS        | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 05]              | SSE                 |
| CMPORDPS        | xmmreg,xmmrm128       | [rm: np 0f c2 /r 07]              | SSE                 |
| CMPORDSS        | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 07]              | SSE                 |
| CMPUNORDPS      | xmmreg,xmmrm128       | [rm: np 0f c2 /r 03]              | SSE                 |
| CMPUNORDSS      | xmmreg,xmmrm32        | [rm: f3 0f c2 /r 03]              | SSE                 |
| CMPPS           | xmmreg,mem,imm        | [rmi: np 0f c2 /r ib,u]           | SSE,SB,AR2          |
| CMPPS           | xmmreg,xmmreg,imm     | [rmi: np 0f c2 /r ib,u]           | SSE,SB,AR2          |
| CMPSS           | xmmreg,mem,imm        | [rmi: f3 0f c2 /r ib,u]           | SSE,SB,AR2          |
| CMPSS           | xmmreg,xmmreg,imm     | [rmi: f3 0f c2 /r ib,u]           | SSE,SB,AR2          |
| COMISS          | xmmreg,xmmrm32        | [rm: np 0f 2f /r]                 | SSE                 |
| CVTPI2PS        | xmmreg,mmxrm64        | [rm: np 0f 2a /r]                 | SSE,MMX             |
| CVTPS2PI        | mmxreg,xmmrm64        | [rm: np 0f 2d /r]                 | SSE,MMX             |
| CVTSI2SS        | xmmreg,mem            | [rm: f3 0f 2a /r]                 | SSE,SD,AR1,ND       |
| CVTSI2SS        | xmmreg,rm32           | [rm: f3 0f 2a /r]                 | SSE,SD,AR1          |
| CVTSI2SS        | xmmreg,rm64           | [rm: o64 f3 0f 2a /r]             | X64,SSE,SQ,AR1      |
| CVTSS2SI        | reg32,xmmreg          | [rm: f3 0f 2d /r]                 | SSE,SD,AR1          |
| CVTSS2SI        | reg32,mem             | [rm: f3 0f 2d /r]                 | SSE,SD,AR1          |
| CVTSS2SI        | reg64,xmmreg          | [rm: o64 f3 0f 2d /r]             | X64,SSE,SD,AR1      |
| CVTSS2SI        | reg64,mem             | [rm: o64 f3 0f 2d /r]             | X64,SSE,SD,AR1      |
| CVTTPS2PI       | mmxreg,xmmrm          | [rm: np 0f 2c /r]                 | SSE,MMX,SQ          |
| CVTTSS2SI       | reg32,xmmrm           | [rm: f3 0f 2c /r]                 | SSE,SD,AR1          |
| CVTTSS2SI       | reg64,xmmrm           | [rm: o64 f3 0f 2c /r]             | X64,SSE,SD,AR1      |
| DIVPS           | xmmreg,xmmrm128       | [rm: np 0f 5e /r]                 | SSE                 |
| DIVSS           | xmmreg,xmmrm32        | [rm: f3 0f 5e /r]                 | SSE                 |
| LDMXCSR         | mem32                 | [m: np 0f ae /2]                  | SSE                 |
| MAXPS           | xmmreg,xmmrm128       | [rm: np 0f 5f /r]                 | SSE                 |
| MAXSS           | xmmreg,xmmrm32        | [rm: f3 0f 5f /r]                 | SSE                 |
| MINPS           | xmmreg,xmmrm128       | [rm: np 0f 5d /r]                 | SSE                 |
| MINSS           | xmmreg,xmmrm32        | [rm: f3 0f 5d /r]                 | SSE                 |
| MOVAPS          | xmmreg,xmmrm128       | [rm: np 0f 28 /r]                 | SSE                 |
| MOVAPS          | xmmrm128,xmmreg       | [mr: np 0f 29 /r]                 | SSE                 |
| MOVHPS          | xmmreg,mem64          | [rm: np 0f 16 /r]                 | SSE                 |
| MOVHPS          | mem64,xmmreg          | [mr: np 0f 17 /r]                 | SSE                 |
| MOVLHPS         | xmmreg,xmmreg         | [rm: np 0f 16 /r]                 | SSE                 |
| MOVLPS          | xmmreg,mem64          | [rm: np 0f 12 /r]                 | SSE                 |
| MOVLPS          | mem64,xmmreg          | [mr: np 0f 13 /r]                 | SSE                 |
| MOVHLPS         | xmmreg,xmmreg         | [rm: np 0f 12 /r]                 | SSE                 |
| MOVMSKPS        | reg32,xmmreg          | [rm: np 0f 50 /r]                 | SSE                 |
| MOVMSKPS        | reg64,xmmreg          | [rm: np o64 0f 50 /r]             | X64,SSE             |
| MOVNTPS         | mem128,xmmreg         | [mr: np 0f 2b /r]                 | SSE                 |
| MOVSS           | xmmreg,xmmrm32        | [rm: f3 0f 10 /r]                 | SSE                 |
| MOVSS           | mem32,xmmreg          | [mr: f3 0f 11 /r]                 | SSE                 |
| MOVSS           | xmmreg,xmmreg         | [rm: f3 0f 10 /r]                 | SSE                 |
| MOVUPS          | xmmreg,xmmrm128       | [rm: np 0f 10 /r]                 | SSE                 |
| MOVUPS          | xmmrm128,xmmreg       | [mr: np 0f 11 /r]                 | SSE                 |
| MULPS           | xmmreg,xmmrm128       | [rm: np 0f 59 /r]                 | SSE                 |
| MULSS           | xmmreg,xmmrm32        | [rm: f3 0f 59 /r]                 | SSE                 |
| ORPS            | xmmreg,xmmrm128       | [rm: np 0f 56 /r]                 | SSE                 |
| RCPPS           | xmmreg,xmmrm128       | [rm: np 0f 53 /r]                 | SSE                 |
| RCPSS           | xmmreg,xmmrm32        | [rm: f3 0f 53 /r]                 | SSE                 |
| RSQRTPS         | xmmreg,xmmrm128       | [rm: np 0f 52 /r]                 | SSE                 |
| RSQRTSS         | xmmreg,xmmrm32        | [rm: f3 0f 52 /r]                 | SSE                 |
| SHUFPS          | xmmreg,xmmrm128,imm8  | [rmi: np 0f c6 /r ib,u]           | SSE                 |
| SQRTPS          | xmmreg,xmmrm128       | [rm: np 0f 51 /r]                 | SSE                 |
| SQRTSS          | xmmreg,xmmrm32        | [rm: f3 0f 51 /r]                 | SSE                 |
| STMXCSR         | mem32                 | [m: np 0f ae /3]                  | SSE                 |
| SUBPS           | xmmreg,xmmrm128       | [rm: np 0f 5c /r]                 | SSE                 |
| SUBSS           | xmmreg,xmmrm32        | [rm: f3 0f 5c /r]                 | SSE                 |
| UCOMISS         | xmmreg,xmmrm32        | [rm: np 0f 2e /r]                 | SSE                 |
| UNPCKHPS        | xmmreg,xmmrm128       | [rm: np 0f 15 /r]                 | SSE                 |
| UNPCKLPS        | xmmreg,xmmrm128       | [rm: np 0f 14 /r]                 | SSE                 |
| XORPS           | xmmreg,xmmrm128       | [rm: np 0f 57 /r]                 | SSE                 |
| FXRSTOR         | mem                   | [m: np 0f ae /1]                  | P6,SSE,FPU          |
| FXRSTOR64       | mem                   | [m: o64 np 0f ae /1]              | X64,SSE,FPU         |
| FXSAVE          | mem                   | [m: np 0f ae /0]                  | P6,SSE,FPU          |
| FXSAVE64        | mem                   | [m: o64 np 0f ae /0]              | X64,SSE,FPU         |
| XGETBV          | void                  | [0f 01 d0]                        | NEHALEM             |
| XSETBV          | void                  | [0f 01 d1]                        | PRIV                |
| XSAVE           | mem                   | [m: np 0f ae /4]                  | NEHALEM             |
| XSAVE64         | mem                   | [m: o64 np 0f ae /4]              | LONG,NEHALEM        |
| XSAVEC          | mem                   | [m: np 0f c7 /4]                  | FUTURE              |
| XSAVEC64        | mem                   | [m: o64 np 0f c7 /4]              | LONG                |
| XSAVEOPT        | mem                   | [m: np 0f ae /6]                  | FUTURE              |
| XSAVEOPT64      | mem                   | [m: o64 np 0f ae /6]              | LONG                |
| XSAVES          | mem                   | [m: np 0f c7 /5]                  | FUTURE              |
| XSAVES64        | mem                   | [m: o64 np 0f c7 /5]              | LONG                |
| XRSTOR          | mem                   | [m: np 0f ae /5]                  | NEHALEM             |
| XRSTOR64        | mem                   | [m: o64 np 0f ae /5]              | LONG,NEHALEM        |
| XRSTORS         | mem                   | [m: np 0f c7 /3]                  | FUTURE              |
| XRSTORS64       | mem                   | [m: o64 np 0f c7 /3]              | LONG                |
| PREFETCHNTA     | mem8                  | [m: 0f 18 /0]                     | KATMAI              |
| PREFETCHT0      | mem8                  | [m: 0f 18 /1]                     | KATMAI              |
| PREFETCHT1      | mem8                  | [m: 0f 18 /2]                     | KATMAI              |
| PREFETCHT2      | mem8                  | [m: 0f 18 /3]                     | KATMAI              |
| SFENCE          | void                  | [np 0f ae f8]                     | KATMAI              |
| MASKMOVQ        | mmxreg,mmxreg         | [rm: np 0f f7 /r]                 | MMX                 |
| MOVNTQ          | mem,mmxreg            | [mr: np 0f e7 /r]                 | MMX,SQ              |
| PAVGB           | mmxreg,mmxrm          | [rm: np o64nw 0f e0 /r]           | MMX,SQ              |
| PAVGW           | mmxreg,mmxrm          | [rm: np o64nw 0f e3 /r]           | MMX,SQ              |
| PEXTRW          | reg32,mmxreg,imm      | [rmi: np 0f c5 /r ib,u]           | MMX,SB,AR2          |
| PINSRW          | mmxreg,mem,imm        | [rmi: np 0f c4 /r ib,u]           | MMX,SB,AR2          |
| PINSRW          | mmxreg,rm16,imm       | [rmi: np 0f c4 /r ib,u]           | MMX,SB,AR2          |
| PINSRW          | mmxreg,reg32,imm      | [rmi: np 0f c4 /r ib,u]           | MMX,SB,AR2          |
| PMAXSW          | mmxreg,mmxrm          | [rm: np o64nw 0f ee /r]           | MMX,SQ              |
| PMAXUB          | mmxreg,mmxrm          | [rm: np o64nw 0f de /r]           | MMX,SQ              |
| PMINSW          | mmxreg,mmxrm          | [rm: np o64nw 0f ea /r]           | MMX,SQ              |
| PMINUB          | mmxreg,mmxrm          | [rm: np o64nw 0f da /r]           | MMX,SQ              |
| PMOVMSKB        | reg32,mmxreg          | [rm: np 0f d7 /r]                 | MMX                 |
| PMULHUW         | mmxreg,mmxrm          | [rm: np o64nw 0f e4 /r]           | MMX,SQ              |
| PSADBW          | mmxreg,mmxrm          | [rm: np o64nw 0f f6 /r]           | MMX,SQ              |
| PSHUFW          | mmxreg,mmxrm,imm      | [rmi: np o64nw 0f 70 /r ib]       | MMX,SM2,SB,AR2      |
| PF2IW           | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 1c]           | PENT,3DNOW,SQ       |
| PFNACC          | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 8a]           | PENT,3DNOW,SQ       |
| PFPNACC         | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 8e]           | PENT,3DNOW,SQ       |
| PI2FW           | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 0c]           | PENT,3DNOW,SQ       |
| PSWAPD          | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r bb]           | PENT,3DNOW,SQ       |
| MASKMOVDQU      | xmmreg,xmmreg         | [rm: 66 0f f7 /r]                 | SSE2                |
| CLFLUSH         | mem                   | [m: np 0f ae /7]                  | SSE2                |
| MOVNTDQ         | mem,xmmreg            | [mr: 66 0f e7 /r]                 | SSE2,SO             |
| MOVNTI          | mem,reg32             | [mr: np 0f c3 /r]                 | SD                  |
| MOVNTI          | mem,reg64             | [mr: o64 np 0f c3 /r]             | X64,SQ              |
| MOVNTPD         | mem,xmmreg            | [mr: 66 0f 2b /r]                 | SSE2,SO             |
| LFENCE          | void                  | [np 0f ae e8]                     | SSE2                |
| MFENCE          | void                  | [np 0f ae f0]                     | SSE2                |
| MOVD            | mem,xmmreg            | [mr: 66 norexw 0f 7e /r]          | SSE2,SD             |
| MOVD            | xmmreg,mem            | [rm: 66 norexw 0f 6e /r]          | SSE2,SD             |
| MOVD            | xmmreg,rm32           | [rm: 66 norexw 0f 6e /r]          | SSE2                |
| MOVD            | rm32,xmmreg           | [mr: 66 norexw 0f 7e /r]          | SSE2                |
| MOVDQA          | xmmreg,xmmreg         | [rm: 66 0f 6f /r]                 | SSE2                |
| MOVDQA          | mem,xmmreg            | [mr: 66 0f 7f /r]                 | SSE2,SO             |
| MOVDQA          | xmmreg,mem            | [rm: 66 0f 6f /r]                 | SSE2,SO             |
| MOVDQA          | xmmreg,xmmreg         | [mr: 66 0f 7f /r]                 | SSE2                |
| MOVDQU          | xmmreg,xmmreg         | [rm: f3 0f 6f /r]                 | SSE2                |
| MOVDQU          | mem,xmmreg            | [mr: f3 0f 7f /r]                 | SSE2,SO             |
| MOVDQU          | xmmreg,mem            | [rm: f3 0f 6f /r]                 | SSE2,SO             |
| MOVDQU          | xmmreg,xmmreg         | [mr: f3 0f 7f /r]                 | SSE2                |
| MOVDQ2Q         | mmxreg,xmmreg         | [rm: f2 0f d6 /r]                 | SSE2                |
| MOVQ            | xmmreg,xmmreg         | [rm: f3 0f 7e /r]                 | SSE2                |
| MOVQ            | xmmreg,xmmreg         | [mr: 66 0f d6 /r]                 | SSE2                |
| MOVQ            | mem,xmmreg            | [mr: 66 0f d6 /r]                 | SSE2,SQ             |
| MOVQ            | xmmreg,mem            | [rm: f3 0f 7e /r]                 | SSE2,SQ             |
| MOVQ            | xmmreg,rm64           | [rm: 66 o64 0f 6e /r]             | X64,SSE2            |
| MOVQ            | rm64,xmmreg           | [mr: 66 o64 0f 7e /r]             | X64,SSE2            |
| MOVQ2DQ         | xmmreg,mmxreg         | [rm: f3 0f d6 /r]                 | SSE2                |
| PACKSSWB        | xmmreg,xmmrm          | [rm: 66 0f 63 /r]                 | SSE2,SO             |
| PACKSSDW        | xmmreg,xmmrm          | [rm: 66 0f 6b /r]                 | SSE2,SO             |
| PACKUSWB        | xmmreg,xmmrm          | [rm: 66 0f 67 /r]                 | SSE2,SO             |
| PADDB           | xmmreg,xmmrm          | [rm: 66 0f fc /r]                 | SSE2,SO             |
| PADDW           | xmmreg,xmmrm          | [rm: 66 0f fd /r]                 | SSE2,SO             |
| PADDD           | xmmreg,xmmrm          | [rm: 66 0f fe /r]                 | SSE2,SO             |
| PADDQ           | mmxreg,mmxrm          | [rm: np 0f d4 /r]                 | MMX,SQ              |
| PADDQ           | xmmreg,xmmrm          | [rm: 66 0f d4 /r]                 | SSE2,SO             |
| PADDSB          | xmmreg,xmmrm          | [rm: 66 0f ec /r]                 | SSE2,SO             |
| PADDSW          | xmmreg,xmmrm          | [rm: 66 0f ed /r]                 | SSE2,SO             |
| PADDUSB         | xmmreg,xmmrm          | [rm: 66 0f dc /r]                 | SSE2,SO             |
| PADDUSW         | xmmreg,xmmrm          | [rm: 66 0f dd /r]                 | SSE2,SO             |
| PAND            | xmmreg,xmmrm          | [rm: 66 0f db /r]                 | SSE2,SO             |
| PANDN           | xmmreg,xmmrm          | [rm: 66 0f df /r]                 | SSE2,SO             |
| PAVGB           | xmmreg,xmmrm          | [rm: 66 0f e0 /r]                 | SSE2,SO             |
| PAVGW           | xmmreg,xmmrm          | [rm: 66 0f e3 /r]                 | SSE2,SO             |
| PCMPEQB         | xmmreg,xmmrm          | [rm: 66 0f 74 /r]                 | SSE2,SO             |
| PCMPEQW         | xmmreg,xmmrm          | [rm: 66 0f 75 /r]                 | SSE2,SO             |
| PCMPEQD         | xmmreg,xmmrm          | [rm: 66 0f 76 /r]                 | SSE2,SO             |
| PCMPGTB         | xmmreg,xmmrm          | [rm: 66 0f 64 /r]                 | SSE2,SO             |
| PCMPGTW         | xmmreg,xmmrm          | [rm: 66 0f 65 /r]                 | SSE2,SO             |
| PCMPGTD         | xmmreg,xmmrm          | [rm: 66 0f 66 /r]                 | SSE2,SO             |
| PEXTRW          | reg32,xmmreg,imm      | [rmi: 66 0f c5 /r ib,u]           | SSE2,SB,AR2         |
| PEXTRW          | reg64,xmmreg,imm      | [rmi: 66 0f c5 /r ib,u]           | X64,SSE2,SB,AR2,ND  |
| PINSRW          | xmmreg,reg16,imm      | [rmi: 66 0f c4 /r ib,u]           | SSE2,SB,AR2         |
| PINSRW          | xmmreg,reg32,imm      | [rmi: 66 0f c4 /r ib,u]           | SSE2,SB,AR2,ND      |
| PINSRW          | xmmreg,reg64,imm      | [rmi: 66 0f c4 /r ib,u]           | X64,SSE2,SB,AR2,ND  |
| PINSRW          | xmmreg,mem,imm        | [rmi: 66 0f c4 /r ib,u]           | SSE2,SB,AR2         |
| PINSRW          | xmmreg,mem16,imm      | [rmi: 66 0f c4 /r ib,u]           | SSE2,SB,AR2         |
| PMADDWD         | xmmreg,xmmrm          | [rm: 66 0f f5 /r]                 | SSE2,SO             |
| PMAXSW          | xmmreg,xmmrm          | [rm: 66 0f ee /r]                 | SSE2,SO             |
| PMAXUB          | xmmreg,xmmrm          | [rm: 66 0f de /r]                 | SSE2,SO             |
| PMINSW          | xmmreg,xmmrm          | [rm: 66 0f ea /r]                 | SSE2,SO             |
| PMINUB          | xmmreg,xmmrm          | [rm: 66 0f da /r]                 | SSE2,SO             |
| PMOVMSKB        | reg32,xmmreg          | [rm: 66 0f d7 /r]                 | SSE2                |
| PMULHUW         | xmmreg,xmmrm          | [rm: 66 0f e4 /r]                 | SSE2,SO             |
| PMULHW          | xmmreg,xmmrm          | [rm: 66 0f e5 /r]                 | SSE2,SO             |
| PMULLW          | xmmreg,xmmrm          | [rm: 66 0f d5 /r]                 | SSE2,SO             |
| PMULUDQ         | mmxreg,mmxrm          | [rm: np o64nw 0f f4 /r]           | SSE2,SO             |
| PMULUDQ         | xmmreg,xmmrm          | [rm: 66 0f f4 /r]                 | SSE2,SO             |
| POR             | xmmreg,xmmrm          | [rm: 66 0f eb /r]                 | SSE2,SO             |
| PSADBW          | xmmreg,xmmrm          | [rm: 66 0f f6 /r]                 | SSE2,SO             |
| PSHUFD          | xmmreg,xmmreg,imm     | [rmi: 66 0f 70 /r ib]             | SSE2,SB,AR2         |
| PSHUFD          | xmmreg,mem,imm        | [rmi: 66 0f 70 /r ib]             | SSE2,SM2,SB,AR2     |
| PSHUFHW         | xmmreg,xmmreg,imm     | [rmi: f3 0f 70 /r ib]             | SSE2,SB,AR2         |
| PSHUFHW         | xmmreg,mem,imm        | [rmi: f3 0f 70 /r ib]             | SSE2,SM2,SB,AR2     |
| PSHUFLW         | xmmreg,xmmreg,imm     | [rmi: f2 0f 70 /r ib]             | SSE2,SB,AR2         |
| PSHUFLW         | xmmreg,mem,imm        | [rmi: f2 0f 70 /r ib]             | SSE2,SM2,SB,AR2     |
| PSLLDQ          | xmmreg,imm            | [mi: 66 0f 73 /7 ib,u]            | SSE2,SB,AR1         |
| PSLLW           | xmmreg,xmmrm          | [rm: 66 0f f1 /r]                 | SSE2,SO             |
| PSLLW           | xmmreg,imm            | [mi: 66 0f 71 /6 ib,u]            | SSE2,SB,AR1         |
| PSLLD           | xmmreg,xmmrm          | [rm: 66 0f f2 /r]                 | SSE2,SO             |
| PSLLD           | xmmreg,imm            | [mi: 66 0f 72 /6 ib,u]            | SSE2,SB,AR1         |
| PSLLQ           | xmmreg,xmmrm          | [rm: 66 0f f3 /r]                 | SSE2,SO             |
| PSLLQ           | xmmreg,imm            | [mi: 66 0f 73 /6 ib,u]            | SSE2,SB,AR1         |
| PSRAW           | xmmreg,xmmrm          | [rm: 66 0f e1 /r]                 | SSE2,SO             |
| PSRAW           | xmmreg,imm            | [mi: 66 0f 71 /4 ib,u]            | SSE2,SB,AR1         |
| PSRAD           | xmmreg,xmmrm          | [rm: 66 0f e2 /r]                 | SSE2,SO             |
| PSRAD           | xmmreg,imm            | [mi: 66 0f 72 /4 ib,u]            | SSE2,SB,AR1         |
| PSRLDQ          | xmmreg,imm            | [mi: 66 0f 73 /3 ib,u]            | SSE2,SB,AR1         |
| PSRLW           | xmmreg,xmmrm          | [rm: 66 0f d1 /r]                 | SSE2,SO             |
| PSRLW           | xmmreg,imm            | [mi: 66 0f 71 /2 ib,u]            | SSE2,SB,AR1         |
| PSRLD           | xmmreg,xmmrm          | [rm: 66 0f d2 /r]                 | SSE2,SO             |
| PSRLD           | xmmreg,imm            | [mi: 66 0f 72 /2 ib,u]            | SSE2,SB,AR1         |
| PSRLQ           | xmmreg,xmmrm          | [rm: 66 0f d3 /r]                 | SSE2,SO             |
| PSRLQ           | xmmreg,imm            | [mi: 66 0f 73 /2 ib,u]            | SSE2,SB,AR1         |
| PSUBB           | xmmreg,xmmrm          | [rm: 66 0f f8 /r]                 | SSE2,SO             |
| PSUBW           | xmmreg,xmmrm          | [rm: 66 0f f9 /r]                 | SSE2,SO             |
| PSUBD           | xmmreg,xmmrm          | [rm: 66 0f fa /r]                 | SSE2,SO             |
| PSUBQ           | mmxreg,mmxrm          | [rm: np o64nw 0f fb /r]           | SSE2,SO             |
| PSUBQ           | xmmreg,xmmrm          | [rm: 66 0f fb /r]                 | SSE2,SO             |
| PSUBSB          | xmmreg,xmmrm          | [rm: 66 0f e8 /r]                 | SSE2,SO             |
| PSUBSW          | xmmreg,xmmrm          | [rm: 66 0f e9 /r]                 | SSE2,SO             |
| PSUBUSB         | xmmreg,xmmrm          | [rm: 66 0f d8 /r]                 | SSE2,SO             |
| PSUBUSW         | xmmreg,xmmrm          | [rm: 66 0f d9 /r]                 | SSE2,SO             |
| PUNPCKHBW       | xmmreg,xmmrm          | [rm: 66 0f 68 /r]                 | SSE2,SO             |
| PUNPCKHWD       | xmmreg,xmmrm          | [rm: 66 0f 69 /r]                 | SSE2,SO             |
| PUNPCKHDQ       | xmmreg,xmmrm          | [rm: 66 0f 6a /r]                 | SSE2,SO             |
| PUNPCKHQDQ      | xmmreg,xmmrm          | [rm: 66 0f 6d /r]                 | SSE2,SO             |
| PUNPCKLBW       | xmmreg,xmmrm          | [rm: 66 0f 60 /r]                 | SSE2,SO             |
| PUNPCKLWD       | xmmreg,xmmrm          | [rm: 66 0f 61 /r]                 | SSE2,SO             |
| PUNPCKLDQ       | xmmreg,xmmrm          | [rm: 66 0f 62 /r]                 | SSE2,SO             |
| PUNPCKLQDQ      | xmmreg,xmmrm          | [rm: 66 0f 6c /r]                 | SSE2,SO             |
| PXOR            | xmmreg,xmmrm          | [rm: 66 0f ef /r]                 | SSE2,SO             |
| ADDPD           | xmmreg,xmmrm          | [rm: 66 0f 58 /r]                 | SSE2,SO             |
| ADDSD           | xmmreg,xmmrm          | [rm: f2 0f 58 /r]                 | SSE2,SQ             |
| ANDNPD          | xmmreg,xmmrm          | [rm: 66 0f 55 /r]                 | SSE2,SO             |
| ANDPD           | xmmreg,xmmrm          | [rm: 66 0f 54 /r]                 | SSE2,SO             |
| CMPEQPD         | xmmreg,xmmrm          | [rm: 66 0f c2 /r 00]              | SSE2,SO             |
| CMPEQSD         | xmmreg,xmmrm          | [rm: f2 0f c2 /r 00]              | SSE2                |
| CMPLEPD         | xmmreg,xmmrm          | [rm: 66 0f c2 /r 02]              | SSE2,SO             |
| CMPLESD         | xmmreg,xmmrm          | [rm: f2 0f c2 /r 02]              | SSE2                |
| CMPLTPD         | xmmreg,xmmrm          | [rm: 66 0f c2 /r 01]              | SSE2,SO             |
| CMPLTSD         | xmmreg,xmmrm          | [rm: f2 0f c2 /r 01]              | SSE2                |
| CMPNEQPD        | xmmreg,xmmrm          | [rm: 66 0f c2 /r 04]              | SSE2,SO             |
| CMPNEQSD        | xmmreg,xmmrm          | [rm: f2 0f c2 /r 04]              | SSE2                |
| CMPNLEPD        | xmmreg,xmmrm          | [rm: 66 0f c2 /r 06]              | SSE2,SO             |
| CMPNLESD        | xmmreg,xmmrm          | [rm: f2 0f c2 /r 06]              | SSE2                |
| CMPNLTPD        | xmmreg,xmmrm          | [rm: 66 0f c2 /r 05]              | SSE2,SO             |
| CMPNLTSD        | xmmreg,xmmrm          | [rm: f2 0f c2 /r 05]              | SSE2                |
| CMPORDPD        | xmmreg,xmmrm          | [rm: 66 0f c2 /r 07]              | SSE2,SO             |
| CMPORDSD        | xmmreg,xmmrm          | [rm: f2 0f c2 /r 07]              | SSE2                |
| CMPUNORDPD      | xmmreg,xmmrm          | [rm: 66 0f c2 /r 03]              | SSE2,SO             |
| CMPUNORDSD      | xmmreg,xmmrm          | [rm: f2 0f c2 /r 03]              | SSE2                |
| CMPPD           | xmmreg,xmmrm128,imm8  | [rmi: 66 0f c2 /r ib,u]           | SSE2                |
| CMPSD           | xmmreg,xmmrm128,imm8  | [rmi: f2 0f c2 /r ib,u]           | SSE2                |
| COMISD          | xmmreg,xmmrm          | [rm: 66 0f 2f /r]                 | SSE2                |
| CVTDQ2PD        | xmmreg,xmmrm          | [rm: f3 0f e6 /r]                 | SSE2,SQ             |
| CVTDQ2PS        | xmmreg,xmmrm          | [rm: np 0f 5b /r]                 | SSE2,SO             |
| CVTPD2DQ        | xmmreg,xmmrm          | [rm: f2 0f e6 /r]                 | SSE2,SO             |
| CVTPD2PI        | mmxreg,xmmrm          | [rm: 66 0f 2d /r]                 | SSE2,SO             |
| CVTPD2PS        | xmmreg,xmmrm          | [rm: 66 0f 5a /r]                 | SSE2,SO             |
| CVTPI2PD        | xmmreg,mmxrm          | [rm: 66 0f 2a /r]                 | SSE2,SQ             |
| CVTPS2DQ        | xmmreg,xmmrm          | [rm: 66 0f 5b /r]                 | SSE2,SO             |
| CVTPS2PD        | xmmreg,xmmrm          | [rm: np 0f 5a /r]                 | SSE2,SQ             |
| CVTSD2SI        | reg32,xmmreg          | [rm: norexw f2 0f 2d /r]          | SSE2,SQ,AR1         |
| CVTSD2SI        | reg32,mem             | [rm: norexw f2 0f 2d /r]          | SSE2,SQ,AR1         |
| CVTSD2SI        | reg64,xmmreg          | [rm: o64 f2 0f 2d /r]             | X64,SSE2,SQ,AR1     |
| CVTSD2SI        | reg64,mem             | [rm: o64 f2 0f 2d /r]             | X64,SSE2,SQ,AR1     |
| CVTSD2SS        | xmmreg,xmmrm          | [rm: f2 0f 5a /r]                 | SSE2,SQ             |
| CVTSI2SD        | xmmreg,mem            | [rm: f2 0f 2a /r]                 | SSE2,SD,AR1,ND      |
| CVTSI2SD        | xmmreg,rm32           | [rm: norexw f2 0f 2a /r]          | SSE2,SD,AR1         |
| CVTSI2SD        | xmmreg,rm64           | [rm: o64 f2 0f 2a /r]             | X64,SSE2,SQ,AR1     |
| CVTSS2SD        | xmmreg,xmmrm          | [rm: f3 0f 5a /r]                 | SSE2,SD             |
| CVTTPD2PI       | mmxreg,xmmrm          | [rm: 66 0f 2c /r]                 | SSE2,SO             |
| CVTTPD2DQ       | xmmreg,xmmrm          | [rm: 66 0f e6 /r]                 | SSE2,SO             |
| CVTTPS2DQ       | xmmreg,xmmrm          | [rm: f3 0f 5b /r]                 | SSE2,SO             |
| CVTTSD2SI       | reg32,xmmreg          | [rm: norexw f2 0f 2c /r]          | SSE2,SQ,AR1         |
| CVTTSD2SI       | reg32,mem             | [rm: norexw f2 0f 2c /r]          | SSE2,SQ,AR1         |
| CVTTSD2SI       | reg64,xmmreg          | [rm: o64 f2 0f 2c /r]             | X64,SSE2,SQ,AR1     |
| CVTTSD2SI       | reg64,mem             | [rm: o64 f2 0f 2c /r]             | X64,SSE2,SQ,AR1     |
| DIVPD           | xmmreg,xmmrm          | [rm: 66 0f 5e /r]                 | SSE2,SO             |
| DIVSD           | xmmreg,xmmrm          | [rm: f2 0f 5e /r]                 | SSE2                |
| MAXPD           | xmmreg,xmmrm          | [rm: 66 0f 5f /r]                 | SSE2,SO             |
| MAXSD           | xmmreg,xmmrm          | [rm: f2 0f 5f /r]                 | SSE2                |
| MINPD           | xmmreg,xmmrm          | [rm: 66 0f 5d /r]                 | SSE2,SO             |
| MINSD           | xmmreg,xmmrm          | [rm: f2 0f 5d /r]                 | SSE2                |
| MOVAPD          | xmmreg,xmmreg         | [rm: 66 0f 28 /r]                 | SSE2                |
| MOVAPD          | xmmreg,xmmreg         | [mr: 66 0f 29 /r]                 | SSE2                |
| MOVAPD          | mem,xmmreg            | [mr: 66 0f 29 /r]                 | SSE2,SO             |
| MOVAPD          | xmmreg,mem            | [rm: 66 0f 28 /r]                 | SSE2,SO             |
| MOVHPD          | mem,xmmreg            | [mr: 66 0f 17 /r]                 | SSE2                |
| MOVHPD          | xmmreg,mem            | [rm: 66 0f 16 /r]                 | SSE2                |
| MOVLPD          | mem64,xmmreg          | [mr: 66 0f 13 /r]                 | SSE2                |
| MOVLPD          | xmmreg,mem64          | [rm: 66 0f 12 /r]                 | SSE2                |
| MOVMSKPD        | reg32,xmmreg          | [rm: 66 0f 50 /r]                 | SSE2                |
| MOVMSKPD        | reg64,xmmreg          | [rm: 66 o64 0f 50 /r]             | X64,SSE2            |
| MOVSD           | xmmreg,xmmreg         | [rm: f2 0f 10 /r]                 | SSE2                |
| MOVSD           | xmmreg,xmmreg         | [mr: f2 0f 11 /r]                 | SSE2                |
| MOVSD           | mem64,xmmreg          | [mr: f2 0f 11 /r]                 | SSE2                |
| MOVSD           | xmmreg,mem64          | [rm: f2 0f 10 /r]                 | SSE2                |
| MOVUPD          | xmmreg,xmmreg         | [rm: 66 0f 10 /r]                 | SSE2                |
| MOVUPD          | xmmreg,xmmreg         | [mr: 66 0f 11 /r]                 | SSE2                |
| MOVUPD          | mem,xmmreg            | [mr: 66 0f 11 /r]                 | SSE2,SO             |
| MOVUPD          | xmmreg,mem            | [rm: 66 0f 10 /r]                 | SSE2,SO             |
| MULPD           | xmmreg,xmmrm          | [rm: 66 0f 59 /r]                 | SSE2,SO             |
| MULSD           | xmmreg,xmmrm          | [rm: f2 0f 59 /r]                 | SSE2                |
| ORPD            | xmmreg,xmmrm          | [rm: 66 0f 56 /r]                 | SSE2,SO             |
| SHUFPD          | xmmreg,xmmreg,imm     | [rmi: 66 0f c6 /r ib,u]           | SSE2,SB,AR2         |
| SHUFPD          | xmmreg,mem,imm        | [rmi: 66 0f c6 /r ib,u]           | SSE2,SM,SB,AR2      |
| SQRTPD          | xmmreg,xmmrm          | [rm: 66 0f 51 /r]                 | SSE2,SO             |
| SQRTSD          | xmmreg,xmmrm          | [rm: f2 0f 51 /r]                 | SSE2                |
| SUBPD           | xmmreg,xmmrm          | [rm: 66 0f 5c /r]                 | SSE2,SO             |
| SUBSD           | xmmreg,xmmrm          | [rm: f2 0f 5c /r]                 | SSE2                |
| UCOMISD         | xmmreg,xmmrm          | [rm: 66 0f 2e /r]                 | SSE2                |
| UNPCKHPD        | xmmreg,xmmrm128       | [rm: 66 0f 15 /r]                 | SSE2                |
| UNPCKLPD        | xmmreg,xmmrm128       | [rm: 66 0f 14 /r]                 | SSE2                |
| XORPD           | xmmreg,xmmrm128       | [rm: 66 0f 57 /r]                 | SSE2                |
| ADDSUBPD        | xmmreg,xmmrm          | [rm: 66 0f d0 /r]                 | SSE3,SO             |
| ADDSUBPS        | xmmreg,xmmrm          | [rm: f2 0f d0 /r]                 | SSE3,SO             |
| HADDPD          | xmmreg,xmmrm          | [rm: 66 0f 7c /r]                 | SSE3,SO             |
| HADDPS          | xmmreg,xmmrm          | [rm: f2 0f 7c /r]                 | SSE3,SO             |
| HSUBPD          | xmmreg,xmmrm          | [rm: 66 0f 7d /r]                 | SSE3,SO             |
| HSUBPS          | xmmreg,xmmrm          | [rm: f2 0f 7d /r]                 | SSE3,SO             |
| LDDQU           | xmmreg,mem            | [rm: f2 0f f0 /r]                 | SSE3,SO             |
| MOVDDUP         | xmmreg,xmmrm          | [rm: f2 0f 12 /r]                 | SSE3,SQ             |
| MOVSHDUP        | xmmreg,xmmrm          | [rm: f3 0f 16 /r]                 | SSE3                |
| MOVSLDUP        | xmmreg,xmmrm          | [rm: f3 0f 12 /r]                 | SSE3                |
| CLGI            | void                  | [0f 01 dd]                        | VMX,AMD             |
| STGI            | void                  | [0f 01 dc]                        | VMX,AMD             |
| VMCALL          | void                  | [0f 01 c1]                        | VMX                 |
| VMCLEAR         | mem                   | [m: 66 0f c7 /6]                  | VMX                 |
| VMFUNC          | void                  | [0f 01 d4]                        | VMX                 |
| VMLAUNCH        | void                  | [0f 01 c2]                        | VMX                 |
| VMLOAD          | void                  | [0f 01 da]                        | VMX,AMD             |
| VMMCALL         | void                  | [0f 01 d9]                        | VMX,AMD             |
| VMPTRLD         | mem                   | [m: np 0f c7 /6]                  | VMX                 |
| VMPTRST         | mem                   | [m: np 0f c7 /7]                  | VMX                 |
| VMREAD          | rm32,reg32            | [mr: np 0f 78 /r]                 | VMX,NOLONG,SD       |
| VMREAD          | rm64,reg64            | [mr: o64nw np 0f 78 /r]           | X64,VMX,SQ          |
| VMRESUME        | void                  | [0f 01 c3]                        | VMX                 |
| VMRUN           | void                  | [0f 01 d8]                        | VMX,AMD             |
| VMSAVE          | void                  | [0f 01 db]                        | VMX,AMD             |
| VMWRITE         | reg32,rm32            | [rm: np 0f 79 /r]                 | VMX,NOLONG,SD       |
| VMWRITE         | reg64,rm64            | [rm: o64nw np 0f 79 /r]           | X64,VMX,SQ          |
| VMXOFF          | void                  | [0f 01 c4]                        | VMX                 |
| VMXON           | mem                   | [m: f3 0f c7 /6]                  | VMX                 |
| INVEPT          | reg32,mem             | [rm: 66 0f 38 80 /r]              | VMX,SO,NOLONG       |
| INVEPT          | reg64,mem             | [rm: o64nw 66 0f 38 80 /r]        | VMX,SO,LONG         |
| INVVPID         | reg32,mem             | [rm: 66 0f 38 81 /r]              | VMX,SO,NOLONG       |
| INVVPID         | reg64,mem             | [rm: o64nw 66 0f 38 81 /r]        | VMX,SO,LONG         |
| PABSB           | mmxreg,mmxrm          | [rm: np 0f 38 1c /r]              | SSSE3,MMX,SQ        |
| PABSB           | xmmreg,xmmrm          | [rm: 66 0f 38 1c /r]              | SSSE3               |
| PABSW           | mmxreg,mmxrm          | [rm: np 0f 38 1d /r]              | SSSE3,MMX,SQ        |
| PABSW           | xmmreg,xmmrm          | [rm: 66 0f 38 1d /r]              | SSSE3               |
| PABSD           | mmxreg,mmxrm          | [rm: np 0f 38 1e /r]              | SSSE3,MMX,SQ        |
| PABSD           | xmmreg,xmmrm          | [rm: 66 0f 38 1e /r]              | SSSE3               |
| PALIGNR         | mmxreg,mmxrm,imm      | [rmi: np 0f 3a 0f /r ib,u]        | SSSE3,MMX,SQ        |
| PALIGNR         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0f /r ib,u]        | SSSE3               |
| PHADDW          | mmxreg,mmxrm          | [rm: np 0f 38 01 /r]              | SSSE3,MMX,SQ        |
| PHADDW          | xmmreg,xmmrm          | [rm: 66 0f 38 01 /r]              | SSSE3               |
| PHADDD          | mmxreg,mmxrm          | [rm: np 0f 38 02 /r]              | SSSE3,MMX,SQ        |
| PHADDD          | xmmreg,xmmrm          | [rm: 66 0f 38 02 /r]              | SSSE3               |
| PHADDSW         | mmxreg,mmxrm          | [rm: np 0f 38 03 /r]              | SSSE3,MMX,SQ        |
| PHADDSW         | xmmreg,xmmrm          | [rm: 66 0f 38 03 /r]              | SSSE3               |
| PHSUBW          | mmxreg,mmxrm          | [rm: np 0f 38 05 /r]              | SSSE3,MMX,SQ        |
| PHSUBW          | xmmreg,xmmrm          | [rm: 66 0f 38 05 /r]              | SSSE3               |
| PHSUBD          | mmxreg,mmxrm          | [rm: np 0f 38 06 /r]              | SSSE3,MMX,SQ        |
| PHSUBD          | xmmreg,xmmrm          | [rm: 66 0f 38 06 /r]              | SSSE3               |
| PHSUBSW         | mmxreg,mmxrm          | [rm: np 0f 38 07 /r]              | SSSE3,MMX,SQ        |
| PHSUBSW         | xmmreg,xmmrm          | [rm: 66 0f 38 07 /r]              | SSSE3               |
| PMADDUBSW       | mmxreg,mmxrm          | [rm: np 0f 38 04 /r]              | SSSE3,MMX,SQ        |
| PMADDUBSW       | xmmreg,xmmrm          | [rm: 66 0f 38 04 /r]              | SSSE3               |
| PMULHRSW        | mmxreg,mmxrm          | [rm: np 0f 38 0b /r]              | SSSE3,MMX,SQ        |
| PMULHRSW        | xmmreg,xmmrm          | [rm: 66 0f 38 0b /r]              | SSSE3               |
| PSHUFB          | mmxreg,mmxrm          | [rm: np 0f 38 00 /r]              | SSSE3,MMX,SQ        |
| PSHUFB          | xmmreg,xmmrm          | [rm: 66 0f 38 00 /r]              | SSSE3               |
| PSIGNB          | mmxreg,mmxrm          | [rm: np 0f 38 08 /r]              | SSSE3,MMX,SQ        |
| PSIGNB          | xmmreg,xmmrm          | [rm: 66 0f 38 08 /r]              | SSSE3               |
| PSIGNW          | mmxreg,mmxrm          | [rm: np 0f 38 09 /r]              | SSSE3,MMX,SQ        |
| PSIGNW          | xmmreg,xmmrm          | [rm: 66 0f 38 09 /r]              | SSSE3               |
| PSIGND          | mmxreg,mmxrm          | [rm: np 0f 38 0a /r]              | SSSE3,MMX,SQ        |
| PSIGND          | xmmreg,xmmrm          | [rm: 66 0f 38 0a /r]              | SSSE3               |
| EXTRQ           | xmmreg,imm,imm        | [mij: 66 0f 78 /0 ib,u ib,u]      | SSE4A,AMD           |
| EXTRQ           | xmmreg,xmmreg         | [rm: 66 0f 79 /r]                 | SSE4A,AMD           |
| INSERTQ         | xmmreg,xmmreg,imm,imm | [rmij: f2 0f 78 /r ib,u ib,u]     | SSE4A,AMD           |
| INSERTQ         | xmmreg,xmmreg         | [rm: f2 0f 79 /r]                 | SSE4A,AMD           |
| MOVNTSD         | mem,xmmreg            | [mr: f2 0f 2b /r]                 | SSE4A,AMD,SQ        |
| MOVNTSS         | mem,xmmreg            | [mr: f3 0f 2b /r]                 | SSE4A,AMD,SD        |
| LZCNT           | reg16,rm16            | [rm: o16 f3i 0f bd /r]            | P6,AMD              |
| LZCNT           | reg32,rm32            | [rm: o32 f3i 0f bd /r]            | P6,AMD              |
| LZCNT           | reg64,rm64            | [rm: o64 f3i 0f bd /r]            | X64,AMD             |
| BLENDPD         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0d /r ib,u]        | SSE41               |
| BLENDPS         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0c /r ib,u]        | SSE41               |
| BLENDVPD        | xmmreg,xmmrm,xmm0     | [rm-: 66 0f 38 15 /r]             | SSE41               |
| BLENDVPD        | xmmreg,xmmrm          | [rm: 66 0f 38 15 /r]              | SSE41               |
| BLENDVPS        | xmmreg,xmmrm,xmm0     | [rm-: 66 0f 38 14 /r]             | SSE41               |
| BLENDVPS        | xmmreg,xmmrm          | [rm: 66 0f 38 14 /r]              | SSE41               |
| DPPD            | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 41 /r ib,u]        | SSE41               |
| DPPS            | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 40 /r ib,u]        | SSE41               |
| EXTRACTPS       | rm32,xmmreg,imm       | [mri: 66 0f 3a 17 /r ib,u]        | SSE41               |
| EXTRACTPS       | reg64,xmmreg,imm      | [mri: o64 66 0f 3a 17 /r ib,u]    | SSE41,X64           |
| INSERTPS        | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 21 /r ib,u]        | SSE41,SD            |
| MOVNTDQA        | xmmreg,mem128         | [rm: 66 0f 38 2a /r]              | SSE41               |
| MPSADBW         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 42 /r ib,u]        | SSE41               |
| PACKUSDW        | xmmreg,xmmrm          | [rm: 66 0f 38 2b /r]              | SSE41               |
| PBLENDVB        | xmmreg,xmmrm,xmm0     | [rm-: 66 0f 38 10 /r]             | SSE41               |
| PBLENDVB        | xmmreg,xmmrm          | [rm: 66 0f 38 10 /r]              | SSE41               |
| PBLENDW         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0e /r ib,u]        | SSE41               |
| PCMPEQQ         | xmmreg,xmmrm          | [rm: 66 0f 38 29 /r]              | SSE41               |
| PEXTRB          | reg32,xmmreg,imm      | [mri: 66 0f 3a 14 /r ib,u]        | SSE41               |
| PEXTRB          | mem8,xmmreg,imm       | [mri: 66 0f 3a 14 /r ib,u]        | SSE41               |
| PEXTRB          | reg64,xmmreg,imm      | [mri: o64nw 66 0f 3a 14 /r ib,u]  | SSE41,X64           |
| PEXTRD          | rm32,xmmreg,imm       | [mri: norexw 66 0f 3a 16 /r ib,u] | SSE41               |
| PEXTRQ          | rm64,xmmreg,imm       | [mri: o64 66 0f 3a 16 /r ib,u]    | SSE41,X64           |
| PEXTRW          | reg32,xmmreg,imm      | [mri: 66 0f 3a 15 /r ib,u]        | SSE41               |
| PEXTRW          | mem16,xmmreg,imm      | [mri: 66 0f 3a 15 /r ib,u]        | SSE41               |
| PEXTRW          | reg64,xmmreg,imm      | [mri: o64 66 0f 3a 15 /r ib,u]    | SSE41,X64           |
| PHMINPOSUW      | xmmreg,xmmrm          | [rm: 66 0f 38 41 /r]              | SSE41               |
| PINSRB          | xmmreg,mem,imm        | [rmi: 66 0f 3a 20 /r ib,u]        | SSE41,SB,AR2        |
| PINSRB          | xmmreg,rm8,imm        | [rmi: nohi 66 0f 3a 20 /r ib,u]   | SSE41,SB,AR2        |
| PINSRB          | xmmreg,reg32,imm      | [rmi: 66 0f 3a 20 /r ib,u]        | SSE41,SB,AR2        |
| PINSRD          | xmmreg,mem,imm        | [rmi: norexw 66 0f 3a 22 /r ib,u] | SSE41,SB,AR2        |
| PINSRD          | xmmreg,rm32,imm       | [rmi: norexw 66 0f 3a 22 /r ib,u] | SSE41,SB,AR2        |
| PINSRQ          | xmmreg,mem,imm        | [rmi: o64 66 0f 3a 22 /r ib,u]    | SSE41,X64,SB,AR2    |
| PINSRQ          | xmmreg,rm64,imm       | [rmi: o64 66 0f 3a 22 /r ib,u]    | SSE41,X64,SB,AR2    |
| PMAXSB          | xmmreg,xmmrm          | [rm: 66 0f 38 3c /r]              | SSE41               |
| PMAXSD          | xmmreg,xmmrm          | [rm: 66 0f 38 3d /r]              | SSE41               |
| PMAXUD          | xmmreg,xmmrm          | [rm: 66 0f 38 3f /r]              | SSE41               |
| PMAXUW          | xmmreg,xmmrm          | [rm: 66 0f 38 3e /r]              | SSE41               |
| PMINSB          | xmmreg,xmmrm          | [rm: 66 0f 38 38 /r]              | SSE41               |
| PMINSD          | xmmreg,xmmrm          | [rm: 66 0f 38 39 /r]              | SSE41               |
| PMINUD          | xmmreg,xmmrm          | [rm: 66 0f 38 3b /r]              | SSE41               |
| PMINUW          | xmmreg,xmmrm          | [rm: 66 0f 38 3a /r]              | SSE41               |
| PMOVSXBW        | xmmreg,xmmrm          | [rm: 66 0f 38 20 /r]              | SSE41,SQ            |
| PMOVSXBD        | xmmreg,xmmrm          | [rm: 66 0f 38 21 /r]              | SSE41,SD            |
| PMOVSXBQ        | xmmreg,xmmrm          | [rm: 66 0f 38 22 /r]              | SSE41,SW            |
| PMOVSXWD        | xmmreg,xmmrm          | [rm: 66 0f 38 23 /r]              | SSE41,SQ            |
| PMOVSXWQ        | xmmreg,xmmrm          | [rm: 66 0f 38 24 /r]              | SSE41,SD            |
| PMOVSXDQ        | xmmreg,xmmrm          | [rm: 66 0f 38 25 /r]              | SSE41,SQ            |
| PMOVZXBW        | xmmreg,xmmrm          | [rm: 66 0f 38 30 /r]              | SSE41,SQ            |
| PMOVZXBD        | xmmreg,xmmrm          | [rm: 66 0f 38 31 /r]              | SSE41,SD            |
| PMOVZXBQ        | xmmreg,xmmrm          | [rm: 66 0f 38 32 /r]              | SSE41,SW            |
| PMOVZXWD        | xmmreg,xmmrm          | [rm: 66 0f 38 33 /r]              | SSE41,SQ            |
| PMOVZXWQ        | xmmreg,xmmrm          | [rm: 66 0f 38 34 /r]              | SSE41,SD            |
| PMOVZXDQ        | xmmreg,xmmrm          | [rm: 66 0f 38 35 /r]              | SSE41,SQ            |
| PMULDQ          | xmmreg,xmmrm          | [rm: 66 0f 38 28 /r]              | SSE41               |
| PMULLD          | xmmreg,xmmrm          | [rm: 66 0f 38 40 /r]              | SSE41               |
| PTEST           | xmmreg,xmmrm          | [rm: 66 0f 38 17 /r]              | SSE41               |
| ROUNDPD         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 09 /r ib,u]        | SSE41               |
| ROUNDPS         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 08 /r ib,u]        | SSE41               |
| ROUNDSD         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0b /r ib,u]        | SSE41               |
| ROUNDSS         | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 0a /r ib,u]        | SSE41               |
| CRC32           | reg32,rm8             | [rm: f2i 0f 38 f0 /r]             | SSE42               |
| CRC32           | reg32,rm16            | [rm: o16 f2i 0f 38 f1 /r]         | SSE42               |
| CRC32           | reg32,rm32            | [rm: o32 f2i 0f 38 f1 /r]         | SSE42               |
| CRC32           | reg64,rm8             | [rm: o64 f2i 0f 38 f0 /r]         | SSE42,X64           |
| CRC32           | reg64,rm64            | [rm: o64 f2i 0f 38 f1 /r]         | SSE42,X64           |
| PCMPESTRI       | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 61 /r ib,u]        | SSE42               |
| PCMPESTRM       | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 60 /r ib,u]        | SSE42               |
| PCMPISTRI       | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 63 /r ib,u]        | SSE42               |
| PCMPISTRM       | xmmreg,xmmrm,imm      | [rmi: 66 0f 3a 62 /r ib,u]        | SSE42               |
| PCMPGTQ         | xmmreg,xmmrm          | [rm: 66 0f 38 37 /r]              | SSE42               |
| POPCNT          | reg16,rm16            | [rm: o16 f3i 0f b8 /r]            | SW                  |
| POPCNT          | reg32,rm32            | [rm: o32 f3i 0f b8 /r]            | SD                  |
| POPCNT          | reg64,rm64            | [rm: o64 f3i 0f b8 /r]            | SQ,X64              |
| GETSEC          | void                  | [0f 37]                           | KATMAI              |
| PFRCPV          | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 86]           | PENT,3DNOW,SQ,CYRIX |
| PFRSQRTV        | mmxreg,mmxrm          | [rm: o64nw 0f 0f /r 87]           | PENT,3DNOW,SQ,CYRIX |
| MOVBE           | reg16,mem16           | [rm: o16 norep 0f 38 f0 /r]       | SM                  |
| MOVBE           | reg32,mem32           | [rm: o32 norep 0f 38 f0 /r]       | SM                  |
| MOVBE           | reg64,mem64           | [rm: o64 norep 0f 38 f0 /r]       | SM                  |
| MOVBE           | mem16,reg16           | [mr: o16 norep 0f 38 f1 /r]       | SM                  |
| MOVBE           | mem32,reg32           | [mr: o32 norep 0f 38 f1 /r]       | SM                  |
| MOVBE           | mem64,reg64           | [mr: o64 norep 0f 38 f1 /r]       | SM                  |
| AESENC          | xmmreg,xmmrm128       | [rm: 66 0f 38 dc /r]              | SSE                 |
| AESENCLAST      | xmmreg,xmmrm128       | [rm: 66 0f 38 dd /r]              | SSE                 |
| AESDEC          | xmmreg,xmmrm128       | [rm: 66 0f 38 de /r]              | SSE                 |
| AESDECLAST      | xmmreg,xmmrm128       | [rm: 66 0f 38 df /r]              | SSE                 |
| AESIMC          | xmmreg,xmmrm128       | [rm: 66 0f 38 db /r]              | SSE                 |
| AESKEYGENASSIST | xmmreg,xmmrm128,imm8  | [rmi: 66 0f 3a df /r ib]          | SSE                 |

AVX
---------------------------------------------------------------------------------------------------------------------------------
| VAESENC          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 dc /r]             | AVX                  |
| VAESENCLAST      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 dd /r]             | AVX                  |
| VAESDEC          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 de /r]             | AVX                  |
| VAESDECLAST      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 df /r]             | AVX                  |
| VAESIMC          | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 db /r]                  | AVX                  |
| VAESKEYGENASSIST | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a df /r ib]              | AVX                  |
| VAESENC          | ymmreg,ymmreg*,ymmrm256        | [rvm:   vex.nds.256.66.0f38.wig dc /r]       | VAES                 |
| VAESENCLAST      | ymmreg,ymmreg*,ymmrm256        | [rvm:   vex.nds.256.66.0f38.wig dd /r]       | VAES                 |
| VAESDEC          | ymmreg,ymmreg*,ymmrm256        | [rvm:   vex.nds.256.66.0f38.wig de /r]       | VAES                 |
| VAESDECLAST      | ymmreg,ymmreg*,ymmrm256        | [rvm:   vex.nds.256.66.0f38.wig df /r]       | VAES                 |
| VAESENC          | xmmreg,xmmreg*,xmmrm128        | [rvm:fv: evex.nds.128.66.0f38.wig dc /r]     | AVX512VL,AVX512,VAES |
| VAESENC          | ymmreg,ymmreg*,ymmrm256        | [rvm:fv: evex.nds.256.66.0f38.wig dc /r]     | AVX512VL,AVX512,VAES |
| VAESENCLAST      | xmmreg,xmmreg*,xmmrm128        | [rvm:fv: evex.nds.128.66.0f38.wig dd /r]     | AVX512VL,AVX512,VAES |
| VAESENCLAST      | ymmreg,ymmreg*,ymmrm256        | [rvm:fv: evex.nds.256.66.0f38.wig dd /r]     | AVX512VL,AVX512,VAES |
| VAESDEC          | xmmreg,xmmreg*,xmmrm128        | [rvm:fv: evex.nds.128.66.0f38.wig de /r]     | AVX512VL,AVX512,VAES |
| VAESDEC          | ymmreg,ymmreg*,ymmrm256        | [rvm:fv: evex.nds.256.66.0f38.wig de /r]     | AVX512VL,AVX512,VAES |
| VAESDECLAST      | xmmreg,xmmreg*,xmmrm128        | [rvm:fv: evex.nds.128.66.0f38.wig df /r]     | AVX512VL,AVX512,VAES |
| VAESDECLAST      | ymmreg,ymmreg*,ymmrm256        | [rvm:fv: evex.nds.256.66.0f38.wig df /r]     | AVX512VL,AVX512,VAES |
| VAESENC          | zmmreg,zmmreg*,zmmrm512        | [rvm:fv: evex.nds.512.66.0f38.wig dc /r]     | AVX512,VAES          |
| VAESENCLAST      | zmmreg,zmmreg*,zmmrm512        | [rvm:fv: evex.nds.512.66.0f38.wig dd /r]     | AVX512,VAES          |
| VAESDEC          | zmmreg,zmmreg*,zmmrm512        | [rvm:fv: evex.nds.512.66.0f38.wig de /r]     | AVX512,VAES          |
| VAESDECLAST      | zmmreg,zmmreg*,zmmrm512        | [rvm:fv: evex.nds.512.66.0f38.wig df /r]     | AVX512,VAES          |
| VADDPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 58 /r]               | AVX                  |
| VADDPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 58 /r]               | AVX                  |
| VADDPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 58 /r]                  | AVX                  |
| VADDPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 58 /r]                  | AVX                  |
| VADDSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 58 /r]               | AVX                  |
| VADDSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 58 /r]               | AVX                  |
| VADDSUBPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d0 /r]               | AVX                  |
| VADDSUBPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f d0 /r]               | AVX                  |
| VADDSUBPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.f2.0f d0 /r]               | AVX                  |
| VADDSUBPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.f2.0f d0 /r]               | AVX                  |
| VANDPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 54 /r]               | AVX                  |
| VANDPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 54 /r]               | AVX                  |
| VANDPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 54 /r]                  | AVX                  |
| VANDPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 54 /r]                  | AVX                  |
| VANDNPD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 55 /r]               | AVX                  |
| VANDNPD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 55 /r]               | AVX                  |
| VANDNPS          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 55 /r]                  | AVX                  |
| VANDNPS          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 55 /r]                  | AVX                  |
| VBLENDPD         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 0d /r ib]         | AVX                  |
| VBLENDPD         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 0d /r ib]         | AVX                  |
| VBLENDPS         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 0c /r ib]         | AVX                  |
| VBLENDPS         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 0c /r ib]         | AVX                  |
| VBLENDVPD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.nds.128.66.0f3a.w0 4b /r /is4]    | AVX                  |
| VBLENDVPD        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.nds.256.66.0f3a.w0 4b /r /is4]    | AVX                  |
| VBLENDVPS        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.nds.128.66.0f3a.w0 4a /r /is4]    | AVX                  |
| VBLENDVPS        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.nds.256.66.0f3a.w0 4a /r /is4]    | AVX                  |
| VBROADCASTSS     | xmmreg,mem32                   | [rm: vex.128.66.0f38.w0 18 /r]               | AVX                  |
| VBROADCASTSS     | ymmreg,mem32                   | [rm: vex.256.66.0f38.w0 18 /r]               | AVX                  |
| VBROADCASTSD     | ymmreg,mem64                   | [rm: vex.256.66.0f38.w0 19 /r]               | AVX                  |
| VBROADCASTF128   | ymmreg,mem128                  | [rm: vex.256.66.0f38.w0 1a /r]               | AVX                  |
| VCMPEQ_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 10]            | AVX                  |
| VCMPEQ_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 10]            | AVX                  |
| VCMPEQPD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 00]            | AVX                  |
| VCMPEQPD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 00]            | AVX                  |
| VCMPLT_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 01]            | AVX                  |
| VCMPLT_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 01]            | AVX                  |
| VCMPLTPD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 01]            | AVX                  |
| VCMPLTPD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 01]            | AVX                  |
| VCMPLE_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 02]            | AVX                  |
| VCMPLE_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 02]            | AVX                  |
| VCMPLEPD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 02]            | AVX                  |
| VCMPLEPD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 02]            | AVX                  |
| VCMPUNORD_QPD    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 03]            | AVX                  |
| VCMPUNORD_QPD    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 03]            | AVX                  |
| VCMPUNORDPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 03]            | AVX                  |
| VCMPUNORDPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 03]            | AVX                  |
| VCMPNEQ_UQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 04]            | AVX                  |
| VCMPNEQ_UQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 04]            | AVX                  |
| VCMPNEQPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 04]            | AVX                  |
| VCMPNEQPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 04]            | AVX                  |
| VCMPNLT_USPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 05]            | AVX                  |
| VCMPNLT_USPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 05]            | AVX                  |
| VCMPNLTPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 05]            | AVX                  |
| VCMPNLTPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 05]            | AVX                  |
| VCMPNLE_USPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 06]            | AVX                  |
| VCMPNLE_USPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 06]            | AVX                  |
| VCMPNLEPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 06]            | AVX                  |
| VCMPNLEPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 06]            | AVX                  |
| VCMPORD_QPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 07]            | AVX                  |
| VCMPORD_QPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 07]            | AVX                  |
| VCMPORDPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 07]            | AVX                  |
| VCMPORDPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 07]            | AVX                  |
| VCMPEQ_UQPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 08]            | AVX                  |
| VCMPEQ_UQPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 08]            | AVX                  |
| VCMPNGE_USPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 09]            | AVX                  |
| VCMPNGE_USPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 09]            | AVX                  |
| VCMPNGEPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 09]            | AVX                  |
| VCMPNGEPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 09]            | AVX                  |
| VCMPNGT_USPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0a]            | AVX                  |
| VCMPNGT_USPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0a]            | AVX                  |
| VCMPNGTPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0a]            | AVX                  |
| VCMPNGTPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0a]            | AVX                  |
| VCMPFALSE_OQPD   | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0b]            | AVX                  |
| VCMPFALSE_OQPD   | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0b]            | AVX                  |
| VCMPFALSEPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0b]            | AVX                  |
| VCMPFALSEPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0b]            | AVX                  |
| VCMPNEQ_OQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0c]            | AVX                  |
| VCMPNEQ_OQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0c]            | AVX                  |
| VCMPGE_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0d]            | AVX                  |
| VCMPGE_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0d]            | AVX                  |
| VCMPGEPD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0d]            | AVX                  |
| VCMPGEPD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0d]            | AVX                  |
| VCMPGT_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0e]            | AVX                  |
| VCMPGT_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0e]            | AVX                  |
| VCMPGTPD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0e]            | AVX                  |
| VCMPGTPD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0e]            | AVX                  |
| VCMPTRUE_UQPD    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0f]            | AVX                  |
| VCMPTRUE_UQPD    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0f]            | AVX                  |
| VCMPTRUEPD       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 0f]            | AVX                  |
| VCMPTRUEPD       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 0f]            | AVX                  |
| VCMPEQ_OSPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 10]            | AVX                  |
| VCMPEQ_OSPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 10]            | AVX                  |
| VCMPLT_OQPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 11]            | AVX                  |
| VCMPLT_OQPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 11]            | AVX                  |
| VCMPLE_OQPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 12]            | AVX                  |
| VCMPLE_OQPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 12]            | AVX                  |
| VCMPUNORD_SPD    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 13]            | AVX                  |
| VCMPUNORD_SPD    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 13]            | AVX                  |
| VCMPNEQ_USPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 14]            | AVX                  |
| VCMPNEQ_USPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 14]            | AVX                  |
| VCMPNLT_UQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 15]            | AVX                  |
| VCMPNLT_UQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 15]            | AVX                  |
| VCMPNLE_UQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 16]            | AVX                  |
| VCMPNLE_UQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 16]            | AVX                  |
| VCMPORD_SPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 17]            | AVX                  |
| VCMPORD_SPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 17]            | AVX                  |
| VCMPEQ_USPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 18]            | AVX                  |
| VCMPEQ_USPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 18]            | AVX                  |
| VCMPNGE_UQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 19]            | AVX                  |
| VCMPNGE_UQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 19]            | AVX                  |
| VCMPNGT_UQPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1a]            | AVX                  |
| VCMPNGT_UQPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1a]            | AVX                  |
| VCMPFALSE_OSPD   | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1b]            | AVX                  |
| VCMPFALSE_OSPD   | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1b]            | AVX                  |
| VCMPNEQ_OSPD     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1c]            | AVX                  |
| VCMPNEQ_OSPD     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1c]            | AVX                  |
| VCMPGE_OQPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1d]            | AVX                  |
| VCMPGE_OQPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1d]            | AVX                  |
| VCMPGT_OQPD      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1e]            | AVX                  |
| VCMPGT_OQPD      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1e]            | AVX                  |
| VCMPTRUE_USPD    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f c2 /r 1f]            | AVX                  |
| VCMPTRUE_USPD    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f c2 /r 1f]            | AVX                  |
| VCMPPD           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f c2 /r ib]           | AVX                  |
| VCMPPD           | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f c2 /r ib]           | AVX                  |
| VCMPEQ_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 10]               | AVX                  |
| VCMPEQ_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 10]               | AVX                  |
| VCMPEQPS         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 00]               | AVX                  |
| VCMPEQPS         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 00]               | AVX                  |
| VCMPLT_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 01]               | AVX                  |
| VCMPLT_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 01]               | AVX                  |
| VCMPLTPS         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 01]               | AVX                  |
| VCMPLTPS         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 01]               | AVX                  |
| VCMPLE_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 02]               | AVX                  |
| VCMPLE_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 02]               | AVX                  |
| VCMPLEPS         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 02]               | AVX                  |
| VCMPLEPS         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 02]               | AVX                  |
| VCMPUNORD_QPS    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 03]               | AVX                  |
| VCMPUNORD_QPS    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 03]               | AVX                  |
| VCMPUNORDPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 03]               | AVX                  |
| VCMPUNORDPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 03]               | AVX                  |
| VCMPNEQ_UQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 04]               | AVX                  |
| VCMPNEQ_UQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 04]               | AVX                  |
| VCMPNEQPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 04]               | AVX                  |
| VCMPNEQPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 04]               | AVX                  |
| VCMPNLT_USPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 05]               | AVX                  |
| VCMPNLT_USPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 05]               | AVX                  |
| VCMPNLTPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 05]               | AVX                  |
| VCMPNLTPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 05]               | AVX                  |
| VCMPNLE_USPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 06]               | AVX                  |
| VCMPNLE_USPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 06]               | AVX                  |
| VCMPNLEPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 06]               | AVX                  |
| VCMPNLEPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 06]               | AVX                  |
| VCMPORD_QPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 07]               | AVX                  |
| VCMPORD_QPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 07]               | AVX                  |
| VCMPORDPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 07]               | AVX                  |
| VCMPORDPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 07]               | AVX                  |
| VCMPEQ_UQPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 08]               | AVX                  |
| VCMPEQ_UQPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 08]               | AVX                  |
| VCMPNGE_USPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 09]               | AVX                  |
| VCMPNGE_USPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 09]               | AVX                  |
| VCMPNGEPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 09]               | AVX                  |
| VCMPNGEPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 09]               | AVX                  |
| VCMPNGT_USPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0a]               | AVX                  |
| VCMPNGT_USPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0a]               | AVX                  |
| VCMPNGTPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0a]               | AVX                  |
| VCMPNGTPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0a]               | AVX                  |
| VCMPFALSE_OQPS   | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0b]               | AVX                  |
| VCMPFALSE_OQPS   | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0b]               | AVX                  |
| VCMPFALSEPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0b]               | AVX                  |
| VCMPFALSEPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0b]               | AVX                  |
| VCMPNEQ_OQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0c]               | AVX                  |
| VCMPNEQ_OQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0c]               | AVX                  |
| VCMPGE_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0d]               | AVX                  |
| VCMPGE_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0d]               | AVX                  |
| VCMPGEPS         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0d]               | AVX                  |
| VCMPGEPS         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0d]               | AVX                  |
| VCMPGT_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0e]               | AVX                  |
| VCMPGT_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0e]               | AVX                  |
| VCMPGTPS         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0e]               | AVX                  |
| VCMPGTPS         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0e]               | AVX                  |
| VCMPTRUE_UQPS    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0f]               | AVX                  |
| VCMPTRUE_UQPS    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0f]               | AVX                  |
| VCMPTRUEPS       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 0f]               | AVX                  |
| VCMPTRUEPS       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 0f]               | AVX                  |
| VCMPEQ_OSPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 10]               | AVX                  |
| VCMPEQ_OSPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 10]               | AVX                  |
| VCMPLT_OQPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 11]               | AVX                  |
| VCMPLT_OQPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 11]               | AVX                  |
| VCMPLE_OQPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 12]               | AVX                  |
| VCMPLE_OQPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 12]               | AVX                  |
| VCMPUNORD_SPS    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 13]               | AVX                  |
| VCMPUNORD_SPS    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 13]               | AVX                  |
| VCMPNEQ_USPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 14]               | AVX                  |
| VCMPNEQ_USPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 14]               | AVX                  |
| VCMPNLT_UQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 15]               | AVX                  |
| VCMPNLT_UQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 15]               | AVX                  |
| VCMPNLE_UQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 16]               | AVX                  |
| VCMPNLE_UQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 16]               | AVX                  |
| VCMPORD_SPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 17]               | AVX                  |
| VCMPORD_SPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 17]               | AVX                  |
| VCMPEQ_USPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 18]               | AVX                  |
| VCMPEQ_USPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 18]               | AVX                  |
| VCMPNGE_UQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 19]               | AVX                  |
| VCMPNGE_UQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 19]               | AVX                  |
| VCMPNGT_UQPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1a]               | AVX                  |
| VCMPNGT_UQPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1a]               | AVX                  |
| VCMPFALSE_OSPS   | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1b]               | AVX                  |
| VCMPFALSE_OSPS   | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1b]               | AVX                  |
| VCMPNEQ_OSPS     | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1c]               | AVX                  |
| VCMPNEQ_OSPS     | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1c]               | AVX                  |
| VCMPGE_OQPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1d]               | AVX                  |
| VCMPGE_OQPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1d]               | AVX                  |
| VCMPGT_OQPS      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1e]               | AVX                  |
| VCMPGT_OQPS      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1e]               | AVX                  |
| VCMPTRUE_USPS    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f c2 /r 1f]               | AVX                  |
| VCMPTRUE_USPS    | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f c2 /r 1f]               | AVX                  |
| VCMPPS           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.0f c2 /r ib]              | AVX                  |
| VCMPPS           | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.0f c2 /r ib]              | AVX                  |
| VCMPEQ_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 10]            | AVX                  |
| VCMPEQSD         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 00]            | AVX                  |
| VCMPLT_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 01]            | AVX                  |
| VCMPLTSD         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 01]            | AVX                  |
| VCMPLE_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 02]            | AVX                  |
| VCMPLESD         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 02]            | AVX                  |
| VCMPUNORD_QSD    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 03]            | AVX                  |
| VCMPUNORDSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 03]            | AVX                  |
| VCMPNEQ_UQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 04]            | AVX                  |
| VCMPNEQSD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 04]            | AVX                  |
| VCMPNLT_USSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 05]            | AVX                  |
| VCMPNLTSD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 05]            | AVX                  |
| VCMPNLE_USSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 06]            | AVX                  |
| VCMPNLESD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 06]            | AVX                  |
| VCMPORD_QSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 07]            | AVX                  |
| VCMPORDSD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 07]            | AVX                  |
| VCMPEQ_UQSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 08]            | AVX                  |
| VCMPNGE_USSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 09]            | AVX                  |
| VCMPNGESD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 09]            | AVX                  |
| VCMPNGT_USSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0a]            | AVX                  |
| VCMPNGTSD        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0a]            | AVX                  |
| VCMPFALSE_OQSD   | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0b]            | AVX                  |
| VCMPFALSESD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0b]            | AVX                  |
| VCMPNEQ_OQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0c]            | AVX                  |
| VCMPGE_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0d]            | AVX                  |
| VCMPGESD         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0d]            | AVX                  |
| VCMPGT_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0e]            | AVX                  |
| VCMPGTSD         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0e]            | AVX                  |
| VCMPTRUE_UQSD    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0f]            | AVX                  |
| VCMPTRUESD       | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 0f]            | AVX                  |
| VCMPEQ_OSSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 10]            | AVX                  |
| VCMPLT_OQSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 11]            | AVX                  |
| VCMPLE_OQSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 12]            | AVX                  |
| VCMPUNORD_SSD    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 13]            | AVX                  |
| VCMPNEQ_USSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 14]            | AVX                  |
| VCMPNLT_UQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 15]            | AVX                  |
| VCMPNLE_UQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 16]            | AVX                  |
| VCMPORD_SSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 17]            | AVX                  |
| VCMPEQ_USSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 18]            | AVX                  |
| VCMPNGE_UQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 19]            | AVX                  |
| VCMPNGT_UQSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1a]            | AVX                  |
| VCMPFALSE_OSSD   | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1b]            | AVX                  |
| VCMPNEQ_OSSD     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1c]            | AVX                  |
| VCMPGE_OQSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1d]            | AVX                  |
| VCMPGT_OQSD      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1e]            | AVX                  |
| VCMPTRUE_USSD    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f c2 /r 1f]            | AVX                  |
| VCMPSD           | xmmreg,xmmreg*,xmmrm64,imm8    | [rvmi: vex.nds.lig.f2.0f c2 /r ib]           | AVX                  |
| VCMPEQ_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 10]            | AVX                  |
| VCMPEQSS         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 00]            | AVX                  |
| VCMPLT_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 01]            | AVX                  |
| VCMPLTSS         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 01]            | AVX                  |
| VCMPLE_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 02]            | AVX                  |
| VCMPLESS         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 02]            | AVX                  |
| VCMPUNORD_QSS    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 03]            | AVX                  |
| VCMPUNORDSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 03]            | AVX                  |
| VCMPNEQ_UQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 04]            | AVX                  |
| VCMPNEQSS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 04]            | AVX                  |
| VCMPNLT_USSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 05]            | AVX                  |
| VCMPNLTSS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 05]            | AVX                  |
| VCMPNLE_USSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 06]            | AVX                  |
| VCMPNLESS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 06]            | AVX                  |
| VCMPORD_QSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 07]            | AVX                  |
| VCMPORDSS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 07]            | AVX                  |
| VCMPEQ_UQSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 08]            | AVX                  |
| VCMPNGE_USSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 09]            | AVX                  |
| VCMPNGESS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 09]            | AVX                  |
| VCMPNGT_USSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0a]            | AVX                  |
| VCMPNGTSS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0a]            | AVX                  |
| VCMPFALSE_OQSS   | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0b]            | AVX                  |
| VCMPFALSESS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0b]            | AVX                  |
| VCMPNEQ_OQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0c]            | AVX                  |
| VCMPGE_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0d]            | AVX                  |
| VCMPGESS         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0d]            | AVX                  |
| VCMPGT_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0e]            | AVX                  |
| VCMPGTSS         | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0e]            | AVX                  |
| VCMPTRUE_UQSS    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0f]            | AVX                  |
| VCMPTRUESS       | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 0f]            | AVX                  |
| VCMPEQ_OSSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 10]            | AVX                  |
| VCMPLT_OQSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 11]            | AVX                  |
| VCMPLE_OQSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 12]            | AVX                  |
| VCMPUNORD_SSS    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 13]            | AVX                  |
| VCMPNEQ_USSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 14]            | AVX                  |
| VCMPNLT_UQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 15]            | AVX                  |
| VCMPNLE_UQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 16]            | AVX                  |
| VCMPORD_SSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 17]            | AVX                  |
| VCMPEQ_USSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 18]            | AVX                  |
| VCMPNGE_UQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 19]            | AVX                  |
| VCMPNGT_UQSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1a]            | AVX                  |
| VCMPFALSE_OSSS   | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1b]            | AVX                  |
| VCMPNEQ_OSSS     | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1c]            | AVX                  |
| VCMPGE_OQSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1d]            | AVX                  |
| VCMPGT_OQSS      | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1e]            | AVX                  |
| VCMPTRUE_USSS    | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f3.0f c2 /r 1f]            | AVX                  |
| VCMPSS           | xmmreg,xmmreg*,xmmrm64,imm8    | [rvmi: vex.nds.lig.f3.0f c2 /r ib]           | AVX                  |
| VCOMISD          | xmmreg,xmmrm64                 | [rm: vex.lig.66.0f 2f /r]                    | AVX                  |
| VCOMISS          | xmmreg,xmmrm32                 | [rm: vex.lig.0f 2f /r]                       | AVX                  |
| VCVTDQ2PD        | xmmreg,xmmrm64                 | [rm: vex.128.f3.0f e6 /r]                    | AVX                  |
| VCVTDQ2PD        | ymmreg,xmmrm128                | [rm: vex.256.f3.0f e6 /r]                    | AVX                  |
| VCVTDQ2PS        | xmmreg,xmmrm128                | [rm: vex.128.0f 5b /r]                       | AVX                  |
| VCVTDQ2PS        | ymmreg,ymmrm256                | [rm: vex.256.0f 5b /r]                       | AVX                  |
| VCVTPD2DQ        | xmmreg,xmmreg                  | [rm: vex.128.f2.0f e6 /r]                    | AVX                  |
| VCVTPD2DQ        | xmmreg,mem128                  | [rm: vex.128.f2.0f e6 /r]                    | AVX,SO               |
| VCVTPD2DQ        | xmmreg,ymmreg                  | [rm: vex.256.f2.0f e6 /r]                    | AVX                  |
| VCVTPD2DQ        | xmmreg,mem256                  | [rm: vex.256.f2.0f e6 /r]                    | AVX,SY               |
| VCVTPD2PS        | xmmreg,xmmreg                  | [rm: vex.128.66.0f 5a /r]                    | AVX                  |
| VCVTPD2PS        | xmmreg,mem128                  | [rm: vex.128.66.0f 5a /r]                    | AVX,SO               |
| VCVTPD2PS        | xmmreg,ymmreg                  | [rm: vex.256.66.0f 5a /r]                    | AVX                  |
| VCVTPD2PS        | xmmreg,mem256                  | [rm: vex.256.66.0f 5a /r]                    | AVX,SY               |
| VCVTPS2DQ        | xmmreg,xmmrm128                | [rm: vex.128.66.0f 5b /r]                    | AVX                  |
| VCVTPS2DQ        | ymmreg,ymmrm256                | [rm: vex.256.66.0f 5b /r]                    | AVX                  |
| VCVTPS2PD        | xmmreg,xmmrm64                 | [rm: vex.128.0f 5a /r]                       | AVX                  |
| VCVTPS2PD        | ymmreg,xmmrm128                | [rm: vex.256.0f 5a /r]                       | AVX                  |
| VCVTSD2SI        | reg32,xmmrm64                  | [rm: vex.lig.f2.0f.w0 2d /r]                 | AVX                  |
| VCVTSD2SI        | reg64,xmmrm64                  | [rm: vex.lig.f2.0f.w1 2d /r]                 | AVX,LONG             |
| VCVTSD2SS        | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 5a /r]               | AVX                  |
| VCVTSI2SD        | xmmreg,xmmreg*,rm32            | [rvm: vex.nds.lig.f2.0f.w0 2a /r]            | AVX,SD               |
| VCVTSI2SD        | xmmreg,xmmreg*,mem32           | [rvm: vex.nds.lig.f2.0f.w0 2a /r]            | AVX,ND,SD            |
| VCVTSI2SD        | xmmreg,xmmreg*,rm64            | [rvm: vex.nds.lig.f2.0f.w1 2a /r]            | AVX,LONG,SQ          |
| VCVTSI2SS        | xmmreg,xmmreg*,rm32            | [rvm: vex.nds.lig.f3.0f.w0 2a /r]            | AVX,SD               |
| VCVTSI2SS        | xmmreg,xmmreg*,mem32           | [rvm: vex.nds.lig.f3.0f.w0 2a /r]            | AVX,ND,SD            |
| VCVTSI2SS        | xmmreg,xmmreg*,rm64            | [rvm: vex.nds.lig.f3.0f.w1 2a /r]            | AVX,LONG,SQ          |
| VCVTSS2SD        | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 5a /r]               | AVX                  |
| VCVTSS2SI        | reg32,xmmrm32                  | [rm: vex.lig.f3.0f.w0 2d /r]                 | AVX                  |
| VCVTSS2SI        | reg64,xmmrm32                  | [rm: vex.lig.f3.0f.w1 2d /r]                 | AVX,LONG             |
| VCVTTPD2DQ       | xmmreg,xmmreg                  | [rm: vex.128.66.0f e6 /r]                    | AVX                  |
| VCVTTPD2DQ       | xmmreg,mem128                  | [rm: vex.128.66.0f e6 /r]                    | AVX,SO               |
| VCVTTPD2DQ       | xmmreg,ymmreg                  | [rm: vex.256.66.0f e6 /r]                    | AVX                  |
| VCVTTPD2DQ       | xmmreg,mem256                  | [rm: vex.256.66.0f e6 /r]                    | AVX,SY               |
| VCVTTPS2DQ       | xmmreg,xmmrm128                | [rm: vex.128.f3.0f 5b /r]                    | AVX                  |
| VCVTTPS2DQ       | ymmreg,ymmrm256                | [rm: vex.256.f3.0f 5b /r]                    | AVX                  |
| VCVTTSD2SI       | reg32,xmmrm64                  | [rm: vex.lig.f2.0f.w0 2c /r]                 | AVX                  |
| VCVTTSD2SI       | reg64,xmmrm64                  | [rm: vex.lig.f2.0f.w1 2c /r]                 | AVX,LONG             |
| VCVTTSS2SI       | reg32,xmmrm32                  | [rm: vex.lig.f3.0f.w0 2c /r]                 | AVX                  |
| VCVTTSS2SI       | reg64,xmmrm32                  | [rm: vex.lig.f3.0f.w1 2c /r]                 | AVX,LONG             |
| VDIVPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 5e /r]               | AVX                  |
| VDIVPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 5e /r]               | AVX                  |
| VDIVPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 5e /r]                  | AVX                  |
| VDIVPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 5e /r]                  | AVX                  |
| VDIVSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 5e /r]               | AVX                  |
| VDIVSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 5e /r]               | AVX                  |
| VDPPD            | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 41 /r ib]         | AVX                  |
| VDPPS            | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 40 /r ib]         | AVX                  |
| VDPPS            | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 40 /r ib]         | AVX                  |
| VEXTRACTF128     | xmmrm128,ymmreg,imm8           | [mri: vex.256.66.0f3a.w0 19 /r ib]           | AVX                  |
| VEXTRACTPS       | rm32,xmmreg,imm8               | [mri: vex.128.66.0f3a 17 /r ib]              | AVX                  |
| VHADDPD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 7c /r]               | AVX                  |
| VHADDPD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 7c /r]               | AVX                  |
| VHADDPS          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.f2.0f 7c /r]               | AVX                  |
| VHADDPS          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.f2.0f 7c /r]               | AVX                  |
| VHSUBPD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 7d /r]               | AVX                  |
| VHSUBPD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 7d /r]               | AVX                  |
| VHSUBPS          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.f2.0f 7d /r]               | AVX                  |
| VHSUBPS          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.f2.0f 7d /r]               | AVX                  |
| VINSERTF128      | ymmreg,ymmreg*,xmmrm128,imm8   | [rvmi: vex.nds.256.66.0f3a.w0 18 /r ib]      | AVX                  |
| VINSERTPS        | xmmreg,xmmreg*,xmmrm32,imm8    | [rvmi: vex.nds.128.66.0f3a 21 /r ib]         | AVX                  |
| VLDDQU           | xmmreg,mem128                  | [rm: vex.128.f2.0f f0 /r]                    | AVX                  |
| VLDQQU           | ymmreg,mem256                  | [rm: vex.256.f2.0f f0 /r]                    | AVX                  |
| VLDDQU           | ymmreg,mem256                  | [rm: vex.256.f2.0f f0 /r]                    | AVX                  |
| VLDMXCSR         | mem32                          | [m: vex.lz.0f ae /2]                         | AVX                  |
| VMASKMOVDQU      | xmmreg,xmmreg                  | [rm: vex.128.66.0f f7 /r]                    | AVX                  |
| VMASKMOVPS       | xmmreg,xmmreg,mem128           | [rvm: vex.nds.128.66.0f38.w0 2c /r]          | AVX                  |
| VMASKMOVPS       | ymmreg,ymmreg,mem256           | [rvm: vex.nds.256.66.0f38.w0 2c /r]          | AVX                  |
| VMASKMOVPS       | mem128,xmmreg,xmmreg           | [mvr: vex.nds.128.66.0f38.w0 2e /r]          | AVX,SO               |
| VMASKMOVPS       | mem256,ymmreg,ymmreg           | [mvr: vex.nds.256.66.0f38.w0 2e /r]          | AVX,SY               |
| VMASKMOVPD       | xmmreg,xmmreg,mem128           | [rvm: vex.nds.128.66.0f38.w0 2d /r]          | AVX                  |
| VMASKMOVPD       | ymmreg,ymmreg,mem256           | [rvm: vex.nds.256.66.0f38.w0 2d /r]          | AVX                  |
| VMASKMOVPD       | mem128,xmmreg,xmmreg           | [mvr: vex.nds.128.66.0f38.w0 2f /r]          | AVX                  |
| VMASKMOVPD       | mem256,ymmreg,ymmreg           | [mvr: vex.nds.256.66.0f38.w0 2f /r]          | AVX                  |
| VMAXPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 5f /r]               | AVX                  |
| VMAXPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 5f /r]               | AVX                  |
| VMAXPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 5f /r]                  | AVX                  |
| VMAXPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 5f /r]                  | AVX                  |
| VMAXSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 5f /r]               | AVX                  |
| VMAXSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 5f /r]               | AVX                  |
| VMINPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 5d /r]               | AVX                  |
| VMINPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 5d /r]               | AVX                  |
| VMINPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 5d /r]                  | AVX                  |
| VMINPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 5d /r]                  | AVX                  |
| VMINSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 5d /r]               | AVX                  |
| VMINSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 5d /r]               | AVX                  |
| VMOVAPD          | xmmreg,xmmrm128                | [rm: vex.128.66.0f 28 /r]                    | AVX                  |
| VMOVAPD          | xmmrm128,xmmreg                | [mr: vex.128.66.0f 29 /r]                    | AVX                  |
| VMOVAPD          | ymmreg,ymmrm256                | [rm: vex.256.66.0f 28 /r]                    | AVX                  |
| VMOVAPD          | ymmrm256,ymmreg                | [mr: vex.256.66.0f 29 /r]                    | AVX                  |
| VMOVAPS          | xmmreg,xmmrm128                | [rm: vex.128.0f 28 /r]                       | AVX                  |
| VMOVAPS          | xmmrm128,xmmreg                | [mr: vex.128.0f 29 /r]                       | AVX                  |
| VMOVAPS          | ymmreg,ymmrm256                | [rm: vex.256.0f 28 /r]                       | AVX                  |
| VMOVAPS          | ymmrm256,ymmreg                | [mr: vex.256.0f 29 /r]                       | AVX                  |
| VMOVD            | xmmreg,rm32                    | [rm: vex.128.66.0f.w0 6e /r]                 | AVX                  |
| VMOVD            | rm32,xmmreg                    | [mr: vex.128.66.0f.w0 7e /r]                 | AVX                  |
| VMOVQ            | xmmreg,xmmrm64                 | [rm: vex.128.f3.0f 7e /r]                    | AVX,SQ               |
| VMOVQ            | xmmrm64,xmmreg                 | [mr: vex.128.66.0f d6 /r]                    | AVX,SQ               |
| VMOVQ            | xmmreg,rm64                    | [rm: vex.128.66.0f.w1 6e /r]                 | AVX,LONG,SQ          |
| VMOVQ            | rm64,xmmreg                    | [mr: vex.128.66.0f.w1 7e /r]                 | AVX,LONG,SQ          |
| VMOVDDUP         | xmmreg,xmmrm64                 | [rm: vex.128.f2.0f 12 /r]                    | AVX                  |
| VMOVDDUP         | ymmreg,ymmrm256                | [rm: vex.256.f2.0f 12 /r]                    | AVX                  |
| VMOVDQA          | xmmreg,xmmrm128                | [rm: vex.128.66.0f 6f /r]                    | AVX                  |
| VMOVDQA          | xmmrm128,xmmreg                | [mr: vex.128.66.0f 7f /r]                    | AVX                  |
| VMOVQQA          | ymmreg,ymmrm256                | [rm: vex.256.66.0f 6f /r]                    | AVX                  |
| VMOVQQA          | ymmrm256,ymmreg                | [mr: vex.256.66.0f 7f /r]                    | AVX                  |
| VMOVDQA          | ymmreg,ymmrm256                | [rm: vex.256.66.0f 6f /r]                    | AVX                  |
| VMOVDQA          | ymmrm256,ymmreg                | [mr: vex.256.66.0f 7f /r]                    | AVX                  |
| VMOVDQU          | xmmreg,xmmrm128                | [rm: vex.128.f3.0f 6f /r]                    | AVX                  |
| VMOVDQU          | xmmrm128,xmmreg                | [mr: vex.128.f3.0f 7f /r]                    | AVX                  |
| VMOVQQU          | ymmreg,ymmrm256                | [rm: vex.256.f3.0f 6f /r]                    | AVX                  |
| VMOVQQU          | ymmrm256,ymmreg                | [mr: vex.256.f3.0f 7f /r]                    | AVX                  |
| VMOVDQU          | ymmreg,ymmrm256                | [rm: vex.256.f3.0f 6f /r]                    | AVX                  |
| VMOVDQU          | ymmrm256,ymmreg                | [mr: vex.256.f3.0f 7f /r]                    | AVX                  |
| VMOVHLPS         | xmmreg,xmmreg*,xmmreg          | [rvm: vex.nds.128.0f 12 /r]                  | AVX                  |
| VMOVHPD          | xmmreg,xmmreg*,mem64           | [rvm: vex.nds.128.66.0f 16 /r]               | AVX                  |
| VMOVHPD          | mem64,xmmreg                   | [mr: vex.128.66.0f 17 /r]                    | AVX                  |
| VMOVHPS          | xmmreg,xmmreg*,mem64           | [rvm: vex.nds.128.0f 16 /r]                  | AVX                  |
| VMOVHPS          | mem64,xmmreg                   | [mr: vex.128.0f 17 /r]                       | AVX                  |
| VMOVLHPS         | xmmreg,xmmreg*,xmmreg          | [rvm: vex.nds.128.0f 16 /r]                  | AVX                  |
| VMOVLPD          | xmmreg,xmmreg*,mem64           | [rvm: vex.nds.128.66.0f 12 /r]               | AVX                  |
| VMOVLPD          | mem64,xmmreg                   | [mr: vex.128.66.0f 13 /r]                    | AVX                  |
| VMOVLPS          | xmmreg,xmmreg*,mem64           | [rvm: vex.nds.128.0f 12 /r]                  | AVX                  |
| VMOVLPS          | mem64,xmmreg                   | [mr: vex.128.0f 13 /r]                       | AVX                  |
| VMOVMSKPD        | reg64,xmmreg                   | [rm: vex.128.66.0f 50 /r]                    | AVX,LONG             |
| VMOVMSKPD        | reg32,xmmreg                   | [rm: vex.128.66.0f 50 /r]                    | AVX                  |
| VMOVMSKPD        | reg64,ymmreg                   | [rm: vex.256.66.0f 50 /r]                    | AVX,LONG             |
| VMOVMSKPD        | reg32,ymmreg                   | [rm: vex.256.66.0f 50 /r]                    | AVX                  |
| VMOVMSKPS        | reg64,xmmreg                   | [rm: vex.128.0f 50 /r]                       | AVX,LONG             |
| VMOVMSKPS        | reg32,xmmreg                   | [rm: vex.128.0f 50 /r]                       | AVX                  |
| VMOVMSKPS        | reg64,ymmreg                   | [rm: vex.256.0f 50 /r]                       | AVX,LONG             |
| VMOVMSKPS        | reg32,ymmreg                   | [rm: vex.256.0f 50 /r]                       | AVX                  |
| VMOVNTDQ         | mem128,xmmreg                  | [mr: vex.128.66.0f e7 /r]                    | AVX                  |
| VMOVNTQQ         | mem256,ymmreg                  | [mr: vex.256.66.0f e7 /r]                    | AVX                  |
| VMOVNTDQ         | mem256,ymmreg                  | [mr: vex.256.66.0f e7 /r]                    | AVX                  |
| VMOVNTDQA        | xmmreg,mem128                  | [rm: vex.128.66.0f38 2a /r]                  | AVX                  |
| VMOVNTPD         | mem128,xmmreg                  | [mr: vex.128.66.0f 2b /r]                    | AVX                  |
| VMOVNTPD         | mem256,ymmreg                  | [mr: vex.256.66.0f 2b /r]                    | AVX                  |
| VMOVNTPS         | mem128,xmmreg                  | [mr: vex.128.0f 2b /r]                       | AVX                  |
| VMOVNTPS         | mem256,ymmreg                  | [mr: vex.256.0f 2b /r]                       | AVX                  |
| VMOVSD           | xmmreg,xmmreg*,xmmreg          | [rvm: vex.nds.lig.f2.0f 10 /r]               | AVX                  |
| VMOVSD           | xmmreg,mem64                   | [rm: vex.lig.f2.0f 10 /r]                    | AVX                  |
| VMOVSD           | xmmreg,xmmreg*,xmmreg          | [mvr: vex.nds.lig.f2.0f 11 /r]               | AVX                  |
| VMOVSD           | mem64,xmmreg                   | [mr: vex.lig.f2.0f 11 /r]                    | AVX                  |
| VMOVSHDUP        | xmmreg,xmmrm128                | [rm: vex.128.f3.0f 16 /r]                    | AVX                  |
| VMOVSHDUP        | ymmreg,ymmrm256                | [rm: vex.256.f3.0f 16 /r]                    | AVX                  |
| VMOVSLDUP        | xmmreg,xmmrm128                | [rm: vex.128.f3.0f 12 /r]                    | AVX                  |
| VMOVSLDUP        | ymmreg,ymmrm256                | [rm: vex.256.f3.0f 12 /r]                    | AVX                  |
| VMOVSS           | xmmreg,xmmreg*,xmmreg          | [rvm: vex.nds.lig.f3.0f 10 /r]               | AVX                  |
| VMOVSS           | xmmreg,mem32                   | [rm: vex.lig.f3.0f 10 /r]                    | AVX                  |
| VMOVSS           | xmmreg,xmmreg*,xmmreg          | [mvr: vex.nds.lig.f3.0f 11 /r]               | AVX                  |
| VMOVSS           | mem32,xmmreg                   | [mr: vex.lig.f3.0f 11 /r]                    | AVX                  |
| VMOVUPD          | xmmreg,xmmrm128                | [rm: vex.128.66.0f 10 /r]                    | AVX                  |
| VMOVUPD          | xmmrm128,xmmreg                | [mr: vex.128.66.0f 11 /r]                    | AVX                  |
| VMOVUPD          | ymmreg,ymmrm256                | [rm: vex.256.66.0f 10 /r]                    | AVX                  |
| VMOVUPD          | ymmrm256,ymmreg                | [mr: vex.256.66.0f 11 /r]                    | AVX                  |
| VMOVUPS          | xmmreg,xmmrm128                | [rm: vex.128.0f 10 /r]                       | AVX                  |
| VMOVUPS          | xmmrm128,xmmreg                | [mr: vex.128.0f 11 /r]                       | AVX                  |
| VMOVUPS          | ymmreg,ymmrm256                | [rm: vex.256.0f 10 /r]                       | AVX                  |
| VMOVUPS          | ymmrm256,ymmreg                | [mr: vex.256.0f 11 /r]                       | AVX                  |
| VMPSADBW         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 42 /r ib]         | AVX                  |
| VMULPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 59 /r]               | AVX                  |
| VMULPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 59 /r]               | AVX                  |
| VMULPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 59 /r]                  | AVX                  |
| VMULPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 59 /r]                  | AVX                  |
| VMULSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 59 /r]               | AVX                  |
| VMULSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 59 /r]               | AVX                  |
| VORPD            | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 56 /r]               | AVX                  |
| VORPD            | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 56 /r]               | AVX                  |
| VORPS            | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 56 /r]                  | AVX                  |
| VORPS            | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 56 /r]                  | AVX                  |
| VPABSB           | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 1c /r]                  | AVX                  |
| VPABSW           | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 1d /r]                  | AVX                  |
| VPABSD           | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 1e /r]                  | AVX                  |
| VPACKSSWB        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 63 /r]               | AVX                  |
| VPACKSSDW        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 6b /r]               | AVX                  |
| VPACKUSWB        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 67 /r]               | AVX                  |
| VPACKUSDW        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 2b /r]             | AVX                  |
| VPADDB           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f fc /r]               | AVX                  |
| VPADDW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f fd /r]               | AVX                  |
| VPADDD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f fe /r]               | AVX                  |
| VPADDQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d4 /r]               | AVX                  |
| VPADDSB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f ec /r]               | AVX                  |
| VPADDSW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f ed /r]               | AVX                  |
| VPADDUSB         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f dc /r]               | AVX                  |
| VPADDUSW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f dd /r]               | AVX                  |
| VPALIGNR         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 0f /r ib]         | AVX                  |
| VPAND            | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f db /r]               | AVX                  |
| VPANDN           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f df /r]               | AVX                  |
| VPAVGB           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e0 /r]               | AVX                  |
| VPAVGW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e3 /r]               | AVX                  |
| VPBLENDVB        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.nds.128.66.0f3a.w0 4c /r /is4]    | AVX                  |
| VPBLENDW         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 0e /r ib]         | AVX                  |
| VPCMPESTRI       | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 61 /r ib]              | AVX                  |
| VPCMPESTRM       | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 60 /r ib]              | AVX                  |
| VPCMPISTRI       | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 63 /r ib]              | AVX                  |
| VPCMPISTRM       | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 62 /r ib]              | AVX                  |
| VPCMPEQB         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 74 /r]               | AVX                  |
| VPCMPEQW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 75 /r]               | AVX                  |
| VPCMPEQD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 76 /r]               | AVX                  |
| VPCMPEQQ         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 29 /r]             | AVX                  |
| VPCMPGTB         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 64 /r]               | AVX                  |
| VPCMPGTW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 65 /r]               | AVX                  |
| VPCMPGTD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 66 /r]               | AVX                  |
| VPCMPGTQ         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 37 /r]             | AVX                  |
| VPERMILPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w0 0d /r]          | AVX                  |
| VPERMILPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 0d /r]          | AVX                  |
| VPERMILPD        | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a.w0 05 /r ib]           | AVX                  |
| VPERMILPD        | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a.w0 05 /r ib]           | AVX                  |
| VPERMILPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w0 0c /r]          | AVX                  |
| VPERMILPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 0c /r]          | AVX                  |
| VPERMILPS        | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a.w0 04 /r ib]           | AVX                  |
| VPERMILPS        | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a.w0 04 /r ib]           | AVX                  |
| VPERM2F128       | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a.w0 06 /r ib]      | AVX                  |
| VPEXTRB          | reg64,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 14 /r ib]           | AVX,LONG             |
| VPEXTRB          | reg32,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 14 /r ib]           | AVX                  |
| VPEXTRB          | mem8,xmmreg,imm8               | [mri: vex.128.66.0f3a.w0 14 /r ib]           | AVX                  |
| VPEXTRW          | reg64,xmmreg,imm8              | [rmi: vex.128.66.0f.w0 c5 /r ib]             | AVX,LONG             |
| VPEXTRW          | reg32,xmmreg,imm8              | [rmi: vex.128.66.0f.w0 c5 /r ib]             | AVX                  |
| VPEXTRW          | reg64,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 15 /r ib]           | AVX,LONG             |
| VPEXTRW          | reg32,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 15 /r ib]           | AVX                  |
| VPEXTRW          | mem16,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 15 /r ib]           | AVX                  |
| VPEXTRD          | reg64,xmmreg,imm8              | [mri: vex.128.66.0f3a.w0 16 /r ib]           | AVX,LONG             |
| VPEXTRD          | rm32,xmmreg,imm8               | [mri: vex.128.66.0f3a.w0 16 /r ib]           | AVX                  |
| VPEXTRQ          | rm64,xmmreg,imm8               | [mri: vex.128.66.0f3a.w1 16 /r ib]           | AVX,LONG             |
| VPHADDW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 01 /r]             | AVX                  |
| VPHADDD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 02 /r]             | AVX                  |
| VPHADDSW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 03 /r]             | AVX                  |
| VPHMINPOSUW      | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 41 /r]                  | AVX                  |
| VPHSUBW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 05 /r]             | AVX                  |
| VPHSUBD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 06 /r]             | AVX                  |
| VPHSUBSW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 07 /r]             | AVX                  |
| VPINSRB          | xmmreg,xmmreg*,mem8,imm8       | [rvmi: vex.nds.128.66.0f3a 20 /r ib]         | AVX                  |
| VPINSRB          | xmmreg,xmmreg*,rm8,imm8        | [rvmi: vex.nds.128.66.0f3a 20 /r ib]         | AVX                  |
| VPINSRB          | xmmreg,xmmreg*,reg32,imm8      | [rvmi: vex.nds.128.66.0f3a 20 /r ib]         | AVX                  |
| VPINSRW          | xmmreg,xmmreg*,mem16,imm8      | [rvmi: vex.nds.128.66.0f c4 /r ib]           | AVX                  |
| VPINSRW          | xmmreg,xmmreg*,rm16,imm8       | [rvmi: vex.nds.128.66.0f c4 /r ib]           | AVX                  |
| VPINSRW          | xmmreg,xmmreg*,reg32,imm8      | [rvmi: vex.nds.128.66.0f c4 /r ib]           | AVX                  |
| VPINSRD          | xmmreg,xmmreg*,mem32,imm8      | [rvmi: vex.nds.128.66.0f3a.w0 22 /r ib]      | AVX                  |
| VPINSRD          | xmmreg,xmmreg*,rm32,imm8       | [rvmi: vex.nds.128.66.0f3a.w0 22 /r ib]      | AVX                  |
| VPINSRQ          | xmmreg,xmmreg*,mem64,imm8      | [rvmi: vex.nds.128.66.0f3a.w1 22 /r ib]      | AVX,LONG             |
| VPINSRQ          | xmmreg,xmmreg*,rm64,imm8       | [rvmi: vex.nds.128.66.0f3a.w1 22 /r ib]      | AVX,LONG             |
| VPMADDWD         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f5 /r]               | AVX                  |
| VPMADDUBSW       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 04 /r]             | AVX                  |
| VPMAXSB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3c /r]             | AVX                  |
| VPMAXSW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f ee /r]               | AVX                  |
| VPMAXSD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3d /r]             | AVX                  |
| VPMAXUB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f de /r]               | AVX                  |
| VPMAXUW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3e /r]             | AVX                  |
| VPMAXUD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3f /r]             | AVX                  |
| VPMINSB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 38 /r]             | AVX                  |
| VPMINSW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f ea /r]               | AVX                  |
| VPMINSD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 39 /r]             | AVX                  |
| VPMINUB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f da /r]               | AVX                  |
| VPMINUW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3a /r]             | AVX                  |
| VPMINUD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 3b /r]             | AVX                  |
| VPMOVMSKB        | reg64,xmmreg                   | [rm: vex.128.66.0f d7 /r]                    | AVX,LONG             |
| VPMOVMSKB        | reg32,xmmreg                   | [rm: vex.128.66.0f d7 /r]                    | AVX                  |
| VPMOVSXBW        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 20 /r]                  | AVX                  |
| VPMOVSXBD        | xmmreg,xmmrm32                 | [rm: vex.128.66.0f38 21 /r]                  | AVX                  |
| VPMOVSXBQ        | xmmreg,xmmrm16                 | [rm: vex.128.66.0f38 22 /r]                  | AVX                  |
| VPMOVSXWD        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 23 /r]                  | AVX                  |
| VPMOVSXWQ        | xmmreg,xmmrm32                 | [rm: vex.128.66.0f38 24 /r]                  | AVX                  |
| VPMOVSXDQ        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 25 /r]                  | AVX                  |
| VPMOVZXBW        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 30 /r]                  | AVX                  |
| VPMOVZXBD        | xmmreg,xmmrm32                 | [rm: vex.128.66.0f38 31 /r]                  | AVX                  |
| VPMOVZXBQ        | xmmreg,xmmrm16                 | [rm: vex.128.66.0f38 32 /r]                  | AVX                  |
| VPMOVZXWD        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 33 /r]                  | AVX                  |
| VPMOVZXWQ        | xmmreg,xmmrm32                 | [rm: vex.128.66.0f38 34 /r]                  | AVX                  |
| VPMOVZXDQ        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38 35 /r]                  | AVX                  |
| VPMULHUW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e4 /r]               | AVX                  |
| VPMULHRSW        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 0b /r]             | AVX                  |
| VPMULHW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e5 /r]               | AVX                  |
| VPMULLW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d5 /r]               | AVX                  |
| VPMULLD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 40 /r]             | AVX                  |
| VPMULUDQ         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f4 /r]               | AVX                  |
| VPMULDQ          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 28 /r]             | AVX                  |
| VPOR             | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f eb /r]               | AVX                  |
| VPSADBW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f6 /r]               | AVX                  |
| VPSHUFB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 00 /r]             | AVX                  |
| VPSHUFD          | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f 70 /r ib]                | AVX                  |
| VPSHUFHW         | xmmreg,xmmrm128,imm8           | [rmi: vex.128.f3.0f 70 /r ib]                | AVX                  |
| VPSHUFLW         | xmmreg,xmmrm128,imm8           | [rmi: vex.128.f2.0f 70 /r ib]                | AVX                  |
| VPSIGNB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 08 /r]             | AVX                  |
| VPSIGNW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 09 /r]             | AVX                  |
| VPSIGND          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38 0a /r]             | AVX                  |
| VPSLLDQ          | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 73 /7 ib]            | AVX                  |
| VPSRLDQ          | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 73 /3 ib]            | AVX                  |
| VPSLLW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f1 /r]               | AVX                  |
| VPSLLW           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 71 /6 ib]            | AVX                  |
| VPSLLD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f2 /r]               | AVX                  |
| VPSLLD           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 72 /6 ib]            | AVX                  |
| VPSLLQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f3 /r]               | AVX                  |
| VPSLLQ           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 73 /6 ib]            | AVX                  |
| VPSRAW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e1 /r]               | AVX                  |
| VPSRAW           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 71 /4 ib]            | AVX                  |
| VPSRAD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e2 /r]               | AVX                  |
| VPSRAD           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 72 /4 ib]            | AVX                  |
| VPSRLW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d1 /r]               | AVX                  |
| VPSRLW           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 71 /2 ib]            | AVX                  |
| VPSRLD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d2 /r]               | AVX                  |
| VPSRLD           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 72 /2 ib]            | AVX                  |
| VPSRLQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d3 /r]               | AVX                  |
| VPSRLQ           | xmmreg,xmmreg*,imm8            | [vmi: vex.ndd.128.66.0f 73 /2 ib]            | AVX                  |
| VPTEST           | xmmreg,xmmrm128                | [rm: vex.128.66.0f38 17 /r]                  | AVX                  |
| VPTEST           | ymmreg,ymmrm256                | [rm: vex.256.66.0f38 17 /r]                  | AVX                  |
| VPSUBB           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f8 /r]               | AVX                  |
| VPSUBW           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f f9 /r]               | AVX                  |
| VPSUBD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f fa /r]               | AVX                  |
| VPSUBQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f fb /r]               | AVX                  |
| VPSUBSB          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e8 /r]               | AVX                  |
| VPSUBSW          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f e9 /r]               | AVX                  |
| VPSUBUSB         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d8 /r]               | AVX                  |
| VPSUBUSW         | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f d9 /r]               | AVX                  |
| VPUNPCKHBW       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 68 /r]               | AVX                  |
| VPUNPCKHWD       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 69 /r]               | AVX                  |
| VPUNPCKHDQ       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 6a /r]               | AVX                  |
| VPUNPCKHQDQ      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 6d /r]               | AVX                  |
| VPUNPCKLBW       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 60 /r]               | AVX                  |
| VPUNPCKLWD       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 61 /r]               | AVX                  |
| VPUNPCKLDQ       | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 62 /r]               | AVX                  |
| VPUNPCKLQDQ      | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 6c /r]               | AVX                  |
| VPXOR            | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f ef /r]               | AVX                  |
| VRCPPS           | xmmreg,xmmrm128                | [rm: vex.128.0f 53 /r]                       | AVX                  |
| VRCPPS           | ymmreg,ymmrm256                | [rm: vex.256.0f 53 /r]                       | AVX                  |
| VRCPSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 53 /r]               | AVX                  |
| VRSQRTPS         | xmmreg,xmmrm128                | [rm: vex.128.0f 52 /r]                       | AVX                  |
| VRSQRTPS         | ymmreg,ymmrm256                | [rm: vex.256.0f 52 /r]                       | AVX                  |
| VRSQRTSS         | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 52 /r]               | AVX                  |
| VROUNDPD         | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 09 /r ib]              | AVX                  |
| VROUNDPD         | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a 09 /r ib]              | AVX                  |
| VROUNDPS         | xmmreg,xmmrm128,imm8           | [rmi: vex.128.66.0f3a 08 /r ib]              | AVX                  |
| VROUNDPS         | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a 08 /r ib]              | AVX                  |
| VROUNDSD         | xmmreg,xmmreg*,xmmrm64,imm8    | [rvmi: vex.nds.128.66.0f3a 0b /r ib]         | AVX                  |
| VROUNDSS         | xmmreg,xmmreg*,xmmrm32,imm8    | [rvmi: vex.nds.128.66.0f3a 0a /r ib]         | AVX                  |
| VSHUFPD          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f c6 /r ib]           | AVX                  |
| VSHUFPD          | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f c6 /r ib]           | AVX                  |
| VSHUFPS          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.0f c6 /r ib]              | AVX                  |
| VSHUFPS          | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.0f c6 /r ib]              | AVX                  |
| VSQRTPD          | xmmreg,xmmrm128                | [rm: vex.128.66.0f 51 /r]                    | AVX                  |
| VSQRTPD          | ymmreg,ymmrm256                | [rm: vex.256.66.0f 51 /r]                    | AVX                  |
| VSQRTPS          | xmmreg,xmmrm128                | [rm: vex.128.0f 51 /r]                       | AVX                  |
| VSQRTPS          | ymmreg,ymmrm256                | [rm: vex.256.0f 51 /r]                       | AVX                  |
| VSQRTSD          | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 51 /r]               | AVX                  |
| VSQRTSS          | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 51 /r]               | AVX                  |
| VSTMXCSR         | mem32                          | [m: vex.128.0f ae /3]                        | AVX                  |
| VSUBPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 5c /r]               | AVX                  |
| VSUBPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 5c /r]               | AVX                  |
| VSUBPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 5c /r]                  | AVX                  |
| VSUBPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 5c /r]                  | AVX                  |
| VSUBSD           | xmmreg,xmmreg*,xmmrm64         | [rvm: vex.nds.lig.f2.0f 5c /r]               | AVX                  |
| VSUBSS           | xmmreg,xmmreg*,xmmrm32         | [rvm: vex.nds.lig.f3.0f 5c /r]               | AVX                  |
| VTESTPS          | xmmreg,xmmrm128                | [rm: vex.128.66.0f38.w0 0e /r]               | AVX                  |
| VTESTPS          | ymmreg,ymmrm256                | [rm: vex.256.66.0f38.w0 0e /r]               | AVX                  |
| VTESTPD          | xmmreg,xmmrm128                | [rm: vex.128.66.0f38.w0 0f /r]               | AVX                  |
| VTESTPD          | ymmreg,ymmrm256                | [rm: vex.256.66.0f38.w0 0f /r]               | AVX                  |
| VUCOMISD         | xmmreg,xmmrm64                 | [rm: vex.lig.66.0f 2e /r]                    | AVX                  |
| VUCOMISS         | xmmreg,xmmrm32                 | [rm: vex.lig.0f 2e /r]                       | AVX                  |
| VUNPCKHPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 15 /r]               | AVX                  |
| VUNPCKHPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 15 /r]               | AVX                  |
| VUNPCKHPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 15 /r]                  | AVX                  |
| VUNPCKHPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 15 /r]                  | AVX                  |
| VUNPCKLPD        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 14 /r]               | AVX                  |
| VUNPCKLPD        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 14 /r]               | AVX                  |
| VUNPCKLPS        | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 14 /r]                  | AVX                  |
| VUNPCKLPS        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 14 /r]                  | AVX                  |
| VXORPD           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f 57 /r]               | AVX                  |
| VXORPD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 57 /r]               | AVX                  |
| VXORPS           | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.0f 57 /r]                  | AVX                  |
| VXORPS           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.0f 57 /r]                  | AVX                  |
| VZEROALL         | void                           | [vex.256.0f.w0 77]                           | AVX                  |
| VZEROUPPER       | void                           | [vex.128.0f.w0 77]                           | AVX                  |
| PCLMULLQLQDQ     | xmmreg,xmmrm128                | [rm: 66 0f 3a 44 /r 00]                      | SSE                  |
| PCLMULHQLQDQ     | xmmreg,xmmrm128                | [rm: 66 0f 3a 44 /r 01]                      | SSE                  |
| PCLMULLQHQDQ     | xmmreg,xmmrm128                | [rm: 66 0f 3a 44 /r 10]                      | SSE                  |
| PCLMULHQHQDQ     | xmmreg,xmmrm128                | [rm: 66 0f 3a 44 /r 11]                      | SSE                  |
| PCLMULQDQ        | xmmreg,xmmrm128,imm8           | [rmi: 66 0f 3a 44 /r ib]                     | SSE                  |
| VPCLMULLQLQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f3a 44 /r 00]          | AVX                  |
| VPCLMULHQLQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f3a 44 /r 01]          | AVX                  |
| VPCLMULLQHQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f3a 44 /r 10]          | AVX                  |
| VPCLMULHQHQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f3a 44 /r 11]          | AVX                  |
| VPCLMULQDQ       | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a 44 /r ib]         | AVX                  |
| VPCLMULLQLQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  vex.nds.256.66.0f3a.wig 44 /r 00]  | VPCLMULQDQ           |
| VPCLMULHQLQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  vex.nds.256.66.0f3a.wig 44 /r 01]  | VPCLMULQDQ           |
| VPCLMULLQHQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  vex.nds.256.66.0f3a.wig 44 /r 10]  | VPCLMULQDQ           |
| VPCLMULHQHQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  vex.nds.256.66.0f3a.wig 44 /r 11]  | VPCLMULQDQ           |
| VPCLMULQDQ       | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi:fv: vex.nds.256.66.0f3a.wig 44 /r ib]  | VPCLMULQDQ           |
| VPCLMULLQLQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm:fv:  evex.nds.128.66.0f3a.wig 44 /r 00] | AVX512VL,VPCLMULQDQ  |
| VPCLMULHQLQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm:fv:  evex.nds.128.66.0f3a.wig 44 /r 01] | AVX512VL,VPCLMULQDQ  |
| VPCLMULLQHQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm:fv:  evex.nds.128.66.0f3a.wig 44 /r 10] | AVX512VL,VPCLMULQDQ  |
| VPCLMULHQHQDQ    | xmmreg,xmmreg*,xmmrm128        | [rvm:fv:  evex.nds.128.66.0f3a.wig 44 /r 11] | AVX512VL,VPCLMULQDQ  |
| VPCLMULQDQ       | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi:fv: evex.nds.128.66.0f3a.wig 44 /r ib] | AVX512VL,VPCLMULQDQ  |
| VPCLMULLQLQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  evex.nds.256.66.0f3a.wig 44 /r 00] | AVX512VL,VPCLMULQDQ  |
| VPCLMULHQLQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  evex.nds.256.66.0f3a.wig 44 /r 01] | AVX512VL,VPCLMULQDQ  |
| VPCLMULLQHQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  evex.nds.256.66.0f3a.wig 44 /r 10] | AVX512VL,VPCLMULQDQ  |
| VPCLMULHQHQDQ    | ymmreg,ymmreg*,ymmrm256        | [rvm:fv:  evex.nds.256.66.0f3a.wig 44 /r 11] | AVX512VL,VPCLMULQDQ  |
| VPCLMULQDQ       | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi:fv: evex.nds.256.66.0f3a.wig 44 /r ib] | AVX512VL,VPCLMULQDQ  |
| VPCLMULLQLQDQ    | zmmreg,zmmreg*,zmmrm512        | [rvm:fv:  evex.nds.512.66.0f3a.wig 44 /r 00] | AVX512,VPCLMULQDQ    |
| VPCLMULHQLQDQ    | zmmreg,zmmreg*,zmmrm512        | [rvm:fv:  evex.nds.512.66.0f3a.wig 44 /r 01] | AVX512,VPCLMULQDQ    |
| VPCLMULLQHQDQ    | zmmreg,zmmreg*,zmmrm512        | [rvm:fv:  evex.nds.512.66.0f3a.wig 44 /r 10] | AVX512,VPCLMULQDQ    |
| VPCLMULHQHQDQ    | zmmreg,zmmreg*,zmmrm512        | [rvm:fv:  evex.nds.512.66.0f3a.wig 44 /r 11] | AVX512,VPCLMULQDQ    |
| VPCLMULQDQ       | zmmreg,zmmreg*,zmmrm512,imm8   | [rvmi:fv: evex.nds.512.66.0f3a.wig 44 /r ib] | AVX512,VPCLMULQDQ    |
| VFMADD132PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 98 /r]          | FMA                  |
| VFMADD132PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 98 /r]          | FMA                  |
| VFMADD132PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 98 /r]          | FMA                  |
| VFMADD132PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 98 /r]          | FMA                  |
| VFMADD312PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 98 /r]          | FMA                  |
| VFMADD312PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 98 /r]          | FMA                  |
| VFMADD312PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 98 /r]          | FMA                  |
| VFMADD312PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 98 /r]          | FMA                  |
| VFMADD213PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a8 /r]          | FMA                  |
| VFMADD213PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a8 /r]          | FMA                  |
| VFMADD213PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a8 /r]          | FMA                  |
| VFMADD213PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a8 /r]          | FMA                  |
| VFMADD123PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a8 /r]          | FMA                  |
| VFMADD123PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a8 /r]          | FMA                  |
| VFMADD123PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a8 /r]          | FMA                  |
| VFMADD123PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a8 /r]          | FMA                  |
| VFMADD231PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b8 /r]          | FMA                  |
| VFMADD231PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b8 /r]          | FMA                  |
| VFMADD231PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b8 /r]          | FMA                  |
| VFMADD231PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b8 /r]          | FMA                  |
| VFMADD321PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b8 /r]          | FMA                  |
| VFMADD321PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b8 /r]          | FMA                  |
| VFMADD321PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b8 /r]          | FMA                  |
| VFMADD321PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b8 /r]          | FMA                  |
| VFMADDSUB132PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 96 /r]          | FMA                  |
| VFMADDSUB132PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 96 /r]          | FMA                  |
| VFMADDSUB132PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 96 /r]          | FMA                  |
| VFMADDSUB132PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 96 /r]          | FMA                  |
| VFMADDSUB312PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 96 /r]          | FMA                  |
| VFMADDSUB312PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 96 /r]          | FMA                  |
| VFMADDSUB312PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 96 /r]          | FMA                  |
| VFMADDSUB312PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 96 /r]          | FMA                  |
| VFMADDSUB213PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a6 /r]          | FMA                  |
| VFMADDSUB213PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a6 /r]          | FMA                  |
| VFMADDSUB213PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a6 /r]          | FMA                  |
| VFMADDSUB213PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a6 /r]          | FMA                  |
| VFMADDSUB123PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a6 /r]          | FMA                  |
| VFMADDSUB123PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a6 /r]          | FMA                  |
| VFMADDSUB123PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a6 /r]          | FMA                  |
| VFMADDSUB123PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a6 /r]          | FMA                  |
| VFMADDSUB231PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b6 /r]          | FMA                  |
| VFMADDSUB231PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b6 /r]          | FMA                  |
| VFMADDSUB231PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b6 /r]          | FMA                  |
| VFMADDSUB231PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b6 /r]          | FMA                  |
| VFMADDSUB321PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b6 /r]          | FMA                  |
| VFMADDSUB321PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b6 /r]          | FMA                  |
| VFMADDSUB321PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b6 /r]          | FMA                  |
| VFMADDSUB321PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b6 /r]          | FMA                  |
| VFMSUB132PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9a /r]          | FMA                  |
| VFMSUB132PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9a /r]          | FMA                  |
| VFMSUB132PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9a /r]          | FMA                  |
| VFMSUB132PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9a /r]          | FMA                  |
| VFMSUB312PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9a /r]          | FMA                  |
| VFMSUB312PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9a /r]          | FMA                  |
| VFMSUB312PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9a /r]          | FMA                  |
| VFMSUB312PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9a /r]          | FMA                  |
| VFMSUB213PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 aa /r]          | FMA                  |
| VFMSUB213PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 aa /r]          | FMA                  |
| VFMSUB213PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 aa /r]          | FMA                  |
| VFMSUB213PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 aa /r]          | FMA                  |
| VFMSUB123PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 aa /r]          | FMA                  |
| VFMSUB123PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 aa /r]          | FMA                  |
| VFMSUB123PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 aa /r]          | FMA                  |
| VFMSUB123PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 aa /r]          | FMA                  |
| VFMSUB231PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ba /r]          | FMA                  |
| VFMSUB231PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ba /r]          | FMA                  |
| VFMSUB231PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ba /r]          | FMA                  |
| VFMSUB231PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ba /r]          | FMA                  |
| VFMSUB321PS      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ba /r]          | FMA                  |
| VFMSUB321PS      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ba /r]          | FMA                  |
| VFMSUB321PD      | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ba /r]          | FMA                  |
| VFMSUB321PD      | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ba /r]          | FMA                  |
| VFMSUBADD132PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 97 /r]          | FMA                  |
| VFMSUBADD132PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 97 /r]          | FMA                  |
| VFMSUBADD132PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 97 /r]          | FMA                  |
| VFMSUBADD132PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 97 /r]          | FMA                  |
| VFMSUBADD312PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 97 /r]          | FMA                  |
| VFMSUBADD312PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 97 /r]          | FMA                  |
| VFMSUBADD312PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 97 /r]          | FMA                  |
| VFMSUBADD312PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 97 /r]          | FMA                  |
| VFMSUBADD213PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a7 /r]          | FMA                  |
| VFMSUBADD213PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a7 /r]          | FMA                  |
| VFMSUBADD213PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a7 /r]          | FMA                  |
| VFMSUBADD213PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a7 /r]          | FMA                  |
| VFMSUBADD123PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 a7 /r]          | FMA                  |
| VFMSUBADD123PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 a7 /r]          | FMA                  |
| VFMSUBADD123PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 a7 /r]          | FMA                  |
| VFMSUBADD123PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 a7 /r]          | FMA                  |
| VFMSUBADD231PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b7 /r]          | FMA                  |
| VFMSUBADD231PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b7 /r]          | FMA                  |
| VFMSUBADD231PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b7 /r]          | FMA                  |
| VFMSUBADD231PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b7 /r]          | FMA                  |
| VFMSUBADD321PS   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 b7 /r]          | FMA                  |
| VFMSUBADD321PS   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 b7 /r]          | FMA                  |
| VFMSUBADD321PD   | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 b7 /r]          | FMA                  |
| VFMSUBADD321PD   | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 b7 /r]          | FMA                  |
| VFNMADD132PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9c /r]          | FMA                  |
| VFNMADD132PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9c /r]          | FMA                  |
| VFNMADD132PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9c /r]          | FMA                  |
| VFNMADD132PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9c /r]          | FMA                  |
| VFNMADD312PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9c /r]          | FMA                  |
| VFNMADD312PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9c /r]          | FMA                  |
| VFNMADD312PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9c /r]          | FMA                  |
| VFNMADD312PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9c /r]          | FMA                  |
| VFNMADD213PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ac /r]          | FMA                  |
| VFNMADD213PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ac /r]          | FMA                  |
| VFNMADD213PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ac /r]          | FMA                  |
| VFNMADD213PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ac /r]          | FMA                  |
| VFNMADD123PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ac /r]          | FMA                  |
| VFNMADD123PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ac /r]          | FMA                  |
| VFNMADD123PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ac /r]          | FMA                  |
| VFNMADD123PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ac /r]          | FMA                  |
| VFNMADD231PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 bc /r]          | FMA                  |
| VFNMADD231PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 bc /r]          | FMA                  |
| VFNMADD231PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 bc /r]          | FMA                  |
| VFNMADD231PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 bc /r]          | FMA                  |
| VFNMADD321PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 bc /r]          | FMA                  |
| VFNMADD321PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 bc /r]          | FMA                  |
| VFNMADD321PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 bc /r]          | FMA                  |
| VFNMADD321PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 bc /r]          | FMA                  |
| VFNMSUB132PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9e /r]          | FMA                  |
| VFNMSUB132PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9e /r]          | FMA                  |
| VFNMSUB132PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9e /r]          | FMA                  |
| VFNMSUB132PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9e /r]          | FMA                  |
| VFNMSUB312PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 9e /r]          | FMA                  |
| VFNMSUB312PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 9e /r]          | FMA                  |
| VFNMSUB312PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 9e /r]          | FMA                  |
| VFNMSUB312PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 9e /r]          | FMA                  |
| VFNMSUB213PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ae /r]          | FMA                  |
| VFNMSUB213PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ae /r]          | FMA                  |
| VFNMSUB213PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ae /r]          | FMA                  |
| VFNMSUB213PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ae /r]          | FMA                  |
| VFNMSUB123PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 ae /r]          | FMA                  |
| VFNMSUB123PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 ae /r]          | FMA                  |
| VFNMSUB123PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 ae /r]          | FMA                  |
| VFNMSUB123PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 ae /r]          | FMA                  |
| VFNMSUB231PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 be /r]          | FMA                  |
| VFNMSUB231PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 be /r]          | FMA                  |
| VFNMSUB231PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 be /r]          | FMA                  |
| VFNMSUB231PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 be /r]          | FMA                  |
| VFNMSUB321PS     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w0 be /r]          | FMA                  |
| VFNMSUB321PS     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w0 be /r]          | FMA                  |
| VFNMSUB321PD     | xmmreg,xmmreg,xmmrm128         | [rvm: vex.dds.128.66.0f38.w1 be /r]          | FMA                  |
| VFNMSUB321PD     | ymmreg,ymmreg,ymmrm256         | [rvm: vex.dds.256.66.0f38.w1 be /r]          | FMA                  |
| VFMADD132SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 99 /r]          | FMA                  |
| VFMADD132SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 99 /r]          | FMA                  |
| VFMADD312SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 99 /r]          | FMA                  |
| VFMADD312SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 99 /r]          | FMA                  |
| VFMADD213SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 a9 /r]          | FMA                  |
| VFMADD213SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 a9 /r]          | FMA                  |
| VFMADD123SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 a9 /r]          | FMA                  |
| VFMADD123SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 a9 /r]          | FMA                  |
| VFMADD231SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 b9 /r]          | FMA                  |
| VFMADD231SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 b9 /r]          | FMA                  |
| VFMADD321SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 b9 /r]          | FMA                  |
| VFMADD321SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 b9 /r]          | FMA                  |
| VFMSUB132SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9b /r]          | FMA                  |
| VFMSUB132SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9b /r]          | FMA                  |
| VFMSUB312SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9b /r]          | FMA                  |
| VFMSUB312SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9b /r]          | FMA                  |
| VFMSUB213SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 ab /r]          | FMA                  |
| VFMSUB213SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 ab /r]          | FMA                  |
| VFMSUB123SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 ab /r]          | FMA                  |
| VFMSUB123SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 ab /r]          | FMA                  |
| VFMSUB231SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bb /r]          | FMA                  |
| VFMSUB231SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bb /r]          | FMA                  |
| VFMSUB321SS      | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bb /r]          | FMA                  |
| VFMSUB321SD      | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bb /r]          | FMA                  |
| VFNMADD132SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9d /r]          | FMA                  |
| VFNMADD132SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9d /r]          | FMA                  |
| VFNMADD312SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9d /r]          | FMA                  |
| VFNMADD312SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9d /r]          | FMA                  |
| VFNMADD213SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 ad /r]          | FMA                  |
| VFNMADD213SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 ad /r]          | FMA                  |
| VFNMADD123SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 ad /r]          | FMA                  |
| VFNMADD123SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 ad /r]          | FMA                  |
| VFNMADD231SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bd /r]          | FMA                  |
| VFNMADD231SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bd /r]          | FMA                  |
| VFNMADD321SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bd /r]          | FMA                  |
| VFNMADD321SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bd /r]          | FMA                  |
| VFNMSUB132SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9f /r]          | FMA                  |
| VFNMSUB132SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9f /r]          | FMA                  |
| VFNMSUB312SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 9f /r]          | FMA                  |
| VFNMSUB312SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 9f /r]          | FMA                  |
| VFNMSUB213SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 af /r]          | FMA                  |
| VFNMSUB213SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 af /r]          | FMA                  |
| VFNMSUB123SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 af /r]          | FMA                  |
| VFNMSUB123SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 af /r]          | FMA                  |
| VFNMSUB231SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bf /r]          | FMA                  |
| VFNMSUB231SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bf /r]          | FMA                  |
| VFNMSUB321SS     | xmmreg,xmmreg,xmmrm32          | [rvm: vex.dds.128.66.0f38.w0 bf /r]          | FMA                  |
| VFNMSUB321SD     | xmmreg,xmmreg,xmmrm64          | [rvm: vex.dds.128.66.0f38.w1 bf /r]          | FMA                  |
| RDFSBASE         | reg32                          | [m: norexw f3 0f ae /0]                      | LONG                 |
| RDFSBASE         | reg64                          | [m: o64 f3 0f ae /0]                         | LONG                 |
| RDGSBASE         | reg32                          | [m: norexw f3 0f ae /1]                      | LONG                 |
| RDGSBASE         | reg64                          | [m: o64 f3 0f ae /1]                         | LONG                 |
| RDRAND           | reg16                          | [m: o16 0f c7 /6]                            | FUTURE               |
| RDRAND           | reg32                          | [m: o32 0f c7 /6]                            | FUTURE               |
| RDRAND           | reg64                          | [m: o64 0f c7 /6]                            | LONG                 |
| WRFSBASE         | reg32                          | [m: norexw f3 0f ae /2]                      | LONG                 |
| WRFSBASE         | reg64                          | [m: o64 f3 0f ae /2]                         | LONG                 |
| WRGSBASE         | reg32                          | [m: norexw f3 0f ae /3]                      | LONG                 |
| WRGSBASE         | reg64                          | [m: o64 f3 0f ae /3]                         | LONG                 |
| VCVTPH2PS        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38.w0 13 /r]               | AVX                  |
| VCVTPH2PS        | xmmreg,xmmrm64                 | [rm: vex.128.66.0f38.w0 13 /r]               | AVX                  |
| VCVTPS2PH        | xmmrm128,ymmreg,imm8           | [mri: vex.256.66.0f3a.w0 1d /r ib]           | AVX                  |
| VCVTPS2PH        | xmmrm64,xmmreg,imm8            | [mri: vex.128.66.0f3a.w0 1d /r ib]           | AVX                  |
| ADCX             | reg32,rm32                     | [rm: norexw 66 0f 38 f6 /r]                  | FUTURE               |
| ADCX             | reg64,rm64                     | [rm: o64 66 0f 38 f6 /r]                     | LONG                 |
| ADOX             | reg32,rm32                     | [rm: norexw f3 0f 38 f6 /r]                  | FUTURE               |
| ADOX             | reg64,rm64                     | [rm: o64 f3 0f 38 f6 /r]                     | LONG                 |
| RDSEED           | reg16                          | [m: o16 0f c7 /7]                            | FUTURE               |
| RDSEED           | reg32                          | [m: o32 0f c7 /7]                            | FUTURE               |
| RDSEED           | reg64                          | [m: o64 0f c7 /7]                            | LONG                 |
| CLAC             | void                           | [0f 01 ca]                                   | PRIV                 |
| STAC             | void                           | [0f 01 cb]                                   | PRIV                 |
| XSTORE           | void                           | [0f a7 c0]                                   | PENT,CYRIX           |
| XCRYPTECB        | void                           | [mustrep 0f a7 c8]                           | PENT,CYRIX           |
| XCRYPTCBC        | void                           | [mustrep 0f a7 d0]                           | PENT,CYRIX           |
| XCRYPTCTR        | void                           | [mustrep 0f a7 d8]                           | PENT,CYRIX           |
| XCRYPTCFB        | void                           | [mustrep 0f a7 e0]                           | PENT,CYRIX           |
| XCRYPTOFB        | void                           | [mustrep 0f a7 e8]                           | PENT,CYRIX           |
| MONTMUL          | void                           | [mustrep 0f a6 c0]                           | PENT,CYRIX           |
| XSHA1            | void                           | [mustrep 0f a6 c8]                           | PENT,CYRIX           |
| XSHA256          | void                           | [mustrep 0f a6 d0]                           | PENT,CYRIX           |
| LLWPCB           | reg32                          | [m: xop.m9.w0.l0.p0 12 /0]                   | AMD,386              |
| LLWPCB           | reg64                          | [m: xop.m9.w1.l0.p0 12 /0]                   | AMD,X64              |
| SLWPCB           | reg32                          | [m: xop.m9.w0.l0.p0 12 /1]                   | AMD,386              |
| SLWPCB           | reg64                          | [m: xop.m9.w1.l0.p0 12 /1]                   | AMD,X64              |
| LWPVAL           | reg32,rm32,imm32               | [vmi: xop.m10.w0.ndd.l0.p0 12 /1 id]         | AMD,386              |
| LWPVAL           | reg64,rm32,imm32               | [vmi: xop.m10.w1.ndd.l0.p0 12 /1 id]         | AMD,X64              |
| LWPINS           | reg32,rm32,imm32               | [vmi: xop.m10.w0.ndd.l0.p0 12 /0 id]         | AMD,386              |
| LWPINS           | reg64,rm32,imm32               | [vmi: xop.m10.w1.ndd.l0.p0 12 /0 id]         | AMD,X64              |
| VFMADDPD         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 69 /r /is4]       | AMD,SSE5             |
| VFMADDPD         | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 69 /r /is4]       | AMD,SSE5             |
| VFMADDPD         | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 69 /r /is4]       | AMD,SSE5             |
| VFMADDPD         | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 69 /r /is4]       | AMD,SSE5             |
| VFMADDPS         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 68 /r /is4]       | AMD,SSE5             |
| VFMADDPS         | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 68 /r /is4]       | AMD,SSE5             |
| VFMADDPS         | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 68 /r /is4]       | AMD,SSE5             |
| VFMADDPS         | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 68 /r /is4]       | AMD,SSE5             |
| VFMADDSD         | xmmreg,xmmreg*,xmmrm64,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 6b /r /is4]       | AMD,SSE5             |
| VFMADDSD         | xmmreg,xmmreg*,xmmreg,xmmrm64  | [rvsm: vex.m3.w1.nds.l0.p1 6b /r /is4]       | AMD,SSE5             |
| VFMADDSS         | xmmreg,xmmreg*,xmmrm32,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 6a /r /is4]       | AMD,SSE5             |
| VFMADDSS         | xmmreg,xmmreg*,xmmreg,xmmrm32  | [rvsm: vex.m3.w1.nds.l0.p1 6a /r /is4]       | AMD,SSE5             |
| VFMADDSUBPD      | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 5d /r /is4]       | AMD,SSE5             |
| VFMADDSUBPD      | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 5d /r /is4]       | AMD,SSE5             |
| VFMADDSUBPD      | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 5d /r /is4]       | AMD,SSE5             |
| VFMADDSUBPD      | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 5d /r /is4]       | AMD,SSE5             |
| VFMADDSUBPS      | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 5c /r /is4]       | AMD,SSE5             |
| VFMADDSUBPS      | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 5c /r /is4]       | AMD,SSE5             |
| VFMADDSUBPS      | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 5c /r /is4]       | AMD,SSE5             |
| VFMADDSUBPS      | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 5c /r /is4]       | AMD,SSE5             |
| VFMSUBADDPD      | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 5f /r /is4]       | AMD,SSE5             |
| VFMSUBADDPD      | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 5f /r /is4]       | AMD,SSE5             |
| VFMSUBADDPD      | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 5f /r /is4]       | AMD,SSE5             |
| VFMSUBADDPD      | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 5f /r /is4]       | AMD,SSE5             |
| VFMSUBADDPS      | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 5e /r /is4]       | AMD,SSE5             |
| VFMSUBADDPS      | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 5e /r /is4]       | AMD,SSE5             |
| VFMSUBADDPS      | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 5e /r /is4]       | AMD,SSE5             |
| VFMSUBADDPS      | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 5e /r /is4]       | AMD,SSE5             |
| VFMSUBPD         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 6d /r /is4]       | AMD,SSE5             |
| VFMSUBPD         | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 6d /r /is4]       | AMD,SSE5             |
| VFMSUBPD         | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 6d /r /is4]       | AMD,SSE5             |
| VFMSUBPD         | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 6d /r /is4]       | AMD,SSE5             |
| VFMSUBPS         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 6c /r /is4]       | AMD,SSE5             |
| VFMSUBPS         | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 6c /r /is4]       | AMD,SSE5             |
| VFMSUBPS         | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 6c /r /is4]       | AMD,SSE5             |
| VFMSUBPS         | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 6c /r /is4]       | AMD,SSE5             |
| VFMSUBSD         | xmmreg,xmmreg*,xmmrm64,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 6f /r /is4]       | AMD,SSE5             |
| VFMSUBSD         | xmmreg,xmmreg*,xmmreg,xmmrm64  | [rvsm: vex.m3.w1.nds.l0.p1 6f /r /is4]       | AMD,SSE5             |
| VFMSUBSS         | xmmreg,xmmreg*,xmmrm32,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 6e /r /is4]       | AMD,SSE5             |
| VFMSUBSS         | xmmreg,xmmreg*,xmmreg,xmmrm32  | [rvsm: vex.m3.w1.nds.l0.p1 6e /r /is4]       | AMD,SSE5             |
| VFNMADDPD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 79 /r /is4]       | AMD,SSE5             |
| VFNMADDPD        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 79 /r /is4]       | AMD,SSE5             |
| VFNMADDPD        | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 79 /r /is4]       | AMD,SSE5             |
| VFNMADDPD        | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 79 /r /is4]       | AMD,SSE5             |
| VFNMADDPS        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 78 /r /is4]       | AMD,SSE5             |
| VFNMADDPS        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 78 /r /is4]       | AMD,SSE5             |
| VFNMADDPS        | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 78 /r /is4]       | AMD,SSE5             |
| VFNMADDPS        | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 78 /r /is4]       | AMD,SSE5             |
| VFNMADDSD        | xmmreg,xmmreg*,xmmrm64,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 7b /r /is4]       | AMD,SSE5             |
| VFNMADDSD        | xmmreg,xmmreg*,xmmreg,xmmrm64  | [rvsm: vex.m3.w1.nds.l0.p1 7b /r /is4]       | AMD,SSE5             |
| VFNMADDSS        | xmmreg,xmmreg*,xmmrm32,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 7a /r /is4]       | AMD,SSE5             |
| VFNMADDSS        | xmmreg,xmmreg*,xmmreg,xmmrm32  | [rvsm: vex.m3.w1.nds.l0.p1 7a /r /is4]       | AMD,SSE5             |
| VFNMSUBPD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 7d /r /is4]       | AMD,SSE5             |
| VFNMSUBPD        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 7d /r /is4]       | AMD,SSE5             |
| VFNMSUBPD        | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 7d /r /is4]       | AMD,SSE5             |
| VFNMSUBPD        | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 7d /r /is4]       | AMD,SSE5             |
| VFNMSUBPS        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: vex.m3.w0.nds.l0.p1 7c /r /is4]       | AMD,SSE5             |
| VFNMSUBPS        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.m3.w0.nds.l1.p1 7c /r /is4]       | AMD,SSE5             |
| VFNMSUBPS        | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: vex.m3.w1.nds.l0.p1 7c /r /is4]       | AMD,SSE5             |
| VFNMSUBPS        | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: vex.m3.w1.nds.l1.p1 7c /r /is4]       | AMD,SSE5             |
| VFNMSUBSD        | xmmreg,xmmreg*,xmmrm64,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 7f /r /is4]       | AMD,SSE5             |
| VFNMSUBSD        | xmmreg,xmmreg*,xmmreg,xmmrm64  | [rvsm: vex.m3.w1.nds.l0.p1 7f /r /is4]       | AMD,SSE5             |
| VFNMSUBSS        | xmmreg,xmmreg*,xmmrm32,xmmreg  | [rvms: vex.m3.w0.nds.l0.p1 7e /r /is4]       | AMD,SSE5             |
| VFNMSUBSS        | xmmreg,xmmreg*,xmmreg,xmmrm32  | [rvsm: vex.m3.w1.nds.l0.p1 7e /r /is4]       | AMD,SSE5             |
| VFRCZPD          | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 81 /r]                  | AMD,SSE5             |
| VFRCZPD          | ymmreg,ymmrm256*               | [rm: xop.m9.w0.l1.p0 81 /r]                  | AMD,SSE5             |
| VFRCZPS          | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 80 /r]                  | AMD,SSE5             |
| VFRCZPS          | ymmreg,ymmrm256*               | [rm: xop.m9.w0.l1.p0 80 /r]                  | AMD,SSE5             |
| VFRCZSD          | xmmreg,xmmrm64*                | [rm: xop.m9.w0.l0.p0 83 /r]                  | AMD,SSE5             |
| VFRCZSS          | xmmreg,xmmrm32*                | [rm: xop.m9.w0.l0.p0 82 /r]                  | AMD,SSE5             |
| VPCMOV           | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 a2 /r /is4]       | AMD,SSE5             |
| VPCMOV           | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: xop.m8.w0.nds.l1.p0 a2 /r /is4]       | AMD,SSE5             |
| VPCMOV           | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: xop.m8.w1.nds.l0.p0 a2 /r /is4]       | AMD,SSE5             |
| VPCMOV           | ymmreg,ymmreg*,ymmreg,ymmrm256 | [rvsm: xop.m8.w1.nds.l1.p0 a2 /r /is4]       | AMD,SSE5             |
| VPCOMB           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 cc /r ib]         | AMD,SSE5             |
| VPCOMD           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 ce /r ib]         | AMD,SSE5             |
| VPCOMQ           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 cf /r ib]         | AMD,SSE5             |
| VPCOMUB          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 ec /r ib]         | AMD,SSE5             |
| VPCOMUD          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 ee /r ib]         | AMD,SSE5             |
| VPCOMUQ          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 ef /r ib]         | AMD,SSE5             |
| VPCOMUW          | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 ed /r ib]         | AMD,SSE5             |
| VPCOMW           | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: xop.m8.w0.nds.l0.p0 cd /r ib]         | AMD,SSE5             |
| VPHADDBD         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 c2 /r]                  | AMD,SSE5             |
| VPHADDBQ         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 c3 /r]                  | AMD,SSE5             |
| VPHADDBW         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 c1 /r]                  | AMD,SSE5             |
| VPHADDDQ         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 cb /r]                  | AMD,SSE5             |
| VPHADDUBD        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 d2 /r]                  | AMD,SSE5             |
| VPHADDUBQ        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 d3 /r]                  | AMD,SSE5             |
| VPHADDUBW        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 d1 /r]                  | AMD,SSE5             |
| VPHADDUDQ        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 db /r]                  | AMD,SSE5             |
| VPHADDUWD        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 d6 /r]                  | AMD,SSE5             |
| VPHADDUWQ        | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 d7 /r]                  | AMD,SSE5             |
| VPHADDWD         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 c6 /r]                  | AMD,SSE5             |
| VPHADDWQ         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 c7 /r]                  | AMD,SSE5             |
| VPHSUBBW         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 e1 /r]                  | AMD,SSE5             |
| VPHSUBDQ         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 e3 /r]                  | AMD,SSE5             |
| VPHSUBWD         | xmmreg,xmmrm128*               | [rm: xop.m9.w0.l0.p0 e2 /r]                  | AMD,SSE5             |
| VPMACSDD         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 9e /r /is4]       | AMD,SSE5             |
| VPMACSDQH        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 9f /r /is4]       | AMD,SSE5             |
| VPMACSDQL        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 97 /r /is4]       | AMD,SSE5             |
| VPMACSSDD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 8e /r /is4]       | AMD,SSE5             |
| VPMACSSDQH       | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 8f /r /is4]       | AMD,SSE5             |
| VPMACSSDQL       | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 87 /r /is4]       | AMD,SSE5             |
| VPMACSSWD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 86 /r /is4]       | AMD,SSE5             |
| VPMACSSWW        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 85 /r /is4]       | AMD,SSE5             |
| VPMACSWD         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 96 /r /is4]       | AMD,SSE5             |
| VPMACSWW         | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 95 /r /is4]       | AMD,SSE5             |
| VPMADCSSWD       | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 a6 /r /is4]       | AMD,SSE5             |
| VPMADCSWD        | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 b6 /r /is4]       | AMD,SSE5             |
| VPPERM           | xmmreg,xmmreg*,xmmreg,xmmrm128 | [rvsm: xop.m8.w1.nds.l0.p0 a3 /r /is4]       | AMD,SSE5             |
| VPPERM           | xmmreg,xmmreg*,xmmrm128,xmmreg | [rvms: xop.m8.w0.nds.l0.p0 a3 /r /is4]       | AMD,SSE5             |
| VPROTB           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 90 /r]             | AMD,SSE5             |
| VPROTB           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 90 /r]             | AMD,SSE5             |
| VPROTB           | xmmreg,xmmrm128*,imm8          | [rmi: xop.m8.w0.l0.p0 c0 /r ib]              | AMD,SSE5             |
| VPROTD           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 92 /r]             | AMD,SSE5             |
| VPROTD           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 92 /r]             | AMD,SSE5             |
| VPROTD           | xmmreg,xmmrm128*,imm8          | [rmi: xop.m8.w0.l0.p0 c2 /r ib]              | AMD,SSE5             |
| VPROTQ           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 93 /r]             | AMD,SSE5             |
| VPROTQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 93 /r]             | AMD,SSE5             |
| VPROTQ           | xmmreg,xmmrm128*,imm8          | [rmi: xop.m8.w0.l0.p0 c3 /r ib]              | AMD,SSE5             |
| VPROTW           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 91 /r]             | AMD,SSE5             |
| VPROTW           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 91 /r]             | AMD,SSE5             |
| VPROTW           | xmmreg,xmmrm128*,imm8          | [rmi: xop.m8.w0.l0.p0 c1 /r ib]              | AMD,SSE5             |
| VPSHAB           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 98 /r]             | AMD,SSE5             |
| VPSHAB           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 98 /r]             | AMD,SSE5             |
| VPSHAD           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 9a /r]             | AMD,SSE5             |
| VPSHAD           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 9a /r]             | AMD,SSE5             |
| VPSHAQ           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 9b /r]             | AMD,SSE5             |
| VPSHAQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 9b /r]             | AMD,SSE5             |
| VPSHAW           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 99 /r]             | AMD,SSE5             |
| VPSHAW           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 99 /r]             | AMD,SSE5             |
| VPSHLB           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 94 /r]             | AMD,SSE5             |
| VPSHLB           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 94 /r]             | AMD,SSE5             |
| VPSHLD           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 96 /r]             | AMD,SSE5             |
| VPSHLD           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 96 /r]             | AMD,SSE5             |
| VPSHLQ           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 97 /r]             | AMD,SSE5             |
| VPSHLQ           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 97 /r]             | AMD,SSE5             |
| VPSHLW           | xmmreg,xmmrm128*,xmmreg        | [rmv: xop.m9.w0.nds.l0.p0 95 /r]             | AMD,SSE5             |
| VPSHLW           | xmmreg,xmmreg*,xmmrm128        | [rvm: xop.m9.w1.nds.l0.p0 95 /r]             | AMD,SSE5             |
| VMPSADBW         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 42 /r ib]         | AVX2                 |
| VPABSB           | ymmreg,ymmrm256                | [rm: vex.256.66.0f38 1c /r]                  | AVX2                 |
| VPABSW           | ymmreg,ymmrm256                | [rm: vex.256.66.0f38 1d /r]                  | AVX2                 |
| VPABSD           | ymmreg,ymmrm256                | [rm: vex.256.66.0f38 1e /r]                  | AVX2                 |
| VPACKSSWB        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 63 /r]               | AVX2                 |
| VPACKSSDW        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 6b /r]               | AVX2                 |
| VPACKUSDW        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 2b /r]             | AVX2                 |
| VPACKUSWB        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 67 /r]               | AVX2                 |
| VPADDB           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f fc /r]               | AVX2                 |
| VPADDW           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f fd /r]               | AVX2                 |
| VPADDD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f fe /r]               | AVX2                 |
| VPADDQ           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f d4 /r]               | AVX2                 |
| VPADDSB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f ec /r]               | AVX2                 |
| VPADDSW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f ed /r]               | AVX2                 |
| VPADDUSB         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f dc /r]               | AVX2                 |
| VPADDUSW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f dd /r]               | AVX2                 |
| VPALIGNR         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 0f /r ib]         | AVX2                 |
| VPAND            | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f db /r]               | AVX2                 |
| VPANDN           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f df /r]               | AVX2                 |
| VPAVGB           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e0 /r]               | AVX2                 |
| VPAVGW           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e3 /r]               | AVX2                 |
| VPBLENDVB        | ymmreg,ymmreg*,ymmrm256,ymmreg | [rvms: vex.nds.256.66.0f3a 4c /r /is4]       | AVX2                 |
| VPBLENDW         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a 0e /r ib]         | AVX2                 |
| VPCMPEQB         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 74 /r]               | AVX2                 |
| VPCMPEQW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 75 /r]               | AVX2                 |
| VPCMPEQD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 76 /r]               | AVX2                 |
| VPCMPEQQ         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 29 /r]             | AVX2                 |
| VPCMPGTB         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 64 /r]               | AVX2                 |
| VPCMPGTW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 65 /r]               | AVX2                 |
| VPCMPGTD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 66 /r]               | AVX2                 |
| VPCMPGTQ         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 37 /r]             | AVX2                 |
| VPHADDW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 01 /r]             | AVX2                 |
| VPHADDD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 02 /r]             | AVX2                 |
| VPHADDSW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 03 /r]             | AVX2                 |
| VPHSUBW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 05 /r]             | AVX2                 |
| VPHSUBD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 06 /r]             | AVX2                 |
| VPHSUBSW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 07 /r]             | AVX2                 |
| VPMADDUBSW       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 04 /r]             | AVX2                 |
| VPMADDWD         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f f5 /r]               | AVX2                 |
| VPMAXSB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3c /r]             | AVX2                 |
| VPMAXSW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f ee /r]               | AVX2                 |
| VPMAXSD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3d /r]             | AVX2                 |
| VPMAXUB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f de /r]               | AVX2                 |
| VPMAXUW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3e /r]             | AVX2                 |
| VPMAXUD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3f /r]             | AVX2                 |
| VPMINSB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 38 /r]             | AVX2                 |
| VPMINSW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f ea /r]               | AVX2                 |
| VPMINSD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 39 /r]             | AVX2                 |
| VPMINUB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f da /r]               | AVX2                 |
| VPMINUW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3a /r]             | AVX2                 |
| VPMINUD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 3b /r]             | AVX2                 |
| VPMOVMSKB        | reg32,ymmreg                   | [rm: vex.256.66.0f d7 /r]                    | AVX2                 |
| VPMOVMSKB        | reg64,ymmreg                   | [rm: vex.256.66.0f d7 /r]                    | AVX2                 |
| VPMOVSXBW        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 20 /r]                  | AVX2                 |
| VPMOVSXBD        | ymmreg,mem64                   | [rm: vex.256.66.0f38 21 /r]                  | AVX2                 |
| VPMOVSXBD        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 21 /r]                  | AVX2                 |
| VPMOVSXBQ        | ymmreg,mem32                   | [rm: vex.256.66.0f38 22 /r]                  | AVX2                 |
| VPMOVSXBQ        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 22 /r]                  | AVX2                 |
| VPMOVSXWD        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 23 /r]                  | AVX2                 |
| VPMOVSXWQ        | ymmreg,mem64                   | [rm: vex.256.66.0f38 24 /r]                  | AVX2                 |
| VPMOVSXWQ        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 24 /r]                  | AVX2                 |
| VPMOVSXDQ        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 25 /r]                  | AVX2                 |
| VPMOVZXBW        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 30 /r]                  | AVX2                 |
| VPMOVZXBD        | ymmreg,mem64                   | [rm: vex.256.66.0f38 31 /r]                  | AVX2                 |
| VPMOVZXBD        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 31 /r]                  | AVX2                 |
| VPMOVZXBQ        | ymmreg,mem32                   | [rm: vex.256.66.0f38 32 /r]                  | AVX2                 |
| VPMOVZXBQ        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 32 /r]                  | AVX2                 |
| VPMOVZXWD        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 33 /r]                  | AVX2                 |
| VPMOVZXWQ        | ymmreg,mem64                   | [rm: vex.256.66.0f38 34 /r]                  | AVX2                 |
| VPMOVZXWQ        | ymmreg,xmmreg                  | [rm: vex.256.66.0f38 34 /r]                  | AVX2                 |
| VPMOVZXDQ        | ymmreg,xmmrm128                | [rm: vex.256.66.0f38 35 /r]                  | AVX2                 |
| VPMULDQ          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 28 /r]             | AVX2                 |
| VPMULHRSW        | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 0b /r]             | AVX2                 |
| VPMULHUW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e4 /r]               | AVX2                 |
| VPMULHW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e5 /r]               | AVX2                 |
| VPMULLW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f d5 /r]               | AVX2                 |
| VPMULLD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 40 /r]             | AVX2                 |
| VPMULUDQ         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f f4 /r]               | AVX2                 |
| VPOR             | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f eb /r]               | AVX2                 |
| VPSADBW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f f6 /r]               | AVX2                 |
| VPSHUFB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 00 /r]             | AVX2                 |
| VPSHUFD          | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f 70 /r ib]                | AVX2                 |
| VPSHUFHW         | ymmreg,ymmrm256,imm8           | [rmi: vex.256.f3.0f 70 /r ib]                | AVX2                 |
| VPSHUFLW         | ymmreg,ymmrm256,imm8           | [rmi: vex.256.f2.0f 70 /r ib]                | AVX2                 |
| VPSIGNB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 08 /r]             | AVX2                 |
| VPSIGNW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 09 /r]             | AVX2                 |
| VPSIGND          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38 0a /r]             | AVX2                 |
| VPSLLDQ          | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 73 /7 ib]            | AVX2                 |
| VPSLLW           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f f1 /r]               | AVX2                 |
| VPSLLW           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 71 /6 ib]            | AVX2                 |
| VPSLLD           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f f2 /r]               | AVX2                 |
| VPSLLD           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 72 /6 ib]            | AVX2                 |
| VPSLLQ           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f f3 /r]               | AVX2                 |
| VPSLLQ           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 73 /6 ib]            | AVX2                 |
| VPSRAW           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f e1 /r]               | AVX2                 |
| VPSRAW           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 71 /4 ib]            | AVX2                 |
| VPSRAD           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f e2 /r]               | AVX2                 |
| VPSRAD           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 72 /4 ib]            | AVX2                 |
| VPSRLDQ          | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 73 /3 ib]            | AVX2                 |
| VPSRLW           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f d1 /r]               | AVX2                 |
| VPSRLW           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 71 /2 ib]            | AVX2                 |
| VPSRLD           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f d2 /r]               | AVX2                 |
| VPSRLD           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f 72 /2 ib]            | AVX2                 |
| VPSRLQ           | ymmreg,ymmreg*,xmmrm128        | [rvm: vex.nds.256.66.0f d3 /r]               | AVX2                 |
| VPSRLQ           | ymmreg,ymmreg*,imm8            | [vmi: vex.ndd.256.66.0f.wig 73 /2 ib]        | AVX2                 |
| VPSUBB           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f f8 /r]               | AVX2                 |
| VPSUBW           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f f9 /r]               | AVX2                 |
| VPSUBD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f fa /r]               | AVX2                 |
| VPSUBQ           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f fb /r]               | AVX2                 |
| VPSUBSB          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e8 /r]               | AVX2                 |
| VPSUBSW          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f e9 /r]               | AVX2                 |
| VPSUBUSB         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f d8 /r]               | AVX2                 |
| VPSUBUSW         | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f d9 /r]               | AVX2                 |
| VPUNPCKHBW       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 68 /r]               | AVX2                 |
| VPUNPCKHWD       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 69 /r]               | AVX2                 |
| VPUNPCKHDQ       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 6a /r]               | AVX2                 |
| VPUNPCKHQDQ      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 6d /r]               | AVX2                 |
| VPUNPCKLBW       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 60 /r]               | AVX2                 |
| VPUNPCKLWD       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 61 /r]               | AVX2                 |
| VPUNPCKLDQ       | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 62 /r]               | AVX2                 |
| VPUNPCKLQDQ      | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f 6c /r]               | AVX2                 |
| VPXOR            | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f ef /r]               | AVX2                 |
| VMOVNTDQA        | ymmreg,mem256                  | [rm: vex.256.66.0f38 2a /r]                  | AVX2                 |
| VBROADCASTSS     | xmmreg,xmmreg                  | [rm: vex.128.66.0f38.w0 18 /r]               | AVX2                 |
| VBROADCASTSS     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 18 /r]               | AVX2                 |
| VBROADCASTSD     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 19 /r]               | AVX2                 |
| VBROADCASTI128   | ymmreg,mem128                  | [rm: vex.256.66.0f38.w0 5a /r]               | AVX2                 |
| VPBLENDD         | xmmreg,xmmreg*,xmmrm128,imm8   | [rvmi: vex.nds.128.66.0f3a.w0 02 /r ib]      | AVX2                 |
| VPBLENDD         | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a.w0 02 /r ib]      | AVX2                 |
| VPBROADCASTB     | xmmreg,mem8                    | [rm: vex.128.66.0f38.w0 78 /r]               | AVX2                 |
| VPBROADCASTB     | xmmreg,xmmreg                  | [rm: vex.128.66.0f38.w0 78 /r]               | AVX2                 |
| VPBROADCASTB     | ymmreg,mem8                    | [rm: vex.256.66.0f38.w0 78 /r]               | AVX2                 |
| VPBROADCASTB     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 78 /r]               | AVX2                 |
| VPBROADCASTW     | xmmreg,mem16                   | [rm: vex.128.66.0f38.w0 79 /r]               | AVX2                 |
| VPBROADCASTW     | xmmreg,xmmreg                  | [rm: vex.128.66.0f38.w0 79 /r]               | AVX2                 |
| VPBROADCASTW     | ymmreg,mem16                   | [rm: vex.256.66.0f38.w0 79 /r]               | AVX2                 |
| VPBROADCASTW     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 79 /r]               | AVX2                 |
| VPBROADCASTD     | xmmreg,mem32                   | [rm: vex.128.66.0f38.w0 58 /r]               | AVX2                 |
| VPBROADCASTD     | xmmreg,xmmreg                  | [rm: vex.128.66.0f38.w0 58 /r]               | AVX2                 |
| VPBROADCASTD     | ymmreg,mem32                   | [rm: vex.256.66.0f38.w0 58 /r]               | AVX2                 |
| VPBROADCASTD     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 58 /r]               | AVX2                 |
| VPBROADCASTQ     | xmmreg,mem64                   | [rm: vex.128.66.0f38.w0 59 /r]               | AVX2                 |
| VPBROADCASTQ     | xmmreg,xmmreg                  | [rm: vex.128.66.0f38.w0 59 /r]               | AVX2                 |
| VPBROADCASTQ     | ymmreg,mem64                   | [rm: vex.256.66.0f38.w0 59 /r]               | AVX2                 |
| VPBROADCASTQ     | ymmreg,xmmreg                  | [rm: vex.256.66.0f38.w0 59 /r]               | AVX2                 |
| VPERMD           | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 36 /r]          | AVX2                 |
| VPERMPD          | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a.w1 01 /r ib]           | AVX2                 |
| VPERMPS          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 16 /r]          | AVX2                 |
| VPERMQ           | ymmreg,ymmrm256,imm8           | [rmi: vex.256.66.0f3a.w1 00 /r ib]           | AVX2                 |
| VPERM2I128       | ymmreg,ymmreg*,ymmrm256,imm8   | [rvmi: vex.nds.256.66.0f3a.w0 46 /r ib]      | AVX2                 |
| VEXTRACTI128     | xmmrm128,ymmreg,imm8           | [mri: vex.256.66.0f3a.w0 39 /r ib]           | AVX2                 |
| VINSERTI128      | ymmreg,ymmreg*,xmmrm128,imm8   | [rvmi: vex.nds.256.66.0f3a.w0 38 /r ib]      | AVX2                 |
| VPMASKMOVD       | xmmreg,xmmreg*,mem128          | [rvm: vex.nds.128.66.0f38.w0 8c /r]          | AVX2                 |
| VPMASKMOVD       | ymmreg,ymmreg*,mem256          | [rvm: vex.nds.256.66.0f38.w0 8c /r]          | AVX2                 |
| VPMASKMOVQ       | xmmreg,xmmreg*,mem128          | [rvm: vex.nds.128.66.0f38.w1 8c /r]          | AVX2                 |
| VPMASKMOVQ       | ymmreg,ymmreg*,mem256          | [rvm: vex.nds.256.66.0f38.w1 8c /r]          | AVX2                 |
| VPMASKMOVD       | mem128,xmmreg*,xmmreg          | [mvr: vex.nds.128.66.0f38.w0 8e /r]          | AVX2                 |
| VPMASKMOVD       | mem256,ymmreg*,ymmreg          | [mvr: vex.nds.256.66.0f38.w0 8e /r]          | AVX2                 |
| VPMASKMOVQ       | mem128,xmmreg*,xmmreg          | [mvr: vex.nds.128.66.0f38.w1 8e /r]          | AVX2                 |
| VPMASKMOVQ       | mem256,ymmreg*,ymmreg          | [mvr: vex.nds.256.66.0f38.w1 8e /r]          | AVX2                 |
| VPSLLVD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w0 47 /r]          | AVX2                 |
| VPSLLVQ          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w1 47 /r]          | AVX2                 |
| VPSLLVD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 47 /r]          | AVX2                 |
| VPSLLVQ          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w1 47 /r]          | AVX2                 |
| VPSRAVD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w0 46 /r]          | AVX2                 |
| VPSRAVD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 46 /r]          | AVX2                 |
| VPSRLVD          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w0 45 /r]          | AVX2                 |
| VPSRLVQ          | xmmreg,xmmreg*,xmmrm128        | [rvm: vex.nds.128.66.0f38.w1 45 /r]          | AVX2                 |
| VPSRLVD          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w0 45 /r]          | AVX2                 |
| VPSRLVQ          | ymmreg,ymmreg*,ymmrm256        | [rvm: vex.nds.256.66.0f38.w1 45 /r]          | AVX2                 |
| VGATHERDPD       | xmmreg,xmem64,xmmreg           | [rmv: vm32x vex.dds.128.66.0f38.w1 92 /r]    | AVX2                 |
| VGATHERQPD       | xmmreg,xmem64,xmmreg           | [rmv: vm64x vex.dds.128.66.0f38.w1 93 /r]    | AVX2                 |
| VGATHERDPD       | ymmreg,xmem64,ymmreg           | [rmv: vm32x vex.dds.256.66.0f38.w1 92 /r]    | AVX2                 |
| VGATHERQPD       | ymmreg,ymem64,ymmreg           | [rmv: vm64y vex.dds.256.66.0f38.w1 93 /r]    | AVX2                 |
| VGATHERDPS       | xmmreg,xmem32,xmmreg           | [rmv: vm32x vex.dds.128.66.0f38.w0 92 /r]    | AVX2                 |
| VGATHERQPS       | xmmreg,xmem32,xmmreg           | [rmv: vm64x vex.dds.128.66.0f38.w0 93 /r]    | AVX2                 |
| VGATHERDPS       | ymmreg,ymem32,ymmreg           | [rmv: vm32y vex.dds.256.66.0f38.w0 92 /r]    | AVX2                 |
| VGATHERQPS       | xmmreg,ymem32,xmmreg           | [rmv: vm64y vex.dds.256.66.0f38.w0 93 /r]    | AVX2                 |
| VPGATHERDD       | xmmreg,xmem32,xmmreg           | [rmv: vm32x vex.dds.128.66.0f38.w0 90 /r]    | AVX2                 |
| VPGATHERQD       | xmmreg,xmem32,xmmreg           | [rmv: vm64x vex.dds.128.66.0f38.w0 91 /r]    | AVX2                 |
| VPGATHERDD       | ymmreg,ymem32,ymmreg           | [rmv: vm32y vex.dds.256.66.0f38.w0 90 /r]    | AVX2                 |
| VPGATHERQD       | xmmreg,ymem32,xmmreg           | [rmv: vm64y vex.dds.256.66.0f38.w0 91 /r]    | AVX2                 |
| VPGATHERDQ       | xmmreg,xmem64,xmmreg           | [rmv: vm32x vex.dds.128.66.0f38.w1 90 /r]    | AVX2                 |
| VPGATHERQQ       | xmmreg,xmem64,xmmreg           | [rmv: vm64x vex.dds.128.66.0f38.w1 91 /r]    | AVX2                 |
| VPGATHERDQ       | ymmreg,xmem64,ymmreg           | [rmv: vm32x vex.dds.256.66.0f38.w1 90 /r]    | AVX2                 |
| VPGATHERQQ       | ymmreg,ymem64,ymmreg           | [rmv: vm64y vex.dds.256.66.0f38.w1 91 /r]    | AVX2                 |
| XABORT           | imm                            | [i: c6 f8 ib]                                | FUTURE,RTM           |
| XABORT           | imm8                           | [i: c6 f8 ib]                                | FUTURE,RTM           |
| XBEGIN           | imm                            | [i: odf c7 f8 rel]                           | FUTURE,RTM           |
| XBEGIN           | imm^near                       | [i: odf c7 f8 rel]                           | FUTURE,RTM,ND        |
| XBEGIN           | imm16                          | [i: o16 c7 f8 rel]                           | FUTURE,RTM,NOLONG    |
| XBEGIN           | imm16^near                     | [i: o16 c7 f8 rel]                           | FUTURE,RTM,NOLONG,ND |
| XBEGIN           | imm32                          | [i: o32 c7 f8 rel]                           | FUTURE,RTM,NOLONG    |
| XBEGIN           | imm32^near                     | [i: o32 c7 f8 rel]                           | FUTURE,RTM,NOLONG,ND |
| XBEGIN           | imm64                          | [i: o64nw c7 f8 rel]                         | FUTURE,RTM,LONG      |
| XBEGIN           | imm64^near                     | [i: o64nw c7 f8 rel]                         | FUTURE,RTM,LONG,ND   |
| XEND             | void                           | [0f 01 d5]                                   | FUTURE,RTM           |
| XTEST            | void                           | [0f 01 d6]                                   | FUTURE,HLE,RTM       |
| ANDN             | reg32,reg32,rm32               | [rvm: vex.nds.lz.0f38.w0 f2 /r]              | FUTURE,BMI1          |
| ANDN             | reg64,reg64,rm64               | [rvm: vex.nds.lz.0f38.w1 f2 /r]              | LONG,FUTURE,BMI1     |
| BEXTR            | reg32,rm32,reg32               | [rmv: vex.nds.lz.0f38.w0 f7 /r]              | FUTURE,BMI1          |
| BEXTR            | reg64,rm64,reg64               | [rmv: vex.nds.lz.0f38.w1 f7 /r]              | LONG,FUTURE,BMI1     |
| BEXTR            | reg32,rm32,imm32               | [rmi: xop.m10.lz.w0 10 /r id]                | FUTURE,TBM           |
| BEXTR            | reg64,rm64,imm32               | [rmi: xop.m10.lz.w1 10 /r id]                | LONG,FUTURE,TBM      |
| BLCI             | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 02 /6]                 | FUTURE,TBM           |
| BLCI             | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 02 /6]                 | LONG,FUTURE,TBM      |
| BLCIC            | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /5]                 | FUTURE,TBM           |
| BLCIC            | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /5]                 | LONG,FUTURE,TBM      |
| BLSI             | reg32,rm32                     | [vm: vex.ndd.lz.0f38.w0 f3 /3]               | FUTURE,BMI1          |
| BLSI             | reg64,rm64                     | [vm: vex.ndd.lz.0f38.w1 f3 /3]               | LONG,FUTURE,BMI1     |
| BLSIC            | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /6]                 | FUTURE,TBM           |
| BLSIC            | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /6]                 | LONG,FUTURE,TBM      |
| BLCFILL          | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /1]                 | FUTURE,TBM           |
| BLCFILL          | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /1]                 | LONG,FUTURE,TBM      |
| BLSFILL          | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /2]                 | FUTURE,TBM           |
| BLSFILL          | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /2]                 | LONG,FUTURE,TBM      |
| BLCMSK           | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 02 /1]                 | FUTURE,TBM           |
| BLCMSK           | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 02 /1]                 | LONG,FUTURE,TBM      |
| BLSMSK           | reg32,rm32                     | [vm: vex.ndd.lz.0f38.w0 f3 /2]               | FUTURE,BMI1          |
| BLSMSK           | reg64,rm64                     | [vm: vex.ndd.lz.0f38.w1 f3 /2]               | LONG,FUTURE,BMI1     |
| BLSR             | reg32,rm32                     | [vm: vex.ndd.lz.0f38.w0 f3 /1]               | FUTURE,BMI1          |
| BLSR             | reg64,rm64                     | [vm: vex.ndd.lz.0f38.w1 f3 /1]               | LONG,FUTURE,BMI1     |
| BLCS             | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /3]                 | FUTURE,TBM           |
| BLCS             | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /3]                 | LONG,FUTURE,TBM      |
| BZHI             | reg32,rm32,reg32               | [rmv: vex.nds.lz.0f38.w0 f5 /r]              | FUTURE,BMI2          |
| BZHI             | reg64,rm64,reg64               | [rmv: vex.nds.lz.0f38.w1 f5 /r]              | LONG,FUTURE,BMI2     |
| MULX             | reg32,reg32,rm32               | [rvm: vex.ndd.lz.f2.0f38.w0 f6 /r]           | FUTURE,BMI2          |
| MULX             | reg64,reg64,rm64               | [rvm: vex.ndd.lz.f2.0f38.w1 f6 /r]           | LONG,FUTURE,BMI2     |
| PDEP             | reg32,reg32,rm32               | [rvm: vex.nds.lz.f2.0f38.w0 f5 /r]           | FUTURE,BMI2          |
| PDEP             | reg64,reg64,rm64               | [rvm: vex.nds.lz.f2.0f38.w1 f5 /r]           | LONG,FUTURE,BMI2     |
| PEXT             | reg32,reg32,rm32               | [rvm: vex.nds.lz.f3.0f38.w0 f5 /r]           | FUTURE,BMI2          |
| PEXT             | reg64,reg64,rm64               | [rvm: vex.nds.lz.f3.0f38.w1 f5 /r]           | LONG,FUTURE,BMI2     |
| RORX             | reg32,rm32,imm8                | [rmi: vex.lz.f2.0f3a.w0 f0 /r ib]            | FUTURE,BMI2          |
| RORX             | reg64,rm64,imm8                | [rmi: vex.lz.f2.0f3a.w1 f0 /r ib]            | LONG,FUTURE,BMI2     |
| SARX             | reg32,rm32,reg32               | [rmv: vex.nds.lz.f3.0f38.w0 f7 /r]           | FUTURE,BMI2          |
| SARX             | reg64,rm64,reg64               | [rmv: vex.nds.lz.f3.0f38.w1 f7 /r]           | LONG,FUTURE,BMI2     |
| SHLX             | reg32,rm32,reg32               | [rmv: vex.nds.lz.66.0f38.w0 f7 /r]           | FUTURE,BMI2          |
| SHLX             | reg64,rm64,reg64               | [rmv: vex.nds.lz.66.0f38.w1 f7 /r]           | LONG,FUTURE,BMI2     |
| SHRX             | reg32,rm32,reg32               | [rmv: vex.nds.lz.f2.0f38.w0 f7 /r]           | FUTURE,BMI2          |
| SHRX             | reg64,rm64,reg64               | [rmv: vex.nds.lz.f2.0f38.w1 f7 /r]           | LONG,FUTURE,BMI2     |
| TZCNT            | reg16,rm16                     | [rm: o16 f3i 0f bc /r]                       | FUTURE,BMI1          |
| TZCNT            | reg32,rm32                     | [rm: o32 f3i 0f bc /r]                       | FUTURE,BMI1          |
| TZCNT            | reg64,rm64                     | [rm: o64 f3i 0f bc /r]                       | LONG,FUTURE,BMI1     |
| TZMSK            | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /4]                 | FUTURE,TBM           |
| TZMSK            | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /4]                 | LONG,FUTURE,TBM      |
| T1MSKC           | reg32,rm32                     | [vm: xop.ndd.lz.m9.w0 01 /7]                 | FUTURE,TBM           |
| T1MSKC           | reg64,rm64                     | [vm: xop.ndd.lz.m9.w1 01 /7]                 | LONG,FUTURE,TBM      |
| PREFETCHWT1      | mem8                           | [m: 0f 0d /2 ]                               | PREFETCHWT1          |
| BNDMK            | bndreg,mem                     | [rm:      f3 0f 1b /r ]                      | MPX,MIB              |
| BNDCL            | bndreg,mem                     | [rm:      f3 0f 1a /r ]                      | MPX                  |
| BNDCL            | bndreg,reg32                   | [rm:      f3 0f 1a /r ]                      | MPX,NOLONG           |
| BNDCL            | bndreg,reg64                   | [rm:   o64nw f3 0f 1a /r ]                   | MPX,LONG             |
| BNDCU            | bndreg,mem                     | [rm:      f2 0f 1a /r ]                      | MPX                  |
| BNDCU            | bndreg,reg32                   | [rm:      f2 0f 1a /r ]                      | MPX,NOLONG           |
| BNDCU            | bndreg,reg64                   | [rm:   o64nw f2 0f 1a /r ]                   | MPX,LONG             |
| BNDCN            | bndreg,mem                     | [rm:      f2 0f 1b /r ]                      | MPX                  |
| BNDCN            | bndreg,reg32                   | [rm:      f2 0f 1b /r ]                      | MPX,NOLONG           |
| BNDCN            | bndreg,reg64                   | [rm:   o64nw f2 0f 1b /r ]                   | MPX,LONG             |
| BNDMOV           | bndreg,bndreg                  | [rm:      66 0f 1a /r ]                      | MPX                  |
| BNDMOV           | bndreg,mem                     | [rm:      66 0f 1a /r ]                      | MPX                  |
| BNDMOV           | bndreg,bndreg                  | [mr:      66 0f 1b /r ]                      | MPX                  |
| BNDMOV           | mem,bndreg                     | [mr:      66 0f 1b /r ]                      | MPX                  |
| BNDLDX           | bndreg,mem                     | [rm:         0f 1a /r ]                      | MPX,MIB              |
| BNDLDX           | bndreg,mem,reg32               | [rmx:        0f 1a /r ]                      | MPX,MIB,NOLONG       |
| BNDLDX           | bndreg,mem,reg64               | [rmx:        0f 1a /r ]                      | MPX,MIB,LONG         |
| BNDSTX           | mem,bndreg                     | [mr:         0f 1b /r ]                      | MPX,MIB              |
| BNDSTX           | mem,reg32,bndreg               | [mxr:        0f 1b /r ]                      | MPX,MIB,NOLONG       |
| BNDSTX           | mem,reg64,bndreg               | [mxr:        0f 1b /r ]                      | MPX,MIB,LONG         |
| BNDSTX           | mem,bndreg,reg32               | [mrx:        0f 1b /r ]                      | MPX,MIB,NOLONG       |
| BNDSTX           | mem,bndreg,reg64               | [mrx:        0f 1b /r ]                      | MPX,MIB,LONG         |
| SHA1MSG1         | xmmreg,xmmrm128                | [rm: 0f 38 c9 /r ]                           | SHA                  |
| SHA1MSG2         | xmmreg,xmmrm128                | [rm: 0f 38 ca /r ]                           | SHA                  |
| SHA1NEXTE        | xmmreg,xmmrm128                | [rm: 0f 38 c8 /r ]                           | SHA                  |
| SHA1RNDS4        | xmmreg,xmmrm128,imm8           | [rmi: 0f 3a cc /r ib ]                       | SHA                  |
| SHA256MSG1       | xmmreg,xmmrm128                | [rm: 0f 38 cc /r ]                           | SHA                  |
| SHA256MSG2       | xmmreg,xmmrm128                | [rm: 0f 38 cd /r ]                           | SHA                  |
| SHA256RNDS2      | xmmreg,xmmrm128,xmm0           | [rm-: 0f 38 cb /r ]                          | SHA                  |
| SHA256RNDS2      | xmmreg,xmmrm128                | [rm:  0f 38 cb /r ]                          | SHA                  |
| KADDB            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 4a /r ]            | FUTURE               |
| KADDD            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 4a /r ]            | FUTURE               |
| KADDQ            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 4a /r ]               | FUTURE               |
| KADDW            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 4a /r ]               | FUTURE               |
| KANDB            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 41 /r ]            | FUTURE               |
| KANDD            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 41 /r ]            | FUTURE               |
| KANDNB           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 42 /r ]            | FUTURE               |
| KANDND           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 42 /r ]            | FUTURE               |
| KANDNQ           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 42 /r ]               | FUTURE               |
| KANDNW           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 42 /r ]               | FUTURE               |
| KANDQ            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 41 /r ]               | FUTURE               |
| KANDW            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 41 /r ]               | FUTURE               |
| KMOVB            | kreg,krm8                      | [rm: vex.l0.66.0f.w0 90 /r ]                 | FUTURE               |
| KMOVB            | mem8,kreg                      | [mr: vex.l0.66.0f.w0 91 /r ]                 | FUTURE               |
| KMOVB            | kreg,reg32                     | [rm: vex.l0.66.0f.w0 92 /r ]                 | FUTURE               |
| KMOVB            | reg32,kreg                     | [rm: vex.l0.66.0f.w0 93 /r ]                 | FUTURE               |
| KMOVD            | kreg,krm32                     | [rm: vex.l0.66.0f.w1 90 /r ]                 | FUTURE               |
| KMOVD            | mem32,kreg                     | [mr: vex.l0.66.0f.w1 91 /r ]                 | FUTURE               |
| KMOVD            | kreg,reg32                     | [rm: vex.l0.f2.0f.w0 92 /r ]                 | FUTURE               |
| KMOVD            | reg32,kreg                     | [rm: vex.l0.f2.0f.w0 93 /r ]                 | FUTURE               |
| KMOVQ            | kreg,krm64                     | [rm: vex.l0.0f.w1 90 /r ]                    | FUTURE               |
| KMOVQ            | mem64,kreg                     | [mr: vex.l0.0f.w1 91 /r ]                    | FUTURE               |
| KMOVQ            | kreg,reg64                     | [rm: vex.l0.f2.0f.w1 92 /r ]                 | FUTURE               |
| KMOVQ            | reg64,kreg                     | [rm: vex.l0.f2.0f.w1 93 /r ]                 | FUTURE               |
| KMOVW            | kreg,krm16                     | [rm: vex.l0.0f.w0 90 /r ]                    | FUTURE               |
| KMOVW            | mem16,kreg                     | [mr: vex.l0.0f.w0 91 /r ]                    | FUTURE               |
| KMOVW            | kreg,reg32                     | [rm: vex.l0.0f.w0 92 /r ]                    | FUTURE               |
| KMOVW            | reg32,kreg                     | [rm: vex.l0.0f.w0 93 /r ]                    | FUTURE               |
| KNOTB            | kreg,kreg                      | [rm: vex.l0.66.0f.w0 44 /r ]                 | FUTURE               |
| KNOTD            | kreg,kreg                      | [rm: vex.l0.66.0f.w1 44 /r ]                 | FUTURE               |
| KNOTQ            | kreg,kreg                      | [rm: vex.l0.0f.w1 44 /r ]                    | FUTURE               |
| KNOTW            | kreg,kreg                      | [rm: vex.l0.0f.w0 44 /r ]                    | FUTURE               |
| KORB             | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 45 /r ]            | FUTURE               |
| KORD             | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 45 /r ]            | FUTURE               |
| KORQ             | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 45 /r ]               | FUTURE               |
| KORTESTB         | kreg,kreg                      | [rm: vex.l0.66.0f.w0 98 /r ]                 | FUTURE               |
| KORTESTD         | kreg,kreg                      | [rm: vex.l0.66.0f.w1 98 /r ]                 | FUTURE               |
| KORTESTQ         | kreg,kreg                      | [rm: vex.l0.0f.w1 98 /r ]                    | FUTURE               |
| KORTESTW         | kreg,kreg                      | [rm: vex.l0.0f.w0 98 /r ]                    | FUTURE               |
| KORW             | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 45 /r ]               | FUTURE               |
| KSHIFTLB         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w0 32 /r ib ]           | FUTURE               |
| KSHIFTLD         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w0 33 /r ib ]           | FUTURE               |
| KSHIFTLQ         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w1 33 /r ib ]           | FUTURE               |
| KSHIFTLW         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w1 32 /r ib ]           | FUTURE               |
| KSHIFTRB         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w0 30 /r ib ]           | FUTURE               |
| KSHIFTRD         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w0 31 /r ib ]           | FUTURE               |
| KSHIFTRQ         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w1 31 /r ib ]           | FUTURE               |
| KSHIFTRW         | kreg,kreg,imm8                 | [rmi: vex.l0.66.0f3a.w1 30 /r ib ]           | FUTURE               |
| KTESTB           | kreg,kreg                      | [rm: vex.l0.66.0f.w0 99 /r ]                 | FUTURE               |
| KTESTD           | kreg,kreg                      | [rm: vex.l0.66.0f.w1 99 /r ]                 | FUTURE               |
| KTESTQ           | kreg,kreg                      | [rm: vex.l0.0f.w1 99 /r ]                    | FUTURE               |
| KTESTW           | kreg,kreg                      | [rm: vex.l0.0f.w0 99 /r ]                    | FUTURE               |
| KUNPCKBW         | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 4b /r ]            | FUTURE               |
| KUNPCKDQ         | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 4b /r ]               | FUTURE               |
| KUNPCKWD         | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 4b /r ]               | FUTURE               |
| KXNORB           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 46 /r ]            | FUTURE               |
| KXNORD           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 46 /r ]            | FUTURE               |
| KXNORQ           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 46 /r ]               | FUTURE               |
| KXNORW           | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 46 /r ]               | FUTURE               |
| KXORB            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w0 47 /r ]            | FUTURE               |
| KXORD            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.66.0f.w1 47 /r ]            | FUTURE               |
| KXORQ            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w1 47 /r ]               | FUTURE               |
| KXORW            | kreg,kreg,kreg                 | [rvm: vex.nds.l1.0f.w0 47 /r ]               | FUTURE               |

AVX-512
-------------------------------------------------------------------------------------------------------------------------
| VADDPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 58 /r ]          | AVX512VL,AVX512          |
| VADDPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 58 /r ]          | AVX512VL,AVX512          |
| VADDPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^er       | [rvm:fv: evex.nds.512.66.0f.w1 58 /r ]          | AVX512                   |
| VADDPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 58 /r ]             | AVX512VL,AVX512          |
| VADDPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 58 /r ]             | AVX512VL,AVX512          |
| VADDPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^er       | [rvm:fv: evex.nds.512.0f.w0 58 /r ]             | AVX512                   |
| VADDSD            | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.f2.0f.w1 58 /r ]         | AVX512                   |
| VADDSS            | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.f3.0f.w0 58 /r ]         | AVX512                   |
| VALIGND           | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w0 03 /r ib ]    | AVX512VL,AVX512          |
| VALIGND           | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w0 03 /r ib ]    | AVX512VL,AVX512          |
| VALIGND           | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w0 03 /r ib ]    | AVX512                   |
| VALIGNQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w1 03 /r ib ]    | AVX512VL,AVX512          |
| VALIGNQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 03 /r ib ]    | AVX512VL,AVX512          |
| VALIGNQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w1 03 /r ib ]    | AVX512                   |
| VANDNPD           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 55 /r ]          | AVX512VL,AVX512DQ        |
| VANDNPD           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 55 /r ]          | AVX512VL,AVX512DQ        |
| VANDNPD           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 55 /r ]          | AVX512DQ                 |
| VANDNPS           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 55 /r ]             | AVX512VL,AVX512DQ        |
| VANDNPS           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 55 /r ]             | AVX512VL,AVX512DQ        |
| VANDNPS           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 55 /r ]             | AVX512DQ                 |
| VANDPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 54 /r ]          | AVX512VL,AVX512DQ        |
| VANDPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 54 /r ]          | AVX512VL,AVX512DQ        |
| VANDPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 54 /r ]          | AVX512DQ                 |
| VANDPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 54 /r ]             | AVX512VL,AVX512DQ        |
| VANDPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 54 /r ]             | AVX512VL,AVX512DQ        |
| VANDPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 54 /r ]             | AVX512DQ                 |
| VBLENDMPD         | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 65 /r ]        | AVX512VL,AVX512          |
| VBLENDMPD         | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 65 /r ]        | AVX512VL,AVX512          |
| VBLENDMPD         | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 65 /r ]        | AVX512                   |
| VBLENDMPS         | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 65 /r ]        | AVX512VL,AVX512          |
| VBLENDMPS         | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 65 /r ]        | AVX512VL,AVX512          |
| VBLENDMPS         | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 65 /r ]        | AVX512                   |
| VBROADCASTF32X2   | ymmreg^mask^z,xmmrm64                       | [rm:t2: evex.256.66.0f38.w0 19 /r ]             | AVX512VL,AVX512DQ        |
| VBROADCASTF32X2   | zmmreg^mask^z,xmmrm64                       | [rm:t2: evex.512.66.0f38.w0 19 /r ]             | AVX512DQ                 |
| VBROADCASTF32X4   | ymmreg^mask^z,mem128                        | [rm:t4: evex.256.66.0f38.w0 1a /r ]             | AVX512VL,AVX512          |
| VBROADCASTF32X4   | zmmreg^mask^z,mem128                        | [rm:t4: evex.512.66.0f38.w0 1a /r ]             | AVX512                   |
| VBROADCASTF32X8   | zmmreg^mask^z,mem256                        | [rm:t8: evex.512.66.0f38.w0 1b /r ]             | AVX512DQ                 |
| VBROADCASTF64X2   | ymmreg^mask^z,mem128                        | [rm:t2: evex.256.66.0f38.w1 1a /r ]             | AVX512VL,AVX512DQ        |
| VBROADCASTF64X2   | zmmreg^mask^z,mem128                        | [rm:t2: evex.512.66.0f38.w1 1a /r ]             | AVX512DQ                 |
| VBROADCASTF64X4   | zmmreg^mask^z,mem256                        | [rm:t4: evex.512.66.0f38.w1 1b /r ]             | AVX512                   |
| VBROADCASTI32X2   | xmmreg^mask^z,xmmrm64                       | [rm:t2: evex.128.66.0f38.w0 59 /r ]             | AVX512VL,AVX512DQ        |
| VBROADCASTI32X2   | ymmreg^mask^z,xmmrm64                       | [rm:t2: evex.256.66.0f38.w0 59 /r ]             | AVX512VL,AVX512DQ        |
| VBROADCASTI32X2   | zmmreg^mask^z,xmmrm64                       | [rm:t2: evex.512.66.0f38.w0 59 /r ]             | AVX512DQ                 |
| VBROADCASTI32X4   | ymmreg^mask^z,mem128                        | [rm:t4: evex.256.66.0f38.w0 5a /r ]             | AVX512VL,AVX512          |
| VBROADCASTI32X4   | zmmreg^mask^z,mem128                        | [rm:t4: evex.512.66.0f38.w0 5a /r ]             | AVX512                   |
| VBROADCASTI32X8   | zmmreg^mask^z,mem256                        | [rm:t8: evex.512.66.0f38.w0 5b /r ]             | AVX512DQ                 |
| VBROADCASTI64X2   | ymmreg^mask^z,mem128                        | [rm:t2: evex.256.66.0f38.w1 5a /r ]             | AVX512VL,AVX512DQ        |
| VBROADCASTI64X2   | zmmreg^mask^z,mem128                        | [rm:t2: evex.512.66.0f38.w1 5a /r ]             | AVX512DQ                 |
| VBROADCASTI64X4   | zmmreg^mask^z,mem256                        | [rm:t4: evex.512.66.0f38.w1 5b /r ]             | AVX512                   |
| VBROADCASTSD      | ymmreg^mask^z,mem64                         | [rm:t1s: evex.256.66.0f38.w1 19 /r ]            | AVX512VL,AVX512          |
| VBROADCASTSD      | zmmreg^mask^z,mem64                         | [rm:t1s: evex.512.66.0f38.w1 19 /r ]            | AVX512                   |
| VBROADCASTSD      | ymmreg^mask^z,xmmreg                        | [rm: evex.256.66.0f38.w1 19 /r ]                | AVX512VL,AVX512          |
| VBROADCASTSD      | zmmreg^mask^z,xmmreg                        | [rm: evex.512.66.0f38.w1 19 /r ]                | AVX512                   |
| VBROADCASTSS      | xmmreg^mask^z,mem32                         | [rm:t1s: evex.128.66.0f38.w0 18 /r ]            | AVX512VL,AVX512          |
| VBROADCASTSS      | ymmreg^mask^z,mem32                         | [rm:t1s: evex.256.66.0f38.w0 18 /r ]            | AVX512VL,AVX512          |
| VBROADCASTSS      | zmmreg^mask^z,mem32                         | [rm:t1s: evex.512.66.0f38.w0 18 /r ]            | AVX512                   |
| VBROADCASTSS      | xmmreg^mask^z,xmmreg                        | [rm: evex.128.66.0f38.w0 18 /r ]                | AVX512VL,AVX512          |
| VBROADCASTSS      | ymmreg^mask^z,xmmreg                        | [rm: evex.256.66.0f38.w0 18 /r ]                | AVX512VL,AVX512          |
| VBROADCASTSS      | zmmreg^mask^z,xmmreg                        | [rm: evex.512.66.0f38.w0 18 /r ]                | AVX512                   |
| VCMPPD            | kreg^mask,xmmreg,xmmrm128^b64,imm8          | [rvmi:fv: evex.nds.128.66.0f.w1 c2 /r ib ]      | AVX512VL,AVX512          |
| VCMPPD            | kreg^mask,ymmreg,ymmrm256^b64,imm8          | [rvmi:fv: evex.nds.256.66.0f.w1 c2 /r ib ]      | AVX512VL,AVX512          |
| VCMPPD            | kreg^mask,zmmreg,zmmrm512^b64^sae,imm8      | [rvmi:fv: evex.nds.512.66.0f.w1 c2 /r ib ]      | AVX512                   |
| VCMPPS            | kreg^mask,xmmreg,xmmrm128^b32,imm8          | [rvmi:fv: evex.nds.128.0f.w0 c2 /r ib ]         | AVX512VL,AVX512          |
| VCMPPS            | kreg^mask,ymmreg,ymmrm256^b32,imm8          | [rvmi:fv: evex.nds.256.0f.w0 c2 /r ib ]         | AVX512VL,AVX512          |
| VCMPPS            | kreg^mask,zmmreg,zmmrm512^b32^sae,imm8      | [rvmi:fv: evex.nds.512.0f.w0 c2 /r ib ]         | AVX512                   |
| VCMPSD            | kreg^mask,xmmreg,xmmrm64^sae,imm8           | [rvmi:t1s: evex.nds.128.f2.0f.w1 c2 /r ib ]     | AVX512                   |
| VCMPSS            | kreg^mask,xmmreg,xmmrm32^sae,imm8           | [rvmi:t1s: evex.nds.128.f3.0f.w0 c2 /r ib ]     | AVX512                   |
| VCOMISD           | xmmreg,xmmrm64^sae                          | [rm:t1s: evex.128.66.0f.w1 2f /r ]              | AVX512                   |
| VCOMISS           | xmmreg,xmmrm32^sae                          | [rm:t1s: evex.128.0f.w0 2f /r ]                 | AVX512                   |
| VCOMPRESSPD       | mem128^mask,xmmreg                          | [mr:t1s: evex.128.66.0f38.w1 8a /r ]            | AVX512VL,AVX512          |
| VCOMPRESSPD       | mem256^mask,ymmreg                          | [mr:t1s: evex.256.66.0f38.w1 8a /r ]            | AVX512VL,AVX512          |
| VCOMPRESSPD       | zmem512^mask,zmmreg                         | [mr:t1s: evex.512.66.0f38.w1 8a /r ]            | AVX512                   |
| VCOMPRESSPD       | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f38.w1 8a /r ]                | AVX512VL,AVX512          |
| VCOMPRESSPD       | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f38.w1 8a /r ]                | AVX512VL,AVX512          |
| VCOMPRESSPD       | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f38.w1 8a /r ]                | AVX512                   |
| VCOMPRESSPS       | mem128^mask,xmmreg                          | [mr:t1s: evex.128.66.0f38.w0 8a /r ]            | AVX512VL,AVX512          |
| VCOMPRESSPS       | mem256^mask,ymmreg                          | [mr:t1s: evex.256.66.0f38.w0 8a /r ]            | AVX512VL,AVX512          |
| VCOMPRESSPS       | zmem512^mask,zmmreg                         | [mr:t1s: evex.512.66.0f38.w0 8a /r ]            | AVX512                   |
| VCOMPRESSPS       | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f38.w0 8a /r ]                | AVX512VL,AVX512          |
| VCOMPRESSPS       | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f38.w0 8a /r ]                | AVX512VL,AVX512          |
| VCOMPRESSPS       | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f38.w0 8a /r ]                | AVX512                   |
| VCVTDQ2PD         | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.f3.0f.w0 e6 /r ]               | AVX512VL,AVX512          |
| VCVTDQ2PD         | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.f3.0f.w0 e6 /r ]               | AVX512VL,AVX512          |
| VCVTDQ2PD         | zmmreg^mask^z,ymmrm256^b32^er               | [rm:hv: evex.512.f3.0f.w0 e6 /r ]               | AVX512                   |
| VCVTDQ2PS         | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.0f.w0 5b /r ]                  | AVX512VL,AVX512          |
| VCVTDQ2PS         | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.0f.w0 5b /r ]                  | AVX512VL,AVX512          |
| VCVTDQ2PS         | zmmreg^mask^z,zmmrm512^b32^er               | [rm:fv: evex.512.0f.w0 5b /r ]                  | AVX512                   |
| VCVTPD2DQ         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.f2.0f.w1 e6 /r ]               | AVX512VL,AVX512          |
| VCVTPD2DQ         | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.f2.0f.w1 e6 /r ]               | AVX512VL,AVX512          |
| VCVTPD2DQ         | ymmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.f2.0f.w1 e6 /r ]               | AVX512                   |
| VCVTPD2PS         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 5a /r ]               | AVX512VL,AVX512          |
| VCVTPD2PS         | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 5a /r ]               | AVX512VL,AVX512          |
| VCVTPD2PS         | ymmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.66.0f.w1 5a /r ]               | AVX512                   |
| VCVTPD2QQ         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 7b /r ]               | AVX512VL,AVX512DQ        |
| VCVTPD2QQ         | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 7b /r ]               | AVX512VL,AVX512DQ        |
| VCVTPD2QQ         | zmmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.66.0f.w1 7b /r ]               | AVX512DQ                 |
| VCVTPD2UDQ        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.0f.w1 79 /r ]                  | AVX512VL,AVX512          |
| VCVTPD2UDQ        | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.0f.w1 79 /r ]                  | AVX512VL,AVX512          |
| VCVTPD2UDQ        | ymmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.0f.w1 79 /r ]                  | AVX512                   |
| VCVTPD2UQQ        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 79 /r ]               | AVX512VL,AVX512DQ        |
| VCVTPD2UQQ        | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 79 /r ]               | AVX512VL,AVX512DQ        |
| VCVTPD2UQQ        | zmmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.66.0f.w1 79 /r ]               | AVX512DQ                 |
| VCVTPH2PS         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.w0 13 /r ]            | AVX512VL,AVX512          |
| VCVTPH2PS         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.w0 13 /r ]            | AVX512VL,AVX512          |
| VCVTPH2PS         | zmmreg^mask^z,ymmrm256^sae                  | [rm:hvm: evex.512.66.0f38.w0 13 /r ]            | AVX512                   |
| VCVTPS2DQ         | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f.w0 5b /r ]               | AVX512VL,AVX512          |
| VCVTPS2DQ         | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f.w0 5b /r ]               | AVX512VL,AVX512          |
| VCVTPS2DQ         | zmmreg^mask^z,zmmrm512^b32^er               | [rm:fv: evex.512.66.0f.w0 5b /r ]               | AVX512                   |
| VCVTPS2PD         | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.0f.w0 5a /r ]                  | AVX512VL,AVX512          |
| VCVTPS2PD         | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.0f.w0 5a /r ]                  | AVX512VL,AVX512          |
| VCVTPS2PD         | zmmreg^mask^z,ymmrm256^b32^sae              | [rm:hv: evex.512.0f.w0 5a /r ]                  | AVX512                   |
| VCVTPS2PH         | xmmreg^mask^z,xmmreg,imm8                   | [mri:hvm: evex.128.66.0f3a.w0 1d /r ib ]        | AVX512VL,AVX512          |
| VCVTPS2PH         | xmmreg^mask^z,ymmreg,imm8                   | [mri:hvm: evex.256.66.0f3a.w0 1d /r ib ]        | AVX512VL,AVX512          |
| VCVTPS2PH         | ymmreg^mask^z,zmmreg^sae,imm8               | [mri:hvm: evex.512.66.0f3a.w0 1d /r ib ]        | AVX512                   |
| VCVTPS2PH         | mem64^mask,xmmreg,imm8                      | [mri:hvm: evex.128.66.0f3a.w0 1d /r ib ]        | AVX512VL,AVX512          |
| VCVTPS2PH         | mem128^mask,ymmreg,imm8                     | [mri:hvm: evex.256.66.0f3a.w0 1d /r ib ]        | AVX512VL,AVX512          |
| VCVTPS2PH         | mem256^mask,zmmreg^sae,imm8                 | [mri:hvm: evex.512.66.0f3a.w0 1d /r ib ]        | AVX512                   |
| VCVTPS2QQ         | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.66.0f.w0 7b /r ]               | AVX512VL,AVX512DQ        |
| VCVTPS2QQ         | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.66.0f.w0 7b /r ]               | AVX512VL,AVX512DQ        |
| VCVTPS2QQ         | zmmreg^mask^z,ymmrm256^b32^er               | [rm:hv: evex.512.66.0f.w0 7b /r ]               | AVX512DQ                 |
| VCVTPS2UDQ        | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.0f.w0 79 /r ]                  | AVX512VL,AVX512          |
| VCVTPS2UDQ        | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.0f.w0 79 /r ]                  | AVX512VL,AVX512          |
| VCVTPS2UDQ        | zmmreg^mask^z,zmmrm512^b32^er               | [rm:fv: evex.512.0f.w0 79 /r ]                  | AVX512                   |
| VCVTPS2UQQ        | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.66.0f.w0 79 /r ]               | AVX512VL,AVX512DQ        |
| VCVTPS2UQQ        | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.66.0f.w0 79 /r ]               | AVX512VL,AVX512DQ        |
| VCVTPS2UQQ        | zmmreg^mask^z,ymmrm256^b32^er               | [rm:hv: evex.512.66.0f.w0 79 /r ]               | AVX512DQ                 |
| VCVTQQ2PD         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.f3.0f.w1 e6 /r ]               | AVX512VL,AVX512DQ        |
| VCVTQQ2PD         | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.f3.0f.w1 e6 /r ]               | AVX512VL,AVX512DQ        |
| VCVTQQ2PD         | zmmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.f3.0f.w1 e6 /r ]               | AVX512DQ                 |
| VCVTQQ2PS         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.0f.w1 5b /r ]                  | AVX512VL,AVX512DQ        |
| VCVTQQ2PS         | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.0f.w1 5b /r ]                  | AVX512VL,AVX512DQ        |
| VCVTQQ2PS         | ymmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.0f.w1 5b /r ]                  | AVX512DQ                 |
| VCVTSD2SI         | reg32,xmmrm64^er                            | [rm:t1f64: evex.128.f2.0f.w0 2d /r ]            | AVX512                   |
| VCVTSD2SI         | reg64,xmmrm64^er                            | [rm:t1f64: evex.128.f2.0f.w1 2d /r ]            | AVX512                   |
| VCVTSD2SS         | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.f2.0f.w1 5a /r ]         | AVX512                   |
| VCVTSD2USI        | reg32,xmmrm64^er                            | [rm:t1f64: evex.128.f2.0f.w0 79 /r ]            | AVX512                   |
| VCVTSD2USI        | reg64,xmmrm64^er                            | [rm:t1f64: evex.128.f2.0f.w1 79 /r ]            | AVX512                   |
| VCVTSI2SD         | xmmreg,  xmmreg^er,rm32                     | [rvm:t1s: evex.nds.128.f2.0f.w0 2a /r ]         | AVX512                   |
| VCVTSI2SD         | xmmreg,  xmmreg^er,rm64                     | [rvm:t1s: evex.nds.128.f2.0f.w1 2a /r ]         | AVX512                   |
| VCVTSI2SS         | xmmreg,  xmmreg^er,rm32                     | [rvm:t1s: evex.nds.128.f3.0f.w0 2a /r ]         | AVX512                   |
| VCVTSI2SS         | xmmreg,  xmmreg^er,rm64                     | [rvm:t1s: evex.nds.128.f3.0f.w1 2a /r ]         | AVX512                   |
| VCVTSS2SD         | xmmreg^mask^z,xmmreg,xmmrm32^sae            | [rvm:t1s: evex.nds.128.f3.0f.w0 5a /r ]         | AVX512                   |
| VCVTSS2SI         | reg32,xmmrm32^er                            | [rm:t1f32: evex.128.f3.0f.w0 2d /r ]            | AVX512                   |
| VCVTSS2SI         | reg64,xmmrm32^er                            | [rm:t1f32: evex.128.f3.0f.w1 2d /r ]            | AVX512                   |
| VCVTSS2USI        | reg32,xmmrm32^er                            | [rm:t1f32: evex.128.f3.0f.w0 79 /r ]            | AVX512                   |
| VCVTSS2USI        | reg64,xmmrm32^er                            | [rm:t1f32: evex.128.f3.0f.w1 79 /r ]            | AVX512                   |
| VCVTTPD2DQ        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 e6 /r ]               | AVX512VL,AVX512          |
| VCVTTPD2DQ        | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 e6 /r ]               | AVX512VL,AVX512          |
| VCVTTPD2DQ        | ymmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f.w1 e6 /r ]               | AVX512                   |
| VCVTTPD2QQ        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPD2QQ        | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPD2QQ        | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f.w1 7a /r ]               | AVX512DQ                 |
| VCVTTPD2UDQ       | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.0f.w1 78 /r ]                  | AVX512VL,AVX512          |
| VCVTTPD2UDQ       | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.0f.w1 78 /r ]                  | AVX512VL,AVX512          |
| VCVTTPD2UDQ       | ymmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.0f.w1 78 /r ]                  | AVX512                   |
| VCVTTPD2UQQ       | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 78 /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPD2UQQ       | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 78 /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPD2UQQ       | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f.w1 78 /r ]               | AVX512DQ                 |
| VCVTTPS2DQ        | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.f3.0f.w0 5b /r ]               | AVX512VL,AVX512          |
| VCVTTPS2DQ        | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.f3.0f.w0 5b /r ]               | AVX512VL,AVX512          |
| VCVTTPS2DQ        | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.f3.0f.w0 5b /r ]               | AVX512                   |
| VCVTTPS2QQ        | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.66.0f.w0 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPS2QQ        | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.66.0f.w0 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPS2QQ        | zmmreg^mask^z,ymmrm256^b32^sae              | [rm:hv: evex.512.66.0f.w0 7a /r ]               | AVX512DQ                 |
| VCVTTPS2UDQ       | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.0f.w0 78 /r ]                  | AVX512VL,AVX512          |
| VCVTTPS2UDQ       | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.0f.w0 78 /r ]                  | AVX512VL,AVX512          |
| VCVTTPS2UDQ       | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.0f.w0 78 /r ]                  | AVX512                   |
| VCVTTPS2UQQ       | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.66.0f.w0 78 /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPS2UQQ       | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.66.0f.w0 78 /r ]               | AVX512VL,AVX512DQ        |
| VCVTTPS2UQQ       | zmmreg^mask^z,ymmrm256^b32^sae              | [rm:hv: evex.512.66.0f.w0 78 /r ]               | AVX512DQ                 |
| VCVTTSD2SI        | reg32,xmmrm64^sae                           | [rm:t1f64: evex.128.f2.0f.w0 2c /r ]            | AVX512                   |
| VCVTTSD2SI        | reg64,xmmrm64^sae                           | [rm:t1f64: evex.128.f2.0f.w1 2c /r ]            | AVX512                   |
| VCVTTSD2USI       | reg32,xmmrm64^sae                           | [rm:t1f64: evex.128.f2.0f.w0 78 /r ]            | AVX512                   |
| VCVTTSD2USI       | reg64,xmmrm64^sae                           | [rm:t1f64: evex.128.f2.0f.w1 78 /r ]            | AVX512                   |
| VCVTTSS2SI        | reg32,xmmrm32^sae                           | [rm:t1f32: evex.128.f3.0f.w0 2c /r ]            | AVX512                   |
| VCVTTSS2SI        | reg64,xmmrm32^sae                           | [rm:t1f32: evex.128.f3.0f.w1 2c /r ]            | AVX512                   |
| VCVTTSS2USI       | reg32,xmmrm32^sae                           | [rm:t1f32: evex.128.f3.0f.w0 78 /r ]            | AVX512                   |
| VCVTTSS2USI       | reg64,xmmrm32^sae                           | [rm:t1f32: evex.128.f3.0f.w1 78 /r ]            | AVX512                   |
| VCVTUDQ2PD        | xmmreg^mask^z,xmmrm64^b32                   | [rm:hv: evex.128.f3.0f.w0 7a /r ]               | AVX512VL,AVX512          |
| VCVTUDQ2PD        | ymmreg^mask^z,xmmrm128^b32                  | [rm:hv: evex.256.f3.0f.w0 7a /r ]               | AVX512VL,AVX512          |
| VCVTUDQ2PD        | zmmreg^mask^z,ymmrm256^b32^er               | [rm:hv: evex.512.f3.0f.w0 7a /r ]               | AVX512                   |
| VCVTUDQ2PS        | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.f2.0f.w0 7a /r ]               | AVX512VL,AVX512          |
| VCVTUDQ2PS        | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.f2.0f.w0 7a /r ]               | AVX512VL,AVX512          |
| VCVTUDQ2PS        | zmmreg^mask^z,zmmrm512^b32^er               | [rm:fv: evex.512.f2.0f.w0 7a /r ]               | AVX512                   |
| VCVTUQQ2PD        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.f3.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTUQQ2PD        | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.f3.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTUQQ2PD        | zmmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.f3.0f.w1 7a /r ]               | AVX512DQ                 |
| VCVTUQQ2PS        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.f2.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTUQQ2PS        | xmmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.f2.0f.w1 7a /r ]               | AVX512VL,AVX512DQ        |
| VCVTUQQ2PS        | ymmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.f2.0f.w1 7a /r ]               | AVX512DQ                 |
| VCVTUSI2SD        | xmmreg,xmmreg^er,rm32                       | [rvm:t1s: evex.nds.128.f2.0f.w0 7b /r ]         | AVX512                   |
| VCVTUSI2SD        | xmmreg,xmmreg^er,rm64                       | [rvm:t1s: evex.nds.128.f2.0f.w1 7b /r ]         | AVX512                   |
| VCVTUSI2SS        | xmmreg,xmmreg^er,rm32                       | [rvm:t1s: evex.nds.128.f3.0f.w0 7b /r ]         | AVX512                   |
| VCVTUSI2SS        | xmmreg,xmmreg^er,rm64                       | [rvm:t1s: evex.nds.128.f3.0f.w1 7b /r ]         | AVX512                   |
| VDBPSADBW         | xmmreg^mask^z,xmmreg*,xmmrm128,imm8         | [rvmi:fvm: evex.nds.128.66.0f3a.w0 42 /r ib ]   | AVX512VL,AVX512BW        |
| VDBPSADBW         | ymmreg^mask^z,ymmreg*,ymmrm256,imm8         | [rvmi:fvm: evex.nds.256.66.0f3a.w0 42 /r ib ]   | AVX512VL,AVX512BW        |
| VDBPSADBW         | zmmreg^mask^z,zmmreg*,zmmrm512,imm8         | [rvmi:fvm: evex.nds.512.66.0f3a.w0 42 /r ib ]   | AVX512BW                 |
| VDIVPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 5e /r ]          | AVX512VL,AVX512          |
| VDIVPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 5e /r ]          | AVX512VL,AVX512          |
| VDIVPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^er       | [rvm:fv: evex.nds.512.66.0f.w1 5e /r ]          | AVX512                   |
| VDIVPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 5e /r ]             | AVX512VL,AVX512          |
| VDIVPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 5e /r ]             | AVX512VL,AVX512          |
| VDIVPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^er       | [rvm:fv: evex.nds.512.0f.w0 5e /r ]             | AVX512                   |
| VDIVSD            | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.f2.0f.w1 5e /r ]         | AVX512                   |
| VDIVSS            | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.f3.0f.w0 5e /r ]         | AVX512                   |
| VEXP2PD           | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f38.w1 c8 /r ]             | AVX512ER                 |
| VEXP2PS           | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.66.0f38.w0 c8 /r ]             | AVX512ER                 |
| VEXPANDPD         | xmmreg^mask^z,mem128                        | [rm:t1s: evex.128.66.0f38.w1 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPD         | ymmreg^mask^z,mem256                        | [rm:t1s: evex.256.66.0f38.w1 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPD         | zmmreg^mask^z,mem512                        | [rm:t1s: evex.512.66.0f38.w1 88 /r ]            | AVX512                   |
| VEXPANDPD         | xmmreg^mask^z,xmmreg                        | [rm:t1s: evex.128.66.0f38.w1 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPD         | ymmreg^mask^z,ymmreg                        | [rm:t1s: evex.256.66.0f38.w1 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPD         | zmmreg^mask^z,zmmreg                        | [rm:t1s: evex.512.66.0f38.w1 88 /r ]            | AVX512                   |
| VEXPANDPS         | xmmreg^mask^z,mem128                        | [rm:t1s: evex.128.66.0f38.w0 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPS         | ymmreg^mask^z,mem256                        | [rm:t1s: evex.256.66.0f38.w0 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPS         | zmmreg^mask^z,mem512                        | [rm:t1s: evex.512.66.0f38.w0 88 /r ]            | AVX512                   |
| VEXPANDPS         | xmmreg^mask^z,xmmreg                        | [rm:t1s: evex.128.66.0f38.w0 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPS         | ymmreg^mask^z,ymmreg                        | [rm:t1s: evex.256.66.0f38.w0 88 /r ]            | AVX512VL,AVX512          |
| VEXPANDPS         | zmmreg^mask^z,zmmreg                        | [rm:t1s: evex.512.66.0f38.w0 88 /r ]            | AVX512                   |
| VEXTRACTF32X4     | xmmreg^mask^z,ymmreg,imm8                   | [mri: evex.256.66.0f3a.w0 19 /r ib ]            | AVX512VL,AVX512          |
| VEXTRACTF32X4     | xmmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w0 19 /r ib ]            | AVX512                   |
| VEXTRACTF32X4     | mem128^mask,ymmreg,imm8                     | [mri:t4: evex.256.66.0f3a.w0 19 /r ib ]         | AVX512VL,AVX512          |
| VEXTRACTF32X4     | mem128^mask,zmmreg,imm8                     | [mri:t4: evex.512.66.0f3a.w0 19 /r ib ]         | AVX512                   |
| VEXTRACTF32X8     | ymmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w0 1b /r ib ]            | AVX512DQ                 |
| VEXTRACTF32X8     | mem256^mask,zmmreg,imm8                     | [mri:t8: evex.512.66.0f3a.w0 1b /r ib ]         | AVX512DQ                 |
| VEXTRACTF64X2     | xmmreg^mask^z,ymmreg,imm8                   | [mri: evex.256.66.0f3a.w1 19 /r ib ]            | AVX512VL,AVX512DQ        |
| VEXTRACTF64X2     | xmmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w1 19 /r ib ]            | AVX512DQ                 |
| VEXTRACTF64X2     | mem128^mask,ymmreg,imm8                     | [mri:t2: evex.256.66.0f3a.w1 19 /r ib ]         | AVX512VL,AVX512DQ        |
| VEXTRACTF64X2     | mem128^mask,zmmreg,imm8                     | [mri:t2: evex.512.66.0f3a.w1 19 /r ib ]         | AVX512DQ                 |
| VEXTRACTF64X4     | ymmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w1 1b /r ib ]            | AVX512                   |
| VEXTRACTF64X4     | mem256^mask,zmmreg,imm8                     | [mri:t4: evex.512.66.0f3a.w1 1b /r ib ]         | AVX512                   |
| VEXTRACTI32X4     | xmmreg^mask^z,ymmreg,imm8                   | [mri: evex.256.66.0f3a.w0 39 /r ib ]            | AVX512VL,AVX512          |
| VEXTRACTI32X4     | xmmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w0 39 /r ib ]            | AVX512                   |
| VEXTRACTI32X4     | mem128^mask,ymmreg,imm8                     | [mri:t4: evex.256.66.0f3a.w0 39 /r ib ]         | AVX512VL,AVX512          |
| VEXTRACTI32X4     | mem128^mask,zmmreg,imm8                     | [mri:t4: evex.512.66.0f3a.w0 39 /r ib ]         | AVX512                   |
| VEXTRACTI32X8     | ymmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w0 3b /r ib ]            | AVX512DQ                 |
| VEXTRACTI32X8     | mem256^mask,zmmreg,imm8                     | [mri:t8: evex.512.66.0f3a.w0 3b /r ib ]         | AVX512DQ                 |
| VEXTRACTI64X2     | xmmreg^mask^z,ymmreg,imm8                   | [mri: evex.256.66.0f3a.w1 39 /r ib ]            | AVX512VL,AVX512DQ        |
| VEXTRACTI64X2     | xmmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w1 39 /r ib ]            | AVX512DQ                 |
| VEXTRACTI64X2     | mem128^mask,ymmreg,imm8                     | [mri:t2: evex.256.66.0f3a.w1 39 /r ib ]         | AVX512VL,AVX512DQ        |
| VEXTRACTI64X2     | mem128^mask,zmmreg,imm8                     | [mri:t2: evex.512.66.0f3a.w1 39 /r ib ]         | AVX512DQ                 |
| VEXTRACTI64X4     | ymmreg^mask^z,zmmreg,imm8                   | [mri: evex.512.66.0f3a.w1 3b /r ib ]            | AVX512                   |
| VEXTRACTI64X4     | mem256^mask,zmmreg,imm8                     | [mri:t4: evex.512.66.0f3a.w1 3b /r ib ]         | AVX512                   |
| VEXTRACTPS        | reg32,xmmreg,imm8                           | [mri:t1s: evex.128.66.0f3a.wig 17 /r ib ]       | AVX512                   |
| VEXTRACTPS        | reg64,xmmreg,imm8                           | [mri:t1s: evex.128.66.0f3a.wig 17 /r ib ]       | AVX512                   |
| VEXTRACTPS        | mem32,xmmreg,imm8                           | [mri:t1s: evex.128.66.0f3a.wig 17 /r ib ]       | AVX512                   |
| VFIXUPIMMPD       | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w1 54 /r ib ]    | AVX512VL,AVX512          |
| VFIXUPIMMPD       | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 54 /r ib ]    | AVX512VL,AVX512          |
| VFIXUPIMMPD       | zmmreg^mask^z,zmmreg*,zmmrm512^b64^sae,imm8 | [rvmi:fv: evex.nds.512.66.0f3a.w1 54 /r ib ]    | AVX512                   |
| VFIXUPIMMPS       | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w0 54 /r ib ]    | AVX512VL,AVX512          |
| VFIXUPIMMPS       | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w0 54 /r ib ]    | AVX512VL,AVX512          |
| VFIXUPIMMPS       | zmmreg^mask^z,zmmreg*,zmmrm512^b32^sae,imm8 | [rvmi:fv: evex.nds.512.66.0f3a.w0 54 /r ib ]    | AVX512                   |
| VFIXUPIMMSD       | xmmreg^mask^z,xmmreg*,xmmrm64^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w1 55 /r ib ]   | AVX512                   |
| VFIXUPIMMSS       | xmmreg^mask^z,xmmreg*,xmmrm32^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w0 55 /r ib ]   | AVX512                   |
| VFMADD132PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 98 /r ]        | AVX512VL,AVX512          |
| VFMADD132PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 98 /r ]        | AVX512VL,AVX512          |
| VFMADD132PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 98 /r ]        | AVX512                   |
| VFMADD132PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 98 /r ]        | AVX512VL,AVX512          |
| VFMADD132PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 98 /r ]        | AVX512VL,AVX512          |
| VFMADD132PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 98 /r ]        | AVX512                   |
| VFMADD132SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 99 /r ]       | AVX512                   |
| VFMADD132SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 99 /r ]       | AVX512                   |
| VFMADD213PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 a8 /r ]        | AVX512VL,AVX512          |
| VFMADD213PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 a8 /r ]        | AVX512VL,AVX512          |
| VFMADD213PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 a8 /r ]        | AVX512                   |
| VFMADD213PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 a8 /r ]        | AVX512VL,AVX512          |
| VFMADD213PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 a8 /r ]        | AVX512VL,AVX512          |
| VFMADD213PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 a8 /r ]        | AVX512                   |
| VFMADD213SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 a9 /r ]       | AVX512                   |
| VFMADD213SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 a9 /r ]       | AVX512                   |
| VFMADD231PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 b8 /r ]        | AVX512VL,AVX512          |
| VFMADD231PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 b8 /r ]        | AVX512VL,AVX512          |
| VFMADD231PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 b8 /r ]        | AVX512                   |
| VFMADD231PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 b8 /r ]        | AVX512VL,AVX512          |
| VFMADD231PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 b8 /r ]        | AVX512VL,AVX512          |
| VFMADD231PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 b8 /r ]        | AVX512                   |
| VFMADD231SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 b9 /r ]       | AVX512                   |
| VFMADD231SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 b9 /r ]       | AVX512                   |
| VFMADDSUB132PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 96 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB132PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 96 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB132PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 96 /r ]        | AVX512                   |
| VFMADDSUB132PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 96 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB132PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 96 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB132PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 96 /r ]        | AVX512                   |
| VFMADDSUB213PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 a6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB213PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 a6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB213PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 a6 /r ]        | AVX512                   |
| VFMADDSUB213PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 a6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB213PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 a6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB213PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 a6 /r ]        | AVX512                   |
| VFMADDSUB231PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 b6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB231PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 b6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB231PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 b6 /r ]        | AVX512                   |
| VFMADDSUB231PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 b6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB231PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 b6 /r ]        | AVX512VL,AVX512          |
| VFMADDSUB231PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 b6 /r ]        | AVX512                   |
| VFMSUB132PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 9a /r ]        | AVX512VL,AVX512          |
| VFMSUB132PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 9a /r ]        | AVX512VL,AVX512          |
| VFMSUB132PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 9a /r ]        | AVX512                   |
| VFMSUB132PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 9a /r ]        | AVX512VL,AVX512          |
| VFMSUB132PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 9a /r ]        | AVX512VL,AVX512          |
| VFMSUB132PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 9a /r ]        | AVX512                   |
| VFMSUB132SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 9b /r ]       | AVX512                   |
| VFMSUB132SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 9b /r ]       | AVX512                   |
| VFMSUB213PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 aa /r ]        | AVX512VL,AVX512          |
| VFMSUB213PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 aa /r ]        | AVX512VL,AVX512          |
| VFMSUB213PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 aa /r ]        | AVX512                   |
| VFMSUB213PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 aa /r ]        | AVX512VL,AVX512          |
| VFMSUB213PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 aa /r ]        | AVX512VL,AVX512          |
| VFMSUB213PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 aa /r ]        | AVX512                   |
| VFMSUB213SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 ab /r ]       | AVX512                   |
| VFMSUB213SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 ab /r ]       | AVX512                   |
| VFMSUB231PD       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 ba /r ]        | AVX512VL,AVX512          |
| VFMSUB231PD       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 ba /r ]        | AVX512VL,AVX512          |
| VFMSUB231PD       | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 ba /r ]        | AVX512                   |
| VFMSUB231PS       | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 ba /r ]        | AVX512VL,AVX512          |
| VFMSUB231PS       | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 ba /r ]        | AVX512VL,AVX512          |
| VFMSUB231PS       | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 ba /r ]        | AVX512                   |
| VFMSUB231SD       | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 bb /r ]       | AVX512                   |
| VFMSUB231SS       | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 bb /r ]       | AVX512                   |
| VFMSUBADD132PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 97 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD132PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 97 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD132PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 97 /r ]        | AVX512                   |
| VFMSUBADD132PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 97 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD132PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 97 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD132PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 97 /r ]        | AVX512                   |
| VFMSUBADD213PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 a7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD213PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 a7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD213PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 a7 /r ]        | AVX512                   |
| VFMSUBADD213PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 a7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD213PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 a7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD213PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 a7 /r ]        | AVX512                   |
| VFMSUBADD231PD    | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 b7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD231PD    | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 b7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD231PD    | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 b7 /r ]        | AVX512                   |
| VFMSUBADD231PS    | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 b7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD231PS    | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 b7 /r ]        | AVX512VL,AVX512          |
| VFMSUBADD231PS    | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 b7 /r ]        | AVX512                   |
| VFNMADD132PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 9c /r ]        | AVX512VL,AVX512          |
| VFNMADD132PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 9c /r ]        | AVX512VL,AVX512          |
| VFNMADD132PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 9c /r ]        | AVX512                   |
| VFNMADD132PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 9c /r ]        | AVX512VL,AVX512          |
| VFNMADD132PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 9c /r ]        | AVX512VL,AVX512          |
| VFNMADD132PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 9c /r ]        | AVX512                   |
| VFNMADD132SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 9d /r ]       | AVX512                   |
| VFNMADD132SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 9d /r ]       | AVX512                   |
| VFNMADD213PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 ac /r ]        | AVX512VL,AVX512          |
| VFNMADD213PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 ac /r ]        | AVX512VL,AVX512          |
| VFNMADD213PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 ac /r ]        | AVX512                   |
| VFNMADD213PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 ac /r ]        | AVX512VL,AVX512          |
| VFNMADD213PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 ac /r ]        | AVX512VL,AVX512          |
| VFNMADD213PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 ac /r ]        | AVX512                   |
| VFNMADD213SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 ad /r ]       | AVX512                   |
| VFNMADD213SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 ad /r ]       | AVX512                   |
| VFNMADD231PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 bc /r ]        | AVX512VL,AVX512          |
| VFNMADD231PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 bc /r ]        | AVX512VL,AVX512          |
| VFNMADD231PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 bc /r ]        | AVX512                   |
| VFNMADD231PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 bc /r ]        | AVX512VL,AVX512          |
| VFNMADD231PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 bc /r ]        | AVX512VL,AVX512          |
| VFNMADD231PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 bc /r ]        | AVX512                   |
| VFNMADD231SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 bd /r ]       | AVX512                   |
| VFNMADD231SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 bd /r ]       | AVX512                   |
| VFNMSUB132PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 9e /r ]        | AVX512VL,AVX512          |
| VFNMSUB132PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 9e /r ]        | AVX512VL,AVX512          |
| VFNMSUB132PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 9e /r ]        | AVX512                   |
| VFNMSUB132PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 9e /r ]        | AVX512VL,AVX512          |
| VFNMSUB132PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 9e /r ]        | AVX512VL,AVX512          |
| VFNMSUB132PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 9e /r ]        | AVX512                   |
| VFNMSUB132SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 9f /r ]       | AVX512                   |
| VFNMSUB132SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 9f /r ]       | AVX512                   |
| VFNMSUB213PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 ae /r ]        | AVX512VL,AVX512          |
| VFNMSUB213PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 ae /r ]        | AVX512VL,AVX512          |
| VFNMSUB213PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 ae /r ]        | AVX512                   |
| VFNMSUB213PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 ae /r ]        | AVX512VL,AVX512          |
| VFNMSUB213PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 ae /r ]        | AVX512VL,AVX512          |
| VFNMSUB213PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 ae /r ]        | AVX512                   |
| VFNMSUB213SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 af /r ]       | AVX512                   |
| VFNMSUB213SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 af /r ]       | AVX512                   |
| VFNMSUB231PD      | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 be /r ]        | AVX512VL,AVX512          |
| VFNMSUB231PD      | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 be /r ]        | AVX512VL,AVX512          |
| VFNMSUB231PD      | zmmreg^mask^z,zmmreg,zmmrm512^b64^er        | [rvm:fv: evex.nds.512.66.0f38.w1 be /r ]        | AVX512                   |
| VFNMSUB231PS      | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 be /r ]        | AVX512VL,AVX512          |
| VFNMSUB231PS      | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 be /r ]        | AVX512VL,AVX512          |
| VFNMSUB231PS      | zmmreg^mask^z,zmmreg,zmmrm512^b32^er        | [rvm:fv: evex.nds.512.66.0f38.w0 be /r ]        | AVX512                   |
| VFNMSUB231SD      | xmmreg^mask^z,xmmreg,xmmrm64^er             | [rvm:t1s: evex.nds.128.66.0f38.w1 bf /r ]       | AVX512                   |
| VFNMSUB231SS      | xmmreg^mask^z,xmmreg,xmmrm32^er             | [rvm:t1s: evex.nds.128.66.0f38.w0 bf /r ]       | AVX512                   |
| VFPCLASSPD        | kreg^mask,xmmrm128^b64,imm8                 | [rmi:fv: evex.128.66.0f3a.w1 66 /r ib ]         | AVX512VL,AVX512DQ        |
| VFPCLASSPD        | kreg^mask,ymmrm256^b64,imm8                 | [rmi:fv: evex.256.66.0f3a.w1 66 /r ib ]         | AVX512VL,AVX512DQ        |
| VFPCLASSPD        | kreg^mask,zmmrm512^b64,imm8                 | [rmi:fv: evex.512.66.0f3a.w1 66 /r ib ]         | AVX512DQ                 |
| VFPCLASSPS        | kreg^mask,xmmrm128^b32,imm8                 | [rmi:fv: evex.128.66.0f3a.w0 66 /r ib ]         | AVX512VL,AVX512DQ        |
| VFPCLASSPS        | kreg^mask,ymmrm256^b32,imm8                 | [rmi:fv: evex.256.66.0f3a.w0 66 /r ib ]         | AVX512VL,AVX512DQ        |
| VFPCLASSPS        | kreg^mask,zmmrm512^b32,imm8                 | [rmi:fv: evex.512.66.0f3a.w0 66 /r ib ]         | AVX512DQ                 |
| VFPCLASSSD        | kreg^mask,xmmrm64,imm8                      | [rmi:t1s: evex.128.66.0f3a.w1 67 /r ib ]        | AVX512DQ                 |
| VFPCLASSSS        | kreg^mask,xmmrm32,imm8                      | [rmi:t1s: evex.128.66.0f3a.w0 67 /r ib ]        | AVX512DQ                 |
| VGATHERDPD        | xmmreg^mask,xmem64                          | [rm:t1s: vsibx evex.128.66.0f38.w1 92 /r ]      | AVX512VL,AVX512          |
| VGATHERDPD        | ymmreg^mask,xmem64                          | [rm:t1s: vsibx evex.256.66.0f38.w1 92 /r ]      | AVX512VL,AVX512          |
| VGATHERDPD        | zmmreg^mask,ymem64                          | [rm:t1s: vsiby evex.512.66.0f38.w1 92 /r ]      | AVX512                   |
| VGATHERDPS        | xmmreg^mask,xmem32                          | [rm:t1s: vsibx evex.128.66.0f38.w0 92 /r ]      | AVX512VL,AVX512          |
| VGATHERDPS        | ymmreg^mask,ymem32                          | [rm:t1s: vsiby evex.256.66.0f38.w0 92 /r ]      | AVX512VL,AVX512          |
| VGATHERDPS        | zmmreg^mask,zmem32                          | [rm:t1s: vsibz evex.512.66.0f38.w0 92 /r ]      | AVX512                   |
| VGATHERPF0DPD     | ymem64^mask                                 | [m:t1s: vsiby evex.512.66.0f38.w1 c6 /1 ]       | AVX512PF                 |
| VGATHERPF0DPS     | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c6 /1 ]       | AVX512PF                 |
| VGATHERPF0QPD     | zmem64^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w1 c7 /1 ]       | AVX512PF                 |
| VGATHERPF0QPS     | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c7 /1 ]       | AVX512PF                 |
| VGATHERPF1DPD     | ymem64^mask                                 | [m:t1s: vsiby evex.512.66.0f38.w1 c6 /2 ]       | AVX512PF                 |
| VGATHERPF1DPS     | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c6 /2 ]       | AVX512PF                 |
| VGATHERPF1QPD     | zmem64^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w1 c7 /2 ]       | AVX512PF                 |
| VGATHERPF1QPS     | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c7 /2 ]       | AVX512PF                 |
| VGATHERQPD        | xmmreg^mask,xmem64                          | [rm:t1s: vsibx evex.128.66.0f38.w1 93 /r ]      | AVX512VL,AVX512          |
| VGATHERQPD        | ymmreg^mask,ymem64                          | [rm:t1s: vsiby evex.256.66.0f38.w1 93 /r ]      | AVX512VL,AVX512          |
| VGATHERQPD        | zmmreg^mask,zmem64                          | [rm:t1s: vsibz evex.512.66.0f38.w1 93 /r ]      | AVX512                   |
| VGATHERQPS        | xmmreg^mask,xmem32                          | [rm:t1s: vsibx evex.128.66.0f38.w0 93 /r ]      | AVX512VL,AVX512          |
| VGATHERQPS        | xmmreg^mask,ymem32                          | [rm:t1s: vsiby evex.256.66.0f38.w0 93 /r ]      | AVX512VL,AVX512          |
| VGATHERQPS        | ymmreg^mask,zmem32                          | [rm:t1s: vsibz evex.512.66.0f38.w0 93 /r ]      | AVX512                   |
| VGETEXPPD         | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 42 /r ]             | AVX512VL,AVX512          |
| VGETEXPPD         | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 42 /r ]             | AVX512VL,AVX512          |
| VGETEXPPD         | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f38.w1 42 /r ]             | AVX512                   |
| VGETEXPPS         | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 42 /r ]             | AVX512VL,AVX512          |
| VGETEXPPS         | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 42 /r ]             | AVX512VL,AVX512          |
| VGETEXPPS         | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.66.0f38.w0 42 /r ]             | AVX512                   |
| VGETEXPSD         | xmmreg^mask^z,xmmreg,xmmrm64^sae            | [rvm:t1s: evex.nds.128.66.0f38.w1 43 /r ]       | AVX512                   |
| VGETEXPSS         | xmmreg^mask^z,xmmreg,xmmrm32^sae            | [rvm:t1s: evex.nds.128.66.0f38.w0 43 /r ]       | AVX512                   |
| VGETMANTPD        | xmmreg^mask^z,xmmrm128^b64,imm8             | [rmi:fv: evex.128.66.0f3a.w1 26 /r ib ]         | AVX512VL,AVX512          |
| VGETMANTPD        | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 26 /r ib ]         | AVX512VL,AVX512          |
| VGETMANTPD        | zmmreg^mask^z,zmmrm512^b64^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w1 26 /r ib ]         | AVX512                   |
| VGETMANTPS        | xmmreg^mask^z,xmmrm128^b32,imm8             | [rmi:fv: evex.128.66.0f3a.w0 26 /r ib ]         | AVX512VL,AVX512          |
| VGETMANTPS        | ymmreg^mask^z,ymmrm256^b32,imm8             | [rmi:fv: evex.256.66.0f3a.w0 26 /r ib ]         | AVX512VL,AVX512          |
| VGETMANTPS        | zmmreg^mask^z,zmmrm512^b32^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w0 26 /r ib ]         | AVX512                   |
| VGETMANTSD        | xmmreg^mask^z,xmmreg,xmmrm64^sae,imm8       | [rvmi:t1s: evex.nds.128.66.0f3a.w1 27 /r ib ]   | AVX512                   |
| VGETMANTSS        | xmmreg^mask^z,xmmreg,xmmrm32^sae,imm8       | [rvmi:t1s: evex.nds.128.66.0f3a.w0 27 /r ib ]   | AVX512                   |
| VINSERTF32X4      | ymmreg^mask^z,ymmreg*,xmmrm128,imm8         | [rvmi:t4: evex.nds.256.66.0f3a.w0 18 /r ib ]    | AVX512VL,AVX512          |
| VINSERTF32X4      | zmmreg^mask^z,zmmreg*,xmmrm128,imm8         | [rvmi:t4: evex.nds.512.66.0f3a.w0 18 /r ib ]    | AVX512                   |
| VINSERTF32X8      | zmmreg^mask^z,zmmreg*,ymmrm256,imm8         | [rvmi:t8: evex.nds.512.66.0f3a.w0 1a /r ib ]    | AVX512DQ                 |
| VINSERTF64X2      | ymmreg^mask^z,ymmreg*,xmmrm128,imm8         | [rvmi:t2: evex.nds.256.66.0f3a.w1 18 /r ib ]    | AVX512VL,AVX512DQ        |
| VINSERTF64X2      | zmmreg^mask^z,zmmreg*,xmmrm128,imm8         | [rvmi:t2: evex.nds.512.66.0f3a.w1 18 /r ib ]    | AVX512DQ                 |
| VINSERTF64X4      | zmmreg^mask^z,zmmreg*,ymmrm256,imm8         | [rvmi:t4: evex.nds.512.66.0f3a.w1 1a /r ib ]    | AVX512                   |
| VINSERTI32X4      | ymmreg^mask^z,ymmreg*,xmmrm128,imm8         | [rvmi:t4: evex.nds.256.66.0f3a.w0 38 /r ib ]    | AVX512VL,AVX512          |
| VINSERTI32X4      | zmmreg^mask^z,zmmreg*,xmmrm128,imm8         | [rvmi:t4: evex.nds.512.66.0f3a.w0 38 /r ib ]    | AVX512                   |
| VINSERTI32X8      | zmmreg^mask^z,zmmreg*,ymmrm256,imm8         | [rvmi:t8: evex.nds.512.66.0f3a.w0 3a /r ib ]    | AVX512DQ                 |
| VINSERTI64X2      | ymmreg^mask^z,ymmreg*,xmmrm128,imm8         | [rvmi:t2: evex.nds.256.66.0f3a.w1 38 /r ib ]    | AVX512VL,AVX512DQ        |
| VINSERTI64X2      | zmmreg^mask^z,zmmreg*,xmmrm128,imm8         | [rvmi:t2: evex.nds.512.66.0f3a.w1 38 /r ib ]    | AVX512DQ                 |
| VINSERTI64X4      | zmmreg^mask^z,zmmreg*,ymmrm256,imm8         | [rvmi:t4: evex.nds.512.66.0f3a.w1 3a /r ib ]    | AVX512                   |
| VINSERTPS         | xmmreg,xmmreg*,xmmrm32,imm8                 | [rvmi:t1s: evex.nds.128.66.0f3a.w0 21 /r ib ]   | AVX512                   |
| VMAXPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 5f /r ]          | AVX512VL,AVX512          |
| VMAXPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 5f /r ]          | AVX512VL,AVX512          |
| VMAXPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^sae      | [rvm:fv: evex.nds.512.66.0f.w1 5f /r ]          | AVX512                   |
| VMAXPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 5f /r ]             | AVX512VL,AVX512          |
| VMAXPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 5f /r ]             | AVX512VL,AVX512          |
| VMAXPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^sae      | [rvm:fv: evex.nds.512.0f.w0 5f /r ]             | AVX512                   |
| VMAXSD            | xmmreg^mask^z,xmmreg*,xmmrm64^sae           | [rvm:t1s: evex.nds.128.f2.0f.w1 5f /r ]         | AVX512                   |
| VMAXSS            | xmmreg^mask^z,xmmreg*,xmmrm32^sae           | [rvm:t1s: evex.nds.128.f3.0f.w0 5f /r ]         | AVX512                   |
| VMINPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 5d /r ]          | AVX512VL,AVX512          |
| VMINPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 5d /r ]          | AVX512VL,AVX512          |
| VMINPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^sae      | [rvm:fv: evex.nds.512.66.0f.w1 5d /r ]          | AVX512                   |
| VMINPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 5d /r ]             | AVX512VL,AVX512          |
| VMINPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 5d /r ]             | AVX512VL,AVX512          |
| VMINPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^sae      | [rvm:fv: evex.nds.512.0f.w0 5d /r ]             | AVX512                   |
| VMINSD            | xmmreg^mask^z,xmmreg*,xmmrm64^sae           | [rvm:t1s: evex.nds.128.f2.0f.w1 5d /r ]         | AVX512                   |
| VMINSS            | xmmreg^mask^z,xmmreg*,xmmrm32^sae           | [rvm:t1s: evex.nds.128.f3.0f.w0 5d /r ]         | AVX512                   |
| VMOVAPD           | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f.w1 28 /r ]              | AVX512VL,AVX512          |
| VMOVAPD           | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f.w1 28 /r ]              | AVX512VL,AVX512          |
| VMOVAPD           | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f.w1 28 /r ]              | AVX512                   |
| VMOVAPD           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f.w1 29 /r ]                  | AVX512VL,AVX512          |
| VMOVAPD           | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f.w1 29 /r ]                  | AVX512VL,AVX512          |
| VMOVAPD           | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f.w1 29 /r ]                  | AVX512                   |
| VMOVAPD           | mem128^mask,xmmreg                          | [mr:fvm: evex.128.66.0f.w1 29 /r ]              | AVX512VL,AVX512          |
| VMOVAPD           | mem256^mask,ymmreg                          | [mr:fvm: evex.256.66.0f.w1 29 /r ]              | AVX512VL,AVX512          |
| VMOVAPD           | zmem512^mask,zmmreg                         | [mr:fvm: evex.512.66.0f.w1 29 /r ]              | AVX512                   |
| VMOVAPS           | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.0f.w0 28 /r ]                 | AVX512VL,AVX512          |
| VMOVAPS           | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.0f.w0 28 /r ]                 | AVX512VL,AVX512          |
| VMOVAPS           | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.0f.w0 28 /r ]                 | AVX512                   |
| VMOVAPS           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.0f.w0 29 /r ]                     | AVX512VL,AVX512          |
| VMOVAPS           | ymmreg^mask^z,ymmreg                        | [mr: evex.256.0f.w0 29 /r ]                     | AVX512VL,AVX512          |
| VMOVAPS           | zmmreg^mask^z,zmmreg                        | [mr: evex.512.0f.w0 29 /r ]                     | AVX512                   |
| VMOVAPS           | mem128^mask,xmmreg                          | [mr:fvm: evex.128.0f.w0 29 /r ]                 | AVX512VL,AVX512          |
| VMOVAPS           | mem256^mask,ymmreg                          | [mr:fvm: evex.256.0f.w0 29 /r ]                 | AVX512VL,AVX512          |
| VMOVAPS           | zmem512^mask,zmmreg                         | [mr:fvm: evex.512.0f.w0 29 /r ]                 | AVX512                   |
| VMOVD             | xmmreg,rm32                                 | [rm:t1s: evex.128.66.0f.w0 6e /r ]              | AVX512                   |
| VMOVD             | rm32,xmmreg                                 | [mr:t1s: evex.128.66.0f.w0 7e /r ]              | AVX512                   |
| VMOVDDUP          | xmmreg^mask^z,xmmrm64                       | [rm:dup: evex.128.f2.0f.w1 12 /r ]              | AVX512VL,AVX512          |
| VMOVDDUP          | ymmreg^mask^z,ymmrm256                      | [rm:dup: evex.256.f2.0f.w1 12 /r ]              | AVX512VL,AVX512          |
| VMOVDDUP          | zmmreg^mask^z,zmmrm512                      | [rm:dup: evex.512.f2.0f.w1 12 /r ]              | AVX512                   |
| VMOVDQA32         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f.w0 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQA32         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f.w0 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQA32         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f.w0 6f /r ]              | AVX512                   |
| VMOVDQA32         | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.66.0f.w0 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQA32         | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.66.0f.w0 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQA32         | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.66.0f.w0 7f /r ]              | AVX512                   |
| VMOVDQA64         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f.w1 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQA64         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f.w1 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQA64         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f.w1 6f /r ]              | AVX512                   |
| VMOVDQA64         | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.66.0f.w1 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQA64         | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.66.0f.w1 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQA64         | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.66.0f.w1 7f /r ]              | AVX512                   |
| VMOVDQU16         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f2.0f.w1 6f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU16         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f2.0f.w1 6f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU16         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f2.0f.w1 6f /r ]              | AVX512BW                 |
| VMOVDQU16         | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.f2.0f.w1 7f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU16         | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.f2.0f.w1 7f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU16         | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.f2.0f.w1 7f /r ]              | AVX512BW                 |
| VMOVDQU32         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f3.0f.w0 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQU32         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f3.0f.w0 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQU32         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f3.0f.w0 6f /r ]              | AVX512                   |
| VMOVDQU32         | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.f3.0f.w0 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQU32         | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.f3.0f.w0 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQU32         | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.f3.0f.w0 7f /r ]              | AVX512                   |
| VMOVDQU64         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f3.0f.w1 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQU64         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f3.0f.w1 6f /r ]              | AVX512VL,AVX512          |
| VMOVDQU64         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f3.0f.w1 6f /r ]              | AVX512                   |
| VMOVDQU64         | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.f3.0f.w1 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQU64         | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.f3.0f.w1 7f /r ]              | AVX512VL,AVX512          |
| VMOVDQU64         | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.f3.0f.w1 7f /r ]              | AVX512                   |
| VMOVDQU8          | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f2.0f.w0 6f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU8          | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f2.0f.w0 6f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU8          | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f2.0f.w0 6f /r ]              | AVX512BW                 |
| VMOVDQU8          | xmmrm128^mask^z,xmmreg                      | [mr:fvm: evex.128.f2.0f.w0 7f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU8          | ymmrm256^mask^z,ymmreg                      | [mr:fvm: evex.256.f2.0f.w0 7f /r ]              | AVX512VL,AVX512BW        |
| VMOVDQU8          | ymmrm512^mask^z,zmmreg                      | [mr:fvm: evex.512.f2.0f.w0 7f /r ]              | AVX512BW                 |
| VMOVHLPS          | xmmreg,xmmreg*,xmmreg                       | [rvm: evex.nds.128.0f.w0 12 /r ]                | AVX512                   |
| VMOVHPD           | xmmreg,xmmreg*,mem64                        | [rvm:t1s: evex.nds.128.66.0f.w1 16 /r ]         | AVX512                   |
| VMOVHPD           | mem64,xmmreg                                | [mr:t1s: evex.128.66.0f.w1 17 /r ]              | AVX512                   |
| VMOVHPS           | xmmreg,xmmreg*,mem64                        | [rvm:t2: evex.nds.128.0f.w0 16 /r ]             | AVX512                   |
| VMOVHPS           | mem64,xmmreg                                | [mr:t2: evex.128.0f.w0 17 /r ]                  | AVX512                   |
| VMOVLHPS          | xmmreg,xmmreg*,xmmreg                       | [rvm: evex.nds.128.0f.w0 16 /r ]                | AVX512                   |
| VMOVLPD           | xmmreg,xmmreg*,mem64                        | [rvm:t1s: evex.nds.128.66.0f.w1 12 /r ]         | AVX512                   |
| VMOVLPD           | mem64,xmmreg                                | [mr:t1s: evex.128.66.0f.w1 13 /r ]              | AVX512                   |
| VMOVLPS           | xmmreg,xmmreg*,mem64                        | [rvm:t2: evex.nds.128.0f.w0 12 /r ]             | AVX512                   |
| VMOVLPS           | mem64,xmmreg                                | [mr:t2: evex.128.0f.w0 13 /r ]                  | AVX512                   |
| VMOVNTDQ          | mem128,xmmreg                               | [mr:fvm: evex.128.66.0f.w0 e7 /r ]              | AVX512VL,AVX512          |
| VMOVNTDQ          | mem256,ymmreg                               | [mr:fvm: evex.256.66.0f.w0 e7 /r ]              | AVX512VL,AVX512          |
| VMOVNTDQ          | mem512,zmmreg                               | [mr:fvm: evex.512.66.0f.w0 e7 /r ]              | AVX512                   |
| VMOVNTDQA         | xmmreg,mem128                               | [rm:fvm: evex.128.66.0f38.w0 2a /r ]            | AVX512VL,AVX512          |
| VMOVNTDQA         | ymmreg,mem256                               | [rm:fvm: evex.256.66.0f38.w0 2a /r ]            | AVX512VL,AVX512          |
| VMOVNTDQA         | zmmreg,mem512                               | [rm:fvm: evex.512.66.0f38.w0 2a /r ]            | AVX512                   |
| VMOVNTPD          | mem128,xmmreg                               | [mr:fvm: evex.128.66.0f.w1 2b /r ]              | AVX512VL,AVX512          |
| VMOVNTPD          | mem256,ymmreg                               | [mr:fvm: evex.256.66.0f.w1 2b /r ]              | AVX512VL,AVX512          |
| VMOVNTPD          | mem512,zmmreg                               | [mr:fvm: evex.512.66.0f.w1 2b /r ]              | AVX512                   |
| VMOVNTPS          | mem128,xmmreg                               | [mr:fvm: evex.128.0f.w0 2b /r ]                 | AVX512VL,AVX512          |
| VMOVNTPS          | mem256,ymmreg                               | [mr:fvm: evex.256.0f.w0 2b /r ]                 | AVX512VL,AVX512          |
| VMOVNTPS          | mem512,zmmreg                               | [mr:fvm: evex.512.0f.w0 2b /r ]                 | AVX512                   |
| VMOVQ             | xmmreg,rm64                                 | [rm:t1s: evex.128.66.0f.w1 6e /r ]              | AVX512                   |
| VMOVQ             | rm64,xmmreg                                 | [mr:t1s: evex.128.66.0f.w1 7e /r ]              | AVX512                   |
| VMOVQ             | xmmreg,xmmrm64                              | [rm:t1s: evex.128.f3.0f.w1 7e /r ]              | AVX512                   |
| VMOVQ             | xmmrm64,xmmreg                              | [mr:t1s: evex.128.66.0f.w1 d6 /r ]              | AVX512                   |
| VMOVSD            | xmmreg^mask^z,mem64                         | [rm:t1s: evex.128.f2.0f.w1 10 /r ]              | AVX512                   |
| VMOVSD            | mem64^mask,xmmreg                           | [mr:t1s: evex.128.f2.0f.w1 11 /r ]              | AVX512                   |
| VMOVSD            | xmmreg^mask^z,xmmreg*,xmmreg                | [rvm: evex.nds.128.f2.0f.w1 10 /r ]             | AVX512                   |
| VMOVSD            | xmmreg^mask^z,xmmreg*,xmmreg                | [mvr: evex.nds.128.f2.0f.w1 11 /r ]             | AVX512                   |
| VMOVSHDUP         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f3.0f.w0 16 /r ]              | AVX512VL,AVX512          |
| VMOVSHDUP         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f3.0f.w0 16 /r ]              | AVX512VL,AVX512          |
| VMOVSHDUP         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f3.0f.w0 16 /r ]              | AVX512                   |
| VMOVSLDUP         | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.f3.0f.w0 12 /r ]              | AVX512VL,AVX512          |
| VMOVSLDUP         | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.f3.0f.w0 12 /r ]              | AVX512VL,AVX512          |
| VMOVSLDUP         | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.f3.0f.w0 12 /r ]              | AVX512                   |
| VMOVSS            | xmmreg^mask^z,mem32                         | [rm:t1s: evex.128.f3.0f.w0 10 /r ]              | AVX512                   |
| VMOVSS            | mem32^mask,xmmreg                           | [mr:t1s: evex.128.f3.0f.w0 11 /r ]              | AVX512                   |
| VMOVSS            | xmmreg^mask^z,xmmreg*,xmmreg                | [rvm: evex.nds.128.f3.0f.w0 10 /r ]             | AVX512                   |
| VMOVSS            | xmmreg^mask^z,xmmreg*,xmmreg                | [mvr: evex.nds.128.f3.0f.w0 11 /r ]             | AVX512                   |
| VMOVUPD           | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f.w1 10 /r ]              | AVX512VL,AVX512          |
| VMOVUPD           | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f.w1 10 /r ]              | AVX512VL,AVX512          |
| VMOVUPD           | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f.w1 10 /r ]              | AVX512                   |
| VMOVUPD           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f.w1 11 /r ]                  | AVX512VL,AVX512          |
| VMOVUPD           | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f.w1 11 /r ]                  | AVX512VL,AVX512          |
| VMOVUPD           | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f.w1 11 /r ]                  | AVX512                   |
| VMOVUPD           | mem128^mask,xmmreg                          | [mr:fvm: evex.128.66.0f.w1 11 /r ]              | AVX512VL,AVX512          |
| VMOVUPD           | mem256^mask,ymmreg                          | [mr:fvm: evex.256.66.0f.w1 11 /r ]              | AVX512VL,AVX512          |
| VMOVUPD           | zmem512^mask,zmmreg                         | [mr:fvm: evex.512.66.0f.w1 11 /r ]              | AVX512                   |
| VMOVUPS           | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.0f.w0 10 /r ]                 | AVX512VL,AVX512          |
| VMOVUPS           | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.0f.w0 10 /r ]                 | AVX512VL,AVX512          |
| VMOVUPS           | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.0f.w0 10 /r ]                 | AVX512                   |
| VMOVUPS           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.0f.w0 11 /r ]                     | AVX512VL,AVX512          |
| VMOVUPS           | ymmreg^mask^z,ymmreg                        | [mr: evex.256.0f.w0 11 /r ]                     | AVX512VL,AVX512          |
| VMOVUPS           | zmmreg^mask^z,zmmreg                        | [mr: evex.512.0f.w0 11 /r ]                     | AVX512                   |
| VMOVUPS           | mem128^mask,xmmreg                          | [mr:fvm: evex.128.0f.w0 11 /r ]                 | AVX512VL,AVX512          |
| VMOVUPS           | mem256^mask,ymmreg                          | [mr:fvm: evex.256.0f.w0 11 /r ]                 | AVX512VL,AVX512          |
| VMOVUPS           | zmem512^mask,zmmreg                         | [mr:fvm: evex.512.0f.w0 11 /r ]                 | AVX512                   |
| VMULPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 59 /r ]          | AVX512VL,AVX512          |
| VMULPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 59 /r ]          | AVX512VL,AVX512          |
| VMULPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^er       | [rvm:fv: evex.nds.512.66.0f.w1 59 /r ]          | AVX512                   |
| VMULPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 59 /r ]             | AVX512VL,AVX512          |
| VMULPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 59 /r ]             | AVX512VL,AVX512          |
| VMULPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^er       | [rvm:fv: evex.nds.512.0f.w0 59 /r ]             | AVX512                   |
| VMULSD            | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.f2.0f.w1 59 /r ]         | AVX512                   |
| VMULSS            | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.f3.0f.w0 59 /r ]         | AVX512                   |
| VORPD             | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 56 /r ]          | AVX512VL,AVX512DQ        |
| VORPD             | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 56 /r ]          | AVX512VL,AVX512DQ        |
| VORPD             | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 56 /r ]          | AVX512DQ                 |
| VORPS             | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 56 /r ]             | AVX512VL,AVX512DQ        |
| VORPS             | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 56 /r ]             | AVX512VL,AVX512DQ        |
| VORPS             | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 56 /r ]             | AVX512DQ                 |
| VPABSB            | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f38.wig 1c /r ]           | AVX512VL,AVX512BW        |
| VPABSB            | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f38.wig 1c /r ]           | AVX512VL,AVX512BW        |
| VPABSB            | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f38.wig 1c /r ]           | AVX512BW                 |
| VPABSD            | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 1e /r ]             | AVX512VL,AVX512          |
| VPABSD            | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 1e /r ]             | AVX512VL,AVX512          |
| VPABSD            | zmmreg^mask^z,zmmrm512^b32                  | [rm:fv: evex.512.66.0f38.w0 1e /r ]             | AVX512                   |
| VPABSQ            | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 1f /r ]             | AVX512VL,AVX512          |
| VPABSQ            | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 1f /r ]             | AVX512VL,AVX512          |
| VPABSQ            | zmmreg^mask^z,zmmrm512^b64                  | [rm:fv: evex.512.66.0f38.w1 1f /r ]             | AVX512                   |
| VPABSW            | xmmreg^mask^z,xmmrm128                      | [rm:fvm: evex.128.66.0f38.wig 1d /r ]           | AVX512VL,AVX512BW        |
| VPABSW            | ymmreg^mask^z,ymmrm256                      | [rm:fvm: evex.256.66.0f38.wig 1d /r ]           | AVX512VL,AVX512BW        |
| VPABSW            | zmmreg^mask^z,zmmrm512                      | [rm:fvm: evex.512.66.0f38.wig 1d /r ]           | AVX512BW                 |
| VPACKSSDW         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 6b /r ]          | AVX512VL,AVX512BW        |
| VPACKSSDW         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 6b /r ]          | AVX512VL,AVX512BW        |
| VPACKSSDW         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 6b /r ]          | AVX512BW                 |
| VPACKSSWB         | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 63 /r ]        | AVX512VL,AVX512BW        |
| VPACKSSWB         | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 63 /r ]        | AVX512VL,AVX512BW        |
| VPACKSSWB         | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 63 /r ]        | AVX512BW                 |
| VPACKUSDW         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 2b /r ]        | AVX512VL,AVX512BW        |
| VPACKUSDW         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 2b /r ]        | AVX512VL,AVX512BW        |
| VPACKUSDW         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 2b /r ]        | AVX512BW                 |
| VPACKUSWB         | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 67 /r ]        | AVX512VL,AVX512BW        |
| VPACKUSWB         | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 67 /r ]        | AVX512VL,AVX512BW        |
| VPACKUSWB         | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 67 /r ]        | AVX512BW                 |
| VPADDB            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig fc /r ]        | AVX512VL,AVX512BW        |
| VPADDB            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig fc /r ]        | AVX512VL,AVX512BW        |
| VPADDB            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig fc /r ]        | AVX512BW                 |
| VPADDD            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 fe /r ]          | AVX512VL,AVX512          |
| VPADDD            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 fe /r ]          | AVX512VL,AVX512          |
| VPADDD            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 fe /r ]          | AVX512                   |
| VPADDQ            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 d4 /r ]          | AVX512VL,AVX512          |
| VPADDQ            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 d4 /r ]          | AVX512VL,AVX512          |
| VPADDQ            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 d4 /r ]          | AVX512                   |
| VPADDSB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig ec /r ]        | AVX512VL,AVX512BW        |
| VPADDSB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig ec /r ]        | AVX512VL,AVX512BW        |
| VPADDSB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig ec /r ]        | AVX512BW                 |
| VPADDSW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig ed /r ]        | AVX512VL,AVX512BW        |
| VPADDSW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig ed /r ]        | AVX512VL,AVX512BW        |
| VPADDSW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig ed /r ]        | AVX512BW                 |
| VPADDUSB          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig dc /r ]        | AVX512VL,AVX512BW        |
| VPADDUSB          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig dc /r ]        | AVX512VL,AVX512BW        |
| VPADDUSB          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig dc /r ]        | AVX512BW                 |
| VPADDUSW          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig dd /r ]        | AVX512VL,AVX512BW        |
| VPADDUSW          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig dd /r ]        | AVX512VL,AVX512BW        |
| VPADDUSW          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig dd /r ]        | AVX512BW                 |
| VPADDW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig fd /r ]        | AVX512VL,AVX512BW        |
| VPADDW            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig fd /r ]        | AVX512VL,AVX512BW        |
| VPADDW            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig fd /r ]        | AVX512BW                 |
| VPALIGNR          | xmmreg^mask^z,xmmreg*,xmmrm128,imm8         | [rvmi:fvm: evex.nds.128.66.0f3a.wig 0f /r ib ]  | AVX512VL,AVX512BW        |
| VPALIGNR          | ymmreg^mask^z,ymmreg*,ymmrm256,imm8         | [rvmi:fvm: evex.nds.256.66.0f3a.wig 0f /r ib ]  | AVX512VL,AVX512BW        |
| VPALIGNR          | zmmreg^mask^z,zmmreg*,zmmrm512,imm8         | [rvmi:fvm: evex.nds.512.66.0f3a.wig 0f /r ib ]  | AVX512BW                 |
| VPANDD            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 db /r ]          | AVX512VL,AVX512          |
| VPANDD            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 db /r ]          | AVX512VL,AVX512          |
| VPANDD            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 db /r ]          | AVX512                   |
| VPANDND           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 df /r ]          | AVX512VL,AVX512          |
| VPANDND           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 df /r ]          | AVX512VL,AVX512          |
| VPANDND           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 df /r ]          | AVX512                   |
| VPANDNQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 df /r ]          | AVX512VL,AVX512          |
| VPANDNQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 df /r ]          | AVX512VL,AVX512          |
| VPANDNQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 df /r ]          | AVX512                   |
| VPANDQ            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 db /r ]          | AVX512VL,AVX512          |
| VPANDQ            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 db /r ]          | AVX512VL,AVX512          |
| VPANDQ            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 db /r ]          | AVX512                   |
| VPAVGB            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e0 /r ]        | AVX512VL,AVX512BW        |
| VPAVGB            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e0 /r ]        | AVX512VL,AVX512BW        |
| VPAVGB            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e0 /r ]        | AVX512BW                 |
| VPAVGW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e3 /r ]        | AVX512VL,AVX512BW        |
| VPAVGW            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e3 /r ]        | AVX512VL,AVX512BW        |
| VPAVGW            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e3 /r ]        | AVX512BW                 |
| VPBLENDMB         | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w0 66 /r ]       | AVX512VL,AVX512BW        |
| VPBLENDMB         | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w0 66 /r ]       | AVX512VL,AVX512BW        |
| VPBLENDMB         | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w0 66 /r ]       | AVX512BW                 |
| VPBLENDMD         | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 64 /r ]        | AVX512VL,AVX512          |
| VPBLENDMD         | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 64 /r ]        | AVX512VL,AVX512          |
| VPBLENDMD         | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 64 /r ]        | AVX512                   |
| VPBLENDMQ         | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 64 /r ]        | AVX512VL,AVX512          |
| VPBLENDMQ         | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 64 /r ]        | AVX512VL,AVX512          |
| VPBLENDMQ         | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 64 /r ]        | AVX512                   |
| VPBLENDMW         | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w1 66 /r ]       | AVX512VL,AVX512BW        |
| VPBLENDMW         | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w1 66 /r ]       | AVX512VL,AVX512BW        |
| VPBLENDMW         | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w1 66 /r ]       | AVX512BW                 |
| VPBROADCASTB      | xmmreg^mask^z,xmmrm8                        | [rm:t1s8: evex.128.66.0f38.w0 78 /r ]           | AVX512VL,AVX512BW        |
| VPBROADCASTB      | ymmreg^mask^z,xmmrm8                        | [rm:t1s8: evex.256.66.0f38.w0 78 /r ]           | AVX512VL,AVX512BW        |
| VPBROADCASTB      | zmmreg^mask^z,xmmrm8                        | [rm:t1s8: evex.512.66.0f38.w0 78 /r ]           | AVX512BW                 |
| VPBROADCASTB      | xmmreg^mask^z,reg8                          | [rm: evex.128.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | xmmreg^mask^z,reg16                         | [rm: evex.128.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | xmmreg^mask^z,reg32                         | [rm: evex.128.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | xmmreg^mask^z,reg64                         | [rm: evex.128.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | ymmreg^mask^z,reg8                          | [rm: evex.256.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | ymmreg^mask^z,reg16                         | [rm: evex.256.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | ymmreg^mask^z,reg32                         | [rm: evex.256.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | ymmreg^mask^z,reg64                         | [rm: evex.256.66.0f38.w0 7a /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTB      | zmmreg^mask^z,reg8                          | [rm: evex.512.66.0f38.w0 7a /r ]                | AVX512BW                 |
| VPBROADCASTB      | zmmreg^mask^z,reg16                         | [rm: evex.512.66.0f38.w0 7a /r ]                | AVX512BW                 |
| VPBROADCASTB      | zmmreg^mask^z,reg32                         | [rm: evex.512.66.0f38.w0 7a /r ]                | AVX512BW                 |
| VPBROADCASTB      | zmmreg^mask^z,reg64                         | [rm: evex.512.66.0f38.w0 7a /r ]                | AVX512BW                 |
| VPBROADCASTD      | xmmreg^mask^z,mem32                         | [rm:t1s: evex.128.66.0f38.w0 58 /r ]            | AVX512VL,AVX512          |
| VPBROADCASTD      | ymmreg^mask^z,mem32                         | [rm:t1s: evex.256.66.0f38.w0 58 /r ]            | AVX512VL,AVX512          |
| VPBROADCASTD      | zmmreg^mask^z,mem32                         | [rm:t1s: evex.512.66.0f38.w0 58 /r ]            | AVX512                   |
| VPBROADCASTD      | xmmreg^mask^z,xmmreg                        | [rm: evex.128.66.0f38.w0 58 /r ]                | AVX512VL,AVX512          |
| VPBROADCASTD      | ymmreg^mask^z,xmmreg                        | [rm: evex.256.66.0f38.w0 58 /r ]                | AVX512VL,AVX512          |
| VPBROADCASTD      | zmmreg^mask^z,xmmreg                        | [rm: evex.512.66.0f38.w0 58 /r ]                | AVX512                   |
| VPBROADCASTD      | xmmreg^mask^z,reg32                         | [rm: evex.128.66.0f38.w0 7c /r ]                | AVX512VL,AVX512          |
| VPBROADCASTD      | ymmreg^mask^z,reg32                         | [rm: evex.256.66.0f38.w0 7c /r ]                | AVX512VL,AVX512          |
| VPBROADCASTD      | zmmreg^mask^z,reg32                         | [rm: evex.512.66.0f38.w0 7c /r ]                | AVX512                   |
| VPBROADCASTMB2Q   | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w1 2a /r ]                | AVX512VL,AVX512CD        |
| VPBROADCASTMB2Q   | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w1 2a /r ]                | AVX512VL,AVX512CD        |
| VPBROADCASTMB2Q   | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w1 2a /r ]                | AVX512CD                 |
| VPBROADCASTMW2D   | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w0 3a /r ]                | AVX512VL,AVX512CD        |
| VPBROADCASTMW2D   | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w0 3a /r ]                | AVX512VL,AVX512CD        |
| VPBROADCASTMW2D   | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w0 3a /r ]                | AVX512CD                 |
| VPBROADCASTQ      | xmmreg^mask^z,mem64                         | [rm:t1s: evex.128.66.0f38.w1 59 /r ]            | AVX512VL,AVX512          |
| VPBROADCASTQ      | ymmreg^mask^z,mem64                         | [rm:t1s: evex.256.66.0f38.w1 59 /r ]            | AVX512VL,AVX512          |
| VPBROADCASTQ      | zmmreg^mask^z,mem64                         | [rm:t1s: evex.512.66.0f38.w1 59 /r ]            | AVX512                   |
| VPBROADCASTQ      | xmmreg^mask^z,xmmreg                        | [rm: evex.128.66.0f38.w1 59 /r ]                | AVX512VL,AVX512          |
| VPBROADCASTQ      | ymmreg^mask^z,xmmreg                        | [rm: evex.256.66.0f38.w1 59 /r ]                | AVX512VL,AVX512          |
| VPBROADCASTQ      | zmmreg^mask^z,xmmreg                        | [rm: evex.512.66.0f38.w1 59 /r ]                | AVX512                   |
| VPBROADCASTQ      | xmmreg^mask^z,reg64                         | [rm: evex.128.66.0f38.w1 7c /r ]                | AVX512VL,AVX512          |
| VPBROADCASTQ      | ymmreg^mask^z,reg64                         | [rm: evex.256.66.0f38.w1 7c /r ]                | AVX512VL,AVX512          |
| VPBROADCASTQ      | zmmreg^mask^z,reg64                         | [rm: evex.512.66.0f38.w1 7c /r ]                | AVX512                   |
| VPBROADCASTW      | xmmreg^mask^z,xmmrm16                       | [rm:t1s16: evex.128.66.0f38.w0 79 /r ]          | AVX512VL,AVX512BW        |
| VPBROADCASTW      | ymmreg^mask^z,xmmrm16                       | [rm:t1s16: evex.256.66.0f38.w0 79 /r ]          | AVX512VL,AVX512BW        |
| VPBROADCASTW      | zmmreg^mask^z,xmmrm16                       | [rm:t1s16: evex.512.66.0f38.w0 79 /r ]          | AVX512BW                 |
| VPBROADCASTW      | xmmreg^mask^z,reg16                         | [rm: evex.128.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | xmmreg^mask^z,reg32                         | [rm: evex.128.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | xmmreg^mask^z,reg64                         | [rm: evex.128.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | ymmreg^mask^z,reg16                         | [rm: evex.256.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | ymmreg^mask^z,reg32                         | [rm: evex.256.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | ymmreg^mask^z,reg64                         | [rm: evex.256.66.0f38.w0 7b /r ]                | AVX512VL,AVX512BW        |
| VPBROADCASTW      | zmmreg^mask^z,reg16                         | [rm: evex.512.66.0f38.w0 7b /r ]                | AVX512BW                 |
| VPBROADCASTW      | zmmreg^mask^z,reg32                         | [rm: evex.512.66.0f38.w0 7b /r ]                | AVX512BW                 |
| VPBROADCASTW      | zmmreg^mask^z,reg64                         | [rm: evex.512.66.0f38.w0 7b /r ]                | AVX512BW                 |
| VPCMPB            | kreg^mask,xmmreg,xmmrm128,imm8              | [rvmi:fvm: evex.nds.128.66.0f3a.w0 3f /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPB            | kreg^mask,ymmreg,ymmrm256,imm8              | [rvmi:fvm: evex.nds.256.66.0f3a.w0 3f /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPB            | kreg^mask,zmmreg,zmmrm512,imm8              | [rvmi:fvm: evex.nds.512.66.0f3a.w0 3f /r ib ]   | AVX512BW                 |
| VPCMPD            | kreg^mask,xmmreg,xmmrm128^b32,imm8          | [rvmi:fv: evex.nds.128.66.0f3a.w0 1f /r ib ]    | AVX512VL,AVX512          |
| VPCMPD            | kreg^mask,ymmreg,ymmrm256^b32,imm8          | [rvmi:fv: evex.nds.256.66.0f3a.w0 1f /r ib ]    | AVX512VL,AVX512          |
| VPCMPD            | kreg^mask,zmmreg,zmmrm512^b32,imm8          | [rvmi:fv: evex.nds.512.66.0f3a.w0 1f /r ib ]    | AVX512                   |
| VPCMPEQB          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f.wig 74 /r ]        | AVX512VL,AVX512BW        |
| VPCMPEQB          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f.wig 74 /r ]        | AVX512VL,AVX512BW        |
| VPCMPEQB          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f.wig 74 /r ]        | AVX512BW                 |
| VPCMPEQD          | kreg^mask,xmmreg,xmmrm128^b32               | [rvm:fv: evex.nds.128.66.0f.w0 76 /r ]          | AVX512VL,AVX512          |
| VPCMPEQD          | kreg^mask,ymmreg,ymmrm256^b32               | [rvm:fv: evex.nds.256.66.0f.w0 76 /r ]          | AVX512VL,AVX512          |
| VPCMPEQD          | kreg^mask,zmmreg,zmmrm512^b32               | [rvm:fv: evex.nds.512.66.0f.w0 76 /r ]          | AVX512                   |
| VPCMPEQQ          | kreg^mask,xmmreg,xmmrm128^b64               | [rvm:fv: evex.nds.128.66.0f38.w1 29 /r ]        | AVX512VL,AVX512          |
| VPCMPEQQ          | kreg^mask,ymmreg,ymmrm256^b64               | [rvm:fv: evex.nds.256.66.0f38.w1 29 /r ]        | AVX512VL,AVX512          |
| VPCMPEQQ          | kreg^mask,zmmreg,zmmrm512^b64               | [rvm:fv: evex.nds.512.66.0f38.w1 29 /r ]        | AVX512                   |
| VPCMPEQW          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f.wig 75 /r ]        | AVX512VL,AVX512BW        |
| VPCMPEQW          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f.wig 75 /r ]        | AVX512VL,AVX512BW        |
| VPCMPEQW          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f.wig 75 /r ]        | AVX512BW                 |
| VPCMPGTB          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f.wig 64 /r ]        | AVX512VL,AVX512BW        |
| VPCMPGTB          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f.wig 64 /r ]        | AVX512VL,AVX512BW        |
| VPCMPGTB          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f.wig 64 /r ]        | AVX512BW                 |
| VPCMPGTD          | kreg^mask,xmmreg,xmmrm128^b32               | [rvm:fv: evex.nds.128.66.0f.w0 66 /r ]          | AVX512VL,AVX512          |
| VPCMPGTD          | kreg^mask,ymmreg,ymmrm256^b32               | [rvm:fv: evex.nds.256.66.0f.w0 66 /r ]          | AVX512VL,AVX512          |
| VPCMPGTD          | kreg^mask,zmmreg,zmmrm512^b32               | [rvm:fv: evex.nds.512.66.0f.w0 66 /r ]          | AVX512                   |
| VPCMPGTQ          | kreg^mask,xmmreg,xmmrm128^b64               | [rvm:fv: evex.nds.128.66.0f38.w1 37 /r ]        | AVX512VL,AVX512          |
| VPCMPGTQ          | kreg^mask,ymmreg,ymmrm256^b64               | [rvm:fv: evex.nds.256.66.0f38.w1 37 /r ]        | AVX512VL,AVX512          |
| VPCMPGTQ          | kreg^mask,zmmreg,zmmrm512^b64               | [rvm:fv: evex.nds.512.66.0f38.w1 37 /r ]        | AVX512                   |
| VPCMPGTW          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f.wig 65 /r ]        | AVX512VL,AVX512BW        |
| VPCMPGTW          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f.wig 65 /r ]        | AVX512VL,AVX512BW        |
| VPCMPGTW          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f.wig 65 /r ]        | AVX512BW                 |
| VPCMPQ            | kreg^mask,xmmreg,xmmrm128^b64,imm8          | [rvmi:fv: evex.nds.128.66.0f3a.w1 1f /r ib ]    | AVX512VL,AVX512          |
| VPCMPQ            | kreg^mask,ymmreg,ymmrm256^b64,imm8          | [rvmi:fv: evex.nds.256.66.0f3a.w1 1f /r ib ]    | AVX512VL,AVX512          |
| VPCMPQ            | kreg^mask,zmmreg,zmmrm512^b64,imm8          | [rvmi:fv: evex.nds.512.66.0f3a.w1 1f /r ib ]    | AVX512                   |
| VPCMPUB           | kreg^mask,xmmreg,xmmrm128,imm8              | [rvmi:fvm: evex.nds.128.66.0f3a.w0 3e /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPUB           | kreg^mask,ymmreg,ymmrm256,imm8              | [rvmi:fvm: evex.nds.256.66.0f3a.w0 3e /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPUB           | kreg^mask,zmmreg,zmmrm512,imm8              | [rvmi:fvm: evex.nds.512.66.0f3a.w0 3e /r ib ]   | AVX512BW                 |
| VPCMPUD           | kreg^mask,xmmreg,xmmrm128^b32,imm8          | [rvmi:fv: evex.nds.128.66.0f3a.w0 1e /r ib ]    | AVX512VL,AVX512          |
| VPCMPUD           | kreg^mask,ymmreg,ymmrm256^b32,imm8          | [rvmi:fv: evex.nds.256.66.0f3a.w0 1e /r ib ]    | AVX512VL,AVX512          |
| VPCMPUD           | kreg^mask,zmmreg,zmmrm512^b32,imm8          | [rvmi:fv: evex.nds.512.66.0f3a.w0 1e /r ib ]    | AVX512                   |
| VPCMPUQ           | kreg^mask,xmmreg,xmmrm128^b64,imm8          | [rvmi:fv: evex.nds.128.66.0f3a.w1 1e /r ib ]    | AVX512VL,AVX512          |
| VPCMPUQ           | kreg^mask,ymmreg,ymmrm256^b64,imm8          | [rvmi:fv: evex.nds.256.66.0f3a.w1 1e /r ib ]    | AVX512VL,AVX512          |
| VPCMPUQ           | kreg^mask,zmmreg,zmmrm512^b64,imm8          | [rvmi:fv: evex.nds.512.66.0f3a.w1 1e /r ib ]    | AVX512                   |
| VPCMPUW           | kreg^mask,xmmreg,xmmrm128,imm8              | [rvmi:fvm: evex.nds.128.66.0f3a.w1 3e /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPUW           | kreg^mask,ymmreg,ymmrm256,imm8              | [rvmi:fvm: evex.nds.256.66.0f3a.w1 3e /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPUW           | kreg^mask,zmmreg,zmmrm512,imm8              | [rvmi:fvm: evex.nds.512.66.0f3a.w1 3e /r ib ]   | AVX512BW                 |
| VPCMPW            | kreg^mask,xmmreg,xmmrm128,imm8              | [rvmi:fvm: evex.nds.128.66.0f3a.w1 3f /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPW            | kreg^mask,ymmreg,ymmrm256,imm8              | [rvmi:fvm: evex.nds.256.66.0f3a.w1 3f /r ib ]   | AVX512VL,AVX512BW        |
| VPCMPW            | kreg^mask,zmmreg,zmmrm512,imm8              | [rvmi:fvm: evex.nds.512.66.0f3a.w1 3f /r ib ]   | AVX512BW                 |
| VPCOMPRESSD       | mem128^mask,xmmreg                          | [mr:t1s: evex.128.66.0f38.w0 8b /r ]            | AVX512VL,AVX512          |
| VPCOMPRESSD       | mem256^mask,ymmreg                          | [mr:t1s: evex.256.66.0f38.w0 8b /r ]            | AVX512VL,AVX512          |
| VPCOMPRESSD       | zmem512^mask,zmmreg                         | [mr:t1s: evex.512.66.0f38.w0 8b /r ]            | AVX512                   |
| VPCOMPRESSD       | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f38.w0 8b /r ]                | AVX512VL,AVX512          |
| VPCOMPRESSD       | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f38.w0 8b /r ]                | AVX512VL,AVX512          |
| VPCOMPRESSD       | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f38.w0 8b /r ]                | AVX512                   |
| VPCOMPRESSQ       | mem128^mask,xmmreg                          | [mr:t1s: evex.128.66.0f38.w1 8b /r ]            | AVX512VL,AVX512          |
| VPCOMPRESSQ       | mem256^mask,ymmreg                          | [mr:t1s: evex.256.66.0f38.w1 8b /r ]            | AVX512VL,AVX512          |
| VPCOMPRESSQ       | zmem512^mask,zmmreg                         | [mr:t1s: evex.512.66.0f38.w1 8b /r ]            | AVX512                   |
| VPCOMPRESSQ       | xmmreg^mask^z,xmmreg                        | [mr: evex.128.66.0f38.w1 8b /r ]                | AVX512VL,AVX512          |
| VPCOMPRESSQ       | ymmreg^mask^z,ymmreg                        | [mr: evex.256.66.0f38.w1 8b /r ]                | AVX512VL,AVX512          |
| VPCOMPRESSQ       | zmmreg^mask^z,zmmreg                        | [mr: evex.512.66.0f38.w1 8b /r ]                | AVX512                   |
| VPCONFLICTD       | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 c4 /r ]             | AVX512VL,AVX512CD        |
| VPCONFLICTD       | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 c4 /r ]             | AVX512VL,AVX512CD        |
| VPCONFLICTD       | zmmreg^mask^z,zmmrm512^b32                  | [rm:fv: evex.512.66.0f38.w0 c4 /r ]             | AVX512CD                 |
| VPCONFLICTQ       | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 c4 /r ]             | AVX512VL,AVX512CD        |
| VPCONFLICTQ       | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 c4 /r ]             | AVX512VL,AVX512CD        |
| VPCONFLICTQ       | zmmreg^mask^z,zmmrm512^b64                  | [rm:fv: evex.512.66.0f38.w1 c4 /r ]             | AVX512CD                 |
| VPERMB            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w0 8d /r ]       | AVX512VL,AVX512VBMI      |
| VPERMB            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w0 8d /r ]       | AVX512VL,AVX512VBMI      |
| VPERMB            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w0 8d /r ]       | AVX512VBMI               |
| VPERMD            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 36 /r ]        | AVX512VL,AVX512          |
| VPERMD            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 36 /r ]        | AVX512                   |
| VPERMI2B          | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w0 75 /r ]       | AVX512VL,AVX512VBMI      |
| VPERMI2B          | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w0 75 /r ]       | AVX512VL,AVX512VBMI      |
| VPERMI2B          | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w0 75 /r ]       | AVX512VBMI               |
| VPERMI2D          | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 76 /r ]        | AVX512VL,AVX512          |
| VPERMI2D          | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 76 /r ]        | AVX512VL,AVX512          |
| VPERMI2D          | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 76 /r ]        | AVX512                   |
| VPERMI2PD         | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 77 /r ]        | AVX512VL,AVX512          |
| VPERMI2PD         | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 77 /r ]        | AVX512VL,AVX512          |
| VPERMI2PD         | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 77 /r ]        | AVX512                   |
| VPERMI2PS         | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 77 /r ]        | AVX512VL,AVX512          |
| VPERMI2PS         | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 77 /r ]        | AVX512VL,AVX512          |
| VPERMI2PS         | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 77 /r ]        | AVX512                   |
| VPERMI2Q          | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 76 /r ]        | AVX512VL,AVX512          |
| VPERMI2Q          | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 76 /r ]        | AVX512VL,AVX512          |
| VPERMI2Q          | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 76 /r ]        | AVX512                   |
| VPERMI2W          | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w1 75 /r ]       | AVX512VL,AVX512BW        |
| VPERMI2W          | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w1 75 /r ]       | AVX512VL,AVX512BW        |
| VPERMI2W          | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w1 75 /r ]       | AVX512BW                 |
| VPERMILPD         | xmmreg^mask^z,xmmrm128^b64,imm8             | [rmi:fv: evex.128.66.0f3a.w1 05 /r ib ]         | AVX512VL,AVX512          |
| VPERMILPD         | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 05 /r ib ]         | AVX512VL,AVX512          |
| VPERMILPD         | zmmreg^mask^z,zmmrm512^b64,imm8             | [rmi:fv: evex.512.66.0f3a.w1 05 /r ib ]         | AVX512                   |
| VPERMILPD         | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 0d /r ]        | AVX512VL,AVX512          |
| VPERMILPD         | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 0d /r ]        | AVX512VL,AVX512          |
| VPERMILPD         | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 0d /r ]        | AVX512                   |
| VPERMILPS         | xmmreg^mask^z,xmmrm128^b32,imm8             | [rmi:fv: evex.128.66.0f3a.w0 04 /r ib ]         | AVX512VL,AVX512          |
| VPERMILPS         | ymmreg^mask^z,ymmrm256^b32,imm8             | [rmi:fv: evex.256.66.0f3a.w0 04 /r ib ]         | AVX512VL,AVX512          |
| VPERMILPS         | zmmreg^mask^z,zmmrm512^b32,imm8             | [rmi:fv: evex.512.66.0f3a.w0 04 /r ib ]         | AVX512                   |
| VPERMILPS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 0c /r ]        | AVX512VL,AVX512          |
| VPERMILPS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 0c /r ]        | AVX512VL,AVX512          |
| VPERMILPS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 0c /r ]        | AVX512                   |
| VPERMPD           | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 01 /r ib ]         | AVX512VL,AVX512          |
| VPERMPD           | zmmreg^mask^z,zmmrm512^b64,imm8             | [rmi:fv: evex.512.66.0f3a.w1 01 /r ib ]         | AVX512                   |
| VPERMPD           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 16 /r ]        | AVX512VL,AVX512          |
| VPERMPD           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 16 /r ]        | AVX512                   |
| VPERMPS           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 16 /r ]        | AVX512VL,AVX512          |
| VPERMPS           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 16 /r ]        | AVX512                   |
| VPERMQ            | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 00 /r ib ]         | AVX512VL,AVX512          |
| VPERMQ            | zmmreg^mask^z,zmmrm512^b64,imm8             | [rmi:fv: evex.512.66.0f3a.w1 00 /r ib ]         | AVX512                   |
| VPERMQ            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 36 /r ]        | AVX512VL,AVX512          |
| VPERMQ            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 36 /r ]        | AVX512                   |
| VPERMT2B          | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w0 7d /r ]       | AVX512VL,AVX512VBMI      |
| VPERMT2B          | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w0 7d /r ]       | AVX512VL,AVX512VBMI      |
| VPERMT2B          | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w0 7d /r ]       | AVX512VBMI               |
| VPERMT2D          | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 7e /r ]        | AVX512VL,AVX512          |
| VPERMT2D          | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 7e /r ]        | AVX512VL,AVX512          |
| VPERMT2D          | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 7e /r ]        | AVX512                   |
| VPERMT2PD         | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 7f /r ]        | AVX512VL,AVX512          |
| VPERMT2PD         | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 7f /r ]        | AVX512VL,AVX512          |
| VPERMT2PD         | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 7f /r ]        | AVX512                   |
| VPERMT2PS         | xmmreg^mask^z,xmmreg,xmmrm128^b32           | [rvm:fv: evex.nds.128.66.0f38.w0 7f /r ]        | AVX512VL,AVX512          |
| VPERMT2PS         | ymmreg^mask^z,ymmreg,ymmrm256^b32           | [rvm:fv: evex.nds.256.66.0f38.w0 7f /r ]        | AVX512VL,AVX512          |
| VPERMT2PS         | zmmreg^mask^z,zmmreg,zmmrm512^b32           | [rvm:fv: evex.nds.512.66.0f38.w0 7f /r ]        | AVX512                   |
| VPERMT2Q          | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 7e /r ]        | AVX512VL,AVX512          |
| VPERMT2Q          | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 7e /r ]        | AVX512VL,AVX512          |
| VPERMT2Q          | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 7e /r ]        | AVX512                   |
| VPERMT2W          | xmmreg^mask^z,xmmreg,xmmrm128               | [rvm:fvm: evex.nds.128.66.0f38.w1 7d /r ]       | AVX512VL,AVX512BW        |
| VPERMT2W          | ymmreg^mask^z,ymmreg,ymmrm256               | [rvm:fvm: evex.nds.256.66.0f38.w1 7d /r ]       | AVX512VL,AVX512BW        |
| VPERMT2W          | zmmreg^mask^z,zmmreg,zmmrm512               | [rvm:fvm: evex.nds.512.66.0f38.w1 7d /r ]       | AVX512BW                 |
| VPERMW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w1 8d /r ]       | AVX512VL,AVX512BW        |
| VPERMW            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w1 8d /r ]       | AVX512VL,AVX512BW        |
| VPERMW            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w1 8d /r ]       | AVX512BW                 |
| VPEXPANDD         | xmmreg^mask^z,mem128                        | [rm:t1s: evex.128.66.0f38.w0 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDD         | ymmreg^mask^z,mem256                        | [rm:t1s: evex.256.66.0f38.w0 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDD         | zmmreg^mask^z,mem512                        | [rm:t1s: evex.512.66.0f38.w0 89 /r ]            | AVX512                   |
| VPEXPANDD         | xmmreg^mask^z,xmmreg                        | [rm:t1s: evex.128.66.0f38.w0 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDD         | ymmreg^mask^z,ymmreg                        | [rm:t1s: evex.256.66.0f38.w0 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDD         | zmmreg^mask^z,zmmreg                        | [rm:t1s: evex.512.66.0f38.w0 89 /r ]            | AVX512                   |
| VPEXPANDQ         | xmmreg^mask^z,mem128                        | [rm:t1s: evex.128.66.0f38.w1 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDQ         | ymmreg^mask^z,mem256                        | [rm:t1s: evex.256.66.0f38.w1 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDQ         | zmmreg^mask^z,mem512                        | [rm:t1s: evex.512.66.0f38.w1 89 /r ]            | AVX512                   |
| VPEXPANDQ         | xmmreg^mask^z,xmmreg                        | [rm:t1s: evex.128.66.0f38.w1 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDQ         | ymmreg^mask^z,ymmreg                        | [rm:t1s: evex.256.66.0f38.w1 89 /r ]            | AVX512VL,AVX512          |
| VPEXPANDQ         | zmmreg^mask^z,zmmreg                        | [rm:t1s: evex.512.66.0f38.w1 89 /r ]            | AVX512                   |
| VPEXTRB           | reg8,xmmreg,imm8                            | [mri:t1s8: evex.128.66.0f3a.wig 14 /r ib ]      | AVX512BW                 |
| VPEXTRB           | reg16,xmmreg,imm8                           | [mri:t1s8: evex.128.66.0f3a.wig 14 /r ib ]      | AVX512BW                 |
| VPEXTRB           | reg32,xmmreg,imm8                           | [mri:t1s8: evex.128.66.0f3a.wig 14 /r ib ]      | AVX512BW                 |
| VPEXTRB           | reg64,xmmreg,imm8                           | [mri:t1s8: evex.128.66.0f3a.wig 14 /r ib ]      | AVX512BW                 |
| VPEXTRB           | mem8,xmmreg,imm8                            | [mri:t1s8: evex.128.66.0f3a.wig 14 /r ib ]      | AVX512BW                 |
| VPEXTRD           | rm32,xmmreg,imm8                            | [mri:t1s: evex.128.66.0f3a.w0 16 /r ib ]        | AVX512DQ                 |
| VPEXTRQ           | rm64,xmmreg,imm8                            | [mri:t1s: evex.128.66.0f3a.w1 16 /r ib ]        | AVX512DQ                 |
| VPEXTRW           | reg16,xmmreg,imm8                           | [mri:t1s16: evex.128.66.0f3a.wig 15 /r ib ]     | AVX512BW                 |
| VPEXTRW           | reg32,xmmreg,imm8                           | [mri:t1s16: evex.128.66.0f3a.wig 15 /r ib ]     | AVX512BW                 |
| VPEXTRW           | reg64,xmmreg,imm8                           | [mri:t1s16: evex.128.66.0f3a.wig 15 /r ib ]     | AVX512BW                 |
| VPEXTRW           | mem16,xmmreg,imm8                           | [mri:t1s16: evex.128.66.0f3a.wig 15 /r ib ]     | AVX512BW                 |
| VPEXTRW           | reg16,xmmreg,imm8                           | [rmi: evex.128.66.0f.wig c5 /r ib ]             | AVX512BW                 |
| VPEXTRW           | reg32,xmmreg,imm8                           | [rmi: evex.128.66.0f.wig c5 /r ib ]             | AVX512BW                 |
| VPEXTRW           | reg64,xmmreg,imm8                           | [rmi: evex.128.66.0f.wig c5 /r ib ]             | AVX512BW                 |
| VPGATHERDD        | xmmreg^mask,xmem32                          | [rm:t1s: vsibx evex.128.66.0f38.w0 90 /r ]      | AVX512VL,AVX512          |
| VPGATHERDD        | ymmreg^mask,ymem32                          | [rm:t1s: vsiby evex.256.66.0f38.w0 90 /r ]      | AVX512VL,AVX512          |
| VPGATHERDD        | zmmreg^mask,zmem32                          | [rm:t1s: vsibz evex.512.66.0f38.w0 90 /r ]      | AVX512                   |
| VPGATHERDQ        | xmmreg^mask,xmem64                          | [rm:t1s: vsibx evex.128.66.0f38.w1 90 /r ]      | AVX512VL,AVX512          |
| VPGATHERDQ        | ymmreg^mask,xmem64                          | [rm:t1s: vsibx evex.256.66.0f38.w1 90 /r ]      | AVX512VL,AVX512          |
| VPGATHERDQ        | zmmreg^mask,ymem64                          | [rm:t1s: vsiby evex.512.66.0f38.w1 90 /r ]      | AVX512                   |
| VPGATHERQD        | xmmreg^mask,xmem32                          | [rm:t1s: vsibx evex.128.66.0f38.w0 91 /r ]      | AVX512VL,AVX512          |
| VPGATHERQD        | xmmreg^mask,ymem32                          | [rm:t1s: vsiby evex.256.66.0f38.w0 91 /r ]      | AVX512VL,AVX512          |
| VPGATHERQD        | ymmreg^mask,zmem32                          | [rm:t1s: vsibz evex.512.66.0f38.w0 91 /r ]      | AVX512                   |
| VPGATHERQQ        | xmmreg^mask,xmem64                          | [rm:t1s: vsibx evex.128.66.0f38.w1 91 /r ]      | AVX512VL,AVX512          |
| VPGATHERQQ        | ymmreg^mask,ymem64                          | [rm:t1s: vsiby evex.256.66.0f38.w1 91 /r ]      | AVX512VL,AVX512          |
| VPGATHERQQ        | zmmreg^mask,zmem64                          | [rm:t1s: vsibz evex.512.66.0f38.w1 91 /r ]      | AVX512                   |
| VPINSRB           | xmmreg,xmmreg*,reg32,imm8                   | [rvmi:t1s8: evex.nds.128.66.0f3a.wig 20 /r ib ] | AVX512BW                 |
| VPINSRB           | xmmreg,xmmreg*,mem8,imm8                    | [rvmi:t1s8: evex.nds.128.66.0f3a.wig 20 /r ib ] | AVX512BW                 |
| VPINSRD           | xmmreg,xmmreg*,rm32,imm8                    | [rvmi:t1s: evex.nds.128.66.0f3a.w0 22 /r ib ]   | AVX512DQ                 |
| VPINSRQ           | xmmreg,xmmreg*,rm64,imm8                    | [rvmi:t1s: evex.nds.128.66.0f3a.w1 22 /r ib ]   | AVX512DQ                 |
| VPINSRW           | xmmreg,xmmreg*,reg32,imm8                   | [rvmi:t1s16: evex.nds.128.66.0f.wig c4 /r ib ]  | AVX512BW                 |
| VPINSRW           | xmmreg,xmmreg*,mem16,imm8                   | [rvmi:t1s16: evex.nds.128.66.0f.wig c4 /r ib ]  | AVX512BW                 |
| VPLZCNTD          | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 44 /r ]             | AVX512VL,AVX512CD        |
| VPLZCNTD          | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 44 /r ]             | AVX512VL,AVX512CD        |
| VPLZCNTD          | zmmreg^mask^z,zmmrm512^b32                  | [rm:fv: evex.512.66.0f38.w0 44 /r ]             | AVX512CD                 |
| VPLZCNTQ          | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 44 /r ]             | AVX512VL,AVX512CD        |
| VPLZCNTQ          | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 44 /r ]             | AVX512VL,AVX512CD        |
| VPLZCNTQ          | zmmreg^mask^z,zmmrm512^b64                  | [rm:fv: evex.512.66.0f38.w1 44 /r ]             | AVX512CD                 |
| VPMADD52HUQ       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 b5 /r ]        | AVX512VL,AVX512IFMA      |
| VPMADD52HUQ       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 b5 /r ]        | AVX512VL,AVX512IFMA      |
| VPMADD52HUQ       | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 b5 /r ]        | AVX512IFMA               |
| VPMADD52LUQ       | xmmreg^mask^z,xmmreg,xmmrm128^b64           | [rvm:fv: evex.nds.128.66.0f38.w1 b4 /r ]        | AVX512VL,AVX512IFMA      |
| VPMADD52LUQ       | ymmreg^mask^z,ymmreg,ymmrm256^b64           | [rvm:fv: evex.nds.256.66.0f38.w1 b4 /r ]        | AVX512VL,AVX512IFMA      |
| VPMADD52LUQ       | zmmreg^mask^z,zmmreg,zmmrm512^b64           | [rvm:fv: evex.nds.512.66.0f38.w1 b4 /r ]        | AVX512IFMA               |
| VPMADDUBSW        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 04 /r ]      | AVX512VL,AVX512BW        |
| VPMADDUBSW        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 04 /r ]      | AVX512VL,AVX512BW        |
| VPMADDUBSW        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 04 /r ]      | AVX512BW                 |
| VPMADDWD          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig f5 /r ]        | AVX512VL,AVX512BW        |
| VPMADDWD          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig f5 /r ]        | AVX512VL,AVX512BW        |
| VPMADDWD          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig f5 /r ]        | AVX512BW                 |
| VPMAXSB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 3c /r ]      | AVX512VL,AVX512BW        |
| VPMAXSB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 3c /r ]      | AVX512VL,AVX512BW        |
| VPMAXSB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 3c /r ]      | AVX512BW                 |
| VPMAXSD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 3d /r ]        | AVX512VL,AVX512          |
| VPMAXSD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 3d /r ]        | AVX512VL,AVX512          |
| VPMAXSD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 3d /r ]        | AVX512                   |
| VPMAXSQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 3d /r ]        | AVX512VL,AVX512          |
| VPMAXSQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 3d /r ]        | AVX512VL,AVX512          |
| VPMAXSQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 3d /r ]        | AVX512                   |
| VPMAXSW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig ee /r ]        | AVX512VL,AVX512BW        |
| VPMAXSW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig ee /r ]        | AVX512VL,AVX512BW        |
| VPMAXSW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig ee /r ]        | AVX512BW                 |
| VPMAXUB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig de /r ]        | AVX512VL,AVX512BW        |
| VPMAXUB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig de /r ]        | AVX512VL,AVX512BW        |
| VPMAXUB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig de /r ]        | AVX512BW                 |
| VPMAXUD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 3f /r ]        | AVX512VL,AVX512          |
| VPMAXUD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 3f /r ]        | AVX512VL,AVX512          |
| VPMAXUD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 3f /r ]        | AVX512                   |
| VPMAXUQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 3f /r ]        | AVX512VL,AVX512          |
| VPMAXUQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 3f /r ]        | AVX512VL,AVX512          |
| VPMAXUQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 3f /r ]        | AVX512                   |
| VPMAXUW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 3e /r ]      | AVX512VL,AVX512BW        |
| VPMAXUW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 3e /r ]      | AVX512VL,AVX512BW        |
| VPMAXUW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 3e /r ]      | AVX512BW                 |
| VPMINSB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 38 /r ]      | AVX512VL,AVX512BW        |
| VPMINSB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 38 /r ]      | AVX512VL,AVX512BW        |
| VPMINSB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 38 /r ]      | AVX512BW                 |
| VPMINSD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 39 /r ]        | AVX512VL,AVX512          |
| VPMINSD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 39 /r ]        | AVX512VL,AVX512          |
| VPMINSD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 39 /r ]        | AVX512                   |
| VPMINSQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 39 /r ]        | AVX512VL,AVX512          |
| VPMINSQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 39 /r ]        | AVX512VL,AVX512          |
| VPMINSQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 39 /r ]        | AVX512                   |
| VPMINSW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig ea /r ]        | AVX512VL,AVX512BW        |
| VPMINSW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig ea /r ]        | AVX512VL,AVX512BW        |
| VPMINSW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig ea /r ]        | AVX512BW                 |
| VPMINUB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig da /r ]        | AVX512VL,AVX512BW        |
| VPMINUB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig da /r ]        | AVX512VL,AVX512BW        |
| VPMINUB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig da /r ]        | AVX512BW                 |
| VPMINUD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 3b /r ]        | AVX512VL,AVX512          |
| VPMINUD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 3b /r ]        | AVX512VL,AVX512          |
| VPMINUD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 3b /r ]        | AVX512                   |
| VPMINUQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 3b /r ]        | AVX512VL,AVX512          |
| VPMINUQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 3b /r ]        | AVX512VL,AVX512          |
| VPMINUQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 3b /r ]        | AVX512                   |
| VPMINUW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 3a /r ]      | AVX512VL,AVX512BW        |
| VPMINUW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 3a /r ]      | AVX512VL,AVX512BW        |
| VPMINUW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 3a /r ]      | AVX512BW                 |
| VPMOVB2M          | kreg,xmmreg                                 | [rm: evex.128.f3.0f38.w0 29 /r ]                | AVX512VL,AVX512BW        |
| VPMOVB2M          | kreg,ymmreg                                 | [rm: evex.256.f3.0f38.w0 29 /r ]                | AVX512VL,AVX512BW        |
| VPMOVB2M          | kreg,zmmreg                                 | [rm: evex.512.f3.0f38.w0 29 /r ]                | AVX512BW                 |
| VPMOVD2M          | kreg,xmmreg                                 | [rm: evex.128.f3.0f38.w0 39 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVD2M          | kreg,ymmreg                                 | [rm: evex.256.f3.0f38.w0 39 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVD2M          | kreg,zmmreg                                 | [rm: evex.512.f3.0f38.w0 39 /r ]                | AVX512DQ                 |
| VPMOVDB           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 31 /r ]                | AVX512VL,AVX512          |
| VPMOVDB           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 31 /r ]                | AVX512VL,AVX512          |
| VPMOVDB           | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 31 /r ]                | AVX512                   |
| VPMOVDB           | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 31 /r ]            | AVX512VL,AVX512          |
| VPMOVDB           | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 31 /r ]            | AVX512VL,AVX512          |
| VPMOVDB           | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 31 /r ]            | AVX512                   |
| VPMOVDW           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 33 /r ]                | AVX512VL,AVX512          |
| VPMOVDW           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 33 /r ]                | AVX512VL,AVX512          |
| VPMOVDW           | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 33 /r ]                | AVX512                   |
| VPMOVDW           | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 33 /r ]            | AVX512VL,AVX512          |
| VPMOVDW           | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 33 /r ]            | AVX512VL,AVX512          |
| VPMOVDW           | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 33 /r ]            | AVX512                   |
| VPMOVM2B          | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w0 28 /r ]                | AVX512VL,AVX512BW        |
| VPMOVM2B          | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w0 28 /r ]                | AVX512VL,AVX512BW        |
| VPMOVM2B          | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w0 28 /r ]                | AVX512BW                 |
| VPMOVM2D          | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w0 38 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVM2D          | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w0 38 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVM2D          | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w0 38 /r ]                | AVX512DQ                 |
| VPMOVM2Q          | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w1 38 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVM2Q          | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w1 38 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVM2Q          | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w1 38 /r ]                | AVX512DQ                 |
| VPMOVM2W          | xmmreg,kreg                                 | [rm: evex.128.f3.0f38.w1 28 /r ]                | AVX512VL,AVX512BW        |
| VPMOVM2W          | ymmreg,kreg                                 | [rm: evex.256.f3.0f38.w1 28 /r ]                | AVX512VL,AVX512BW        |
| VPMOVM2W          | zmmreg,kreg                                 | [rm: evex.512.f3.0f38.w1 28 /r ]                | AVX512BW                 |
| VPMOVQ2M          | kreg,xmmreg                                 | [rm: evex.128.f3.0f38.w1 39 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVQ2M          | kreg,ymmreg                                 | [rm: evex.256.f3.0f38.w1 39 /r ]                | AVX512VL,AVX512DQ        |
| VPMOVQ2M          | kreg,zmmreg                                 | [rm: evex.512.f3.0f38.w1 39 /r ]                | AVX512DQ                 |
| VPMOVQB           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 32 /r ]                | AVX512VL,AVX512          |
| VPMOVQB           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 32 /r ]                | AVX512VL,AVX512          |
| VPMOVQB           | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 32 /r ]                | AVX512                   |
| VPMOVQB           | mem16^mask,xmmreg                           | [mr:ovm: evex.128.f3.0f38.w0 32 /r ]            | AVX512VL,AVX512          |
| VPMOVQB           | mem32^mask,ymmreg                           | [mr:ovm: evex.256.f3.0f38.w0 32 /r ]            | AVX512VL,AVX512          |
| VPMOVQB           | mem64^mask,zmmreg                           | [mr:ovm: evex.512.f3.0f38.w0 32 /r ]            | AVX512                   |
| VPMOVQD           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 35 /r ]                | AVX512VL,AVX512          |
| VPMOVQD           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 35 /r ]                | AVX512VL,AVX512          |
| VPMOVQD           | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 35 /r ]                | AVX512                   |
| VPMOVQD           | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 35 /r ]            | AVX512VL,AVX512          |
| VPMOVQD           | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 35 /r ]            | AVX512VL,AVX512          |
| VPMOVQD           | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 35 /r ]            | AVX512                   |
| VPMOVQW           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 34 /r ]                | AVX512VL,AVX512          |
| VPMOVQW           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 34 /r ]                | AVX512VL,AVX512          |
| VPMOVQW           | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 34 /r ]                | AVX512                   |
| VPMOVQW           | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 34 /r ]            | AVX512VL,AVX512          |
| VPMOVQW           | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 34 /r ]            | AVX512VL,AVX512          |
| VPMOVQW           | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 34 /r ]            | AVX512                   |
| VPMOVSDB          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 21 /r ]                | AVX512VL,AVX512          |
| VPMOVSDB          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 21 /r ]                | AVX512VL,AVX512          |
| VPMOVSDB          | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 21 /r ]                | AVX512                   |
| VPMOVSDB          | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 21 /r ]            | AVX512VL,AVX512          |
| VPMOVSDB          | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 21 /r ]            | AVX512VL,AVX512          |
| VPMOVSDB          | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 21 /r ]            | AVX512                   |
| VPMOVSDW          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 23 /r ]                | AVX512VL,AVX512          |
| VPMOVSDW          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 23 /r ]                | AVX512VL,AVX512          |
| VPMOVSDW          | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 23 /r ]                | AVX512                   |
| VPMOVSDW          | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 23 /r ]            | AVX512VL,AVX512          |
| VPMOVSDW          | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 23 /r ]            | AVX512VL,AVX512          |
| VPMOVSDW          | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 23 /r ]            | AVX512                   |
| VPMOVSQB          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 22 /r ]                | AVX512VL,AVX512          |
| VPMOVSQB          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 22 /r ]                | AVX512VL,AVX512          |
| VPMOVSQB          | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 22 /r ]                | AVX512                   |
| VPMOVSQB          | mem16^mask,xmmreg                           | [mr:ovm: evex.128.f3.0f38.w0 22 /r ]            | AVX512VL,AVX512          |
| VPMOVSQB          | mem32^mask,ymmreg                           | [mr:ovm: evex.256.f3.0f38.w0 22 /r ]            | AVX512VL,AVX512          |
| VPMOVSQB          | mem64^mask,zmmreg                           | [mr:ovm: evex.512.f3.0f38.w0 22 /r ]            | AVX512                   |
| VPMOVSQD          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 25 /r ]                | AVX512VL,AVX512          |
| VPMOVSQD          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 25 /r ]                | AVX512VL,AVX512          |
| VPMOVSQD          | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 25 /r ]                | AVX512                   |
| VPMOVSQD          | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 25 /r ]            | AVX512VL,AVX512          |
| VPMOVSQD          | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 25 /r ]            | AVX512VL,AVX512          |
| VPMOVSQD          | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 25 /r ]            | AVX512                   |
| VPMOVSQW          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 24 /r ]                | AVX512VL,AVX512          |
| VPMOVSQW          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 24 /r ]                | AVX512VL,AVX512          |
| VPMOVSQW          | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 24 /r ]                | AVX512                   |
| VPMOVSQW          | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 24 /r ]            | AVX512VL,AVX512          |
| VPMOVSQW          | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 24 /r ]            | AVX512VL,AVX512          |
| VPMOVSQW          | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 24 /r ]            | AVX512                   |
| VPMOVSWB          | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 20 /r ]                | AVX512VL,AVX512BW        |
| VPMOVSWB          | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 20 /r ]                | AVX512VL,AVX512BW        |
| VPMOVSWB          | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 20 /r ]                | AVX512BW                 |
| VPMOVSWB          | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 20 /r ]            | AVX512VL,AVX512BW        |
| VPMOVSWB          | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 20 /r ]            | AVX512VL,AVX512BW        |
| VPMOVSWB          | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 20 /r ]            | AVX512BW                 |
| VPMOVSXBD         | xmmreg^mask^z,xmmrm32                       | [rm:qvm: evex.128.66.0f38.wig 21 /r ]           | AVX512VL,AVX512          |
| VPMOVSXBD         | ymmreg^mask^z,xmmrm64                       | [rm:qvm: evex.256.66.0f38.wig 21 /r ]           | AVX512VL,AVX512          |
| VPMOVSXBD         | zmmreg^mask^z,xmmrm128                      | [rm:qvm: evex.512.66.0f38.wig 21 /r ]           | AVX512                   |
| VPMOVSXBQ         | xmmreg^mask^z,xmmrm16                       | [rm:ovm: evex.128.66.0f38.wig 22 /r ]           | AVX512VL,AVX512          |
| VPMOVSXBQ         | ymmreg^mask^z,xmmrm32                       | [rm:ovm: evex.256.66.0f38.wig 22 /r ]           | AVX512VL,AVX512          |
| VPMOVSXBQ         | zmmreg^mask^z,xmmrm64                       | [rm:ovm: evex.512.66.0f38.wig 22 /r ]           | AVX512                   |
| VPMOVSXBW         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.wig 20 /r ]           | AVX512VL,AVX512BW        |
| VPMOVSXBW         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.wig 20 /r ]           | AVX512VL,AVX512BW        |
| VPMOVSXBW         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.wig 20 /r ]           | AVX512BW                 |
| VPMOVSXDQ         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.w0 25 /r ]            | AVX512VL,AVX512          |
| VPMOVSXDQ         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.w0 25 /r ]            | AVX512VL,AVX512          |
| VPMOVSXDQ         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.w0 25 /r ]            | AVX512                   |
| VPMOVSXWD         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.wig 23 /r ]           | AVX512VL,AVX512          |
| VPMOVSXWD         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.wig 23 /r ]           | AVX512VL,AVX512          |
| VPMOVSXWD         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.wig 23 /r ]           | AVX512                   |
| VPMOVSXWQ         | xmmreg^mask^z,xmmrm32                       | [rm:qvm: evex.128.66.0f38.wig 24 /r ]           | AVX512VL,AVX512          |
| VPMOVSXWQ         | ymmreg^mask^z,xmmrm64                       | [rm:qvm: evex.256.66.0f38.wig 24 /r ]           | AVX512VL,AVX512          |
| VPMOVSXWQ         | zmmreg^mask^z,xmmrm128                      | [rm:qvm: evex.512.66.0f38.wig 24 /r ]           | AVX512                   |
| VPMOVUSDB         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 11 /r ]                | AVX512VL,AVX512          |
| VPMOVUSDB         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 11 /r ]                | AVX512VL,AVX512          |
| VPMOVUSDB         | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 11 /r ]                | AVX512                   |
| VPMOVUSDB         | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 11 /r ]            | AVX512VL,AVX512          |
| VPMOVUSDB         | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 11 /r ]            | AVX512VL,AVX512          |
| VPMOVUSDB         | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 11 /r ]            | AVX512                   |
| VPMOVUSDW         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 13 /r ]                | AVX512VL,AVX512          |
| VPMOVUSDW         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 13 /r ]                | AVX512VL,AVX512          |
| VPMOVUSDW         | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 13 /r ]                | AVX512                   |
| VPMOVUSDW         | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 13 /r ]            | AVX512VL,AVX512          |
| VPMOVUSDW         | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 13 /r ]            | AVX512VL,AVX512          |
| VPMOVUSDW         | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 13 /r ]            | AVX512                   |
| VPMOVUSQB         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 12 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQB         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 12 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQB         | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 12 /r ]                | AVX512                   |
| VPMOVUSQB         | mem16^mask,xmmreg                           | [mr:ovm: evex.128.f3.0f38.w0 12 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQB         | mem32^mask,ymmreg                           | [mr:ovm: evex.256.f3.0f38.w0 12 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQB         | mem64^mask,zmmreg                           | [mr:ovm: evex.512.f3.0f38.w0 12 /r ]            | AVX512                   |
| VPMOVUSQD         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 15 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQD         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 15 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQD         | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 15 /r ]                | AVX512                   |
| VPMOVUSQD         | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 15 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQD         | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 15 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQD         | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 15 /r ]            | AVX512                   |
| VPMOVUSQW         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 14 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQW         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 14 /r ]                | AVX512VL,AVX512          |
| VPMOVUSQW         | xmmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 14 /r ]                | AVX512                   |
| VPMOVUSQW         | mem32^mask,xmmreg                           | [mr:qvm: evex.128.f3.0f38.w0 14 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQW         | mem64^mask,ymmreg                           | [mr:qvm: evex.256.f3.0f38.w0 14 /r ]            | AVX512VL,AVX512          |
| VPMOVUSQW         | mem128^mask,zmmreg                          | [mr:qvm: evex.512.f3.0f38.w0 14 /r ]            | AVX512                   |
| VPMOVUSWB         | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 10 /r ]                | AVX512VL,AVX512BW        |
| VPMOVUSWB         | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 10 /r ]                | AVX512VL,AVX512BW        |
| VPMOVUSWB         | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 10 /r ]                | AVX512BW                 |
| VPMOVUSWB         | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 10 /r ]            | AVX512VL,AVX512BW        |
| VPMOVUSWB         | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 10 /r ]            | AVX512VL,AVX512BW        |
| VPMOVUSWB         | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 10 /r ]            | AVX512BW                 |
| VPMOVW2M          | kreg,xmmreg                                 | [rm: evex.128.f3.0f38.w1 29 /r ]                | AVX512VL,AVX512BW        |
| VPMOVW2M          | kreg,ymmreg                                 | [rm: evex.256.f3.0f38.w1 29 /r ]                | AVX512VL,AVX512BW        |
| VPMOVW2M          | kreg,zmmreg                                 | [rm: evex.512.f3.0f38.w1 29 /r ]                | AVX512BW                 |
| VPMOVWB           | xmmreg^mask^z,xmmreg                        | [mr: evex.128.f3.0f38.w0 30 /r ]                | AVX512VL,AVX512BW        |
| VPMOVWB           | xmmreg^mask^z,ymmreg                        | [mr: evex.256.f3.0f38.w0 30 /r ]                | AVX512VL,AVX512BW        |
| VPMOVWB           | ymmreg^mask^z,zmmreg                        | [mr: evex.512.f3.0f38.w0 30 /r ]                | AVX512BW                 |
| VPMOVWB           | mem64^mask,xmmreg                           | [mr:hvm: evex.128.f3.0f38.w0 30 /r ]            | AVX512VL,AVX512BW        |
| VPMOVWB           | mem128^mask,ymmreg                          | [mr:hvm: evex.256.f3.0f38.w0 30 /r ]            | AVX512VL,AVX512BW        |
| VPMOVWB           | mem256^mask,zmmreg                          | [mr:hvm: evex.512.f3.0f38.w0 30 /r ]            | AVX512BW                 |
| VPMOVZXBD         | xmmreg^mask^z,xmmrm32                       | [rm:qvm: evex.128.66.0f38.wig 31 /r ]           | AVX512VL,AVX512          |
| VPMOVZXBD         | ymmreg^mask^z,xmmrm64                       | [rm:qvm: evex.256.66.0f38.wig 31 /r ]           | AVX512VL,AVX512          |
| VPMOVZXBD         | zmmreg^mask^z,xmmrm128                      | [rm:qvm: evex.512.66.0f38.wig 31 /r ]           | AVX512                   |
| VPMOVZXBQ         | xmmreg^mask^z,xmmrm16                       | [rm:ovm: evex.128.66.0f38.wig 32 /r ]           | AVX512VL,AVX512          |
| VPMOVZXBQ         | ymmreg^mask^z,xmmrm32                       | [rm:ovm: evex.256.66.0f38.wig 32 /r ]           | AVX512VL,AVX512          |
| VPMOVZXBQ         | zmmreg^mask^z,xmmrm64                       | [rm:ovm: evex.512.66.0f38.wig 32 /r ]           | AVX512                   |
| VPMOVZXBW         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.wig 30 /r ]           | AVX512VL,AVX512BW        |
| VPMOVZXBW         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.wig 30 /r ]           | AVX512VL,AVX512BW        |
| VPMOVZXBW         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.wig 30 /r ]           | AVX512BW                 |
| VPMOVZXDQ         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.w0 35 /r ]            | AVX512VL,AVX512          |
| VPMOVZXDQ         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.w0 35 /r ]            | AVX512VL,AVX512          |
| VPMOVZXDQ         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.w0 35 /r ]            | AVX512                   |
| VPMOVZXWD         | xmmreg^mask^z,xmmrm64                       | [rm:hvm: evex.128.66.0f38.wig 33 /r ]           | AVX512VL,AVX512          |
| VPMOVZXWD         | ymmreg^mask^z,xmmrm128                      | [rm:hvm: evex.256.66.0f38.wig 33 /r ]           | AVX512VL,AVX512          |
| VPMOVZXWD         | zmmreg^mask^z,ymmrm256                      | [rm:hvm: evex.512.66.0f38.wig 33 /r ]           | AVX512                   |
| VPMOVZXWQ         | xmmreg^mask^z,xmmrm32                       | [rm:qvm: evex.128.66.0f38.wig 34 /r ]           | AVX512VL,AVX512          |
| VPMOVZXWQ         | ymmreg^mask^z,xmmrm64                       | [rm:qvm: evex.256.66.0f38.wig 34 /r ]           | AVX512VL,AVX512          |
| VPMOVZXWQ         | zmmreg^mask^z,xmmrm128                      | [rm:qvm: evex.512.66.0f38.wig 34 /r ]           | AVX512                   |
| VPMULDQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 28 /r ]        | AVX512VL,AVX512          |
| VPMULDQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 28 /r ]        | AVX512VL,AVX512          |
| VPMULDQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 28 /r ]        | AVX512                   |
| VPMULHRSW         | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 0b /r ]      | AVX512VL,AVX512BW        |
| VPMULHRSW         | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 0b /r ]      | AVX512VL,AVX512BW        |
| VPMULHRSW         | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 0b /r ]      | AVX512BW                 |
| VPMULHUW          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e4 /r ]        | AVX512VL,AVX512BW        |
| VPMULHUW          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e4 /r ]        | AVX512VL,AVX512BW        |
| VPMULHUW          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e4 /r ]        | AVX512BW                 |
| VPMULHW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e5 /r ]        | AVX512VL,AVX512BW        |
| VPMULHW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e5 /r ]        | AVX512VL,AVX512BW        |
| VPMULHW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e5 /r ]        | AVX512BW                 |
| VPMULLD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 40 /r ]        | AVX512VL,AVX512          |
| VPMULLD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 40 /r ]        | AVX512VL,AVX512          |
| VPMULLD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 40 /r ]        | AVX512                   |
| VPMULLQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 40 /r ]        | AVX512VL,AVX512DQ        |
| VPMULLQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 40 /r ]        | AVX512VL,AVX512DQ        |
| VPMULLQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 40 /r ]        | AVX512DQ                 |
| VPMULLW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig d5 /r ]        | AVX512VL,AVX512BW        |
| VPMULLW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig d5 /r ]        | AVX512VL,AVX512BW        |
| VPMULLW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig d5 /r ]        | AVX512BW                 |
| VPMULTISHIFTQB    | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 83 /r ]        | AVX512VL,AVX512VBMI      |
| VPMULTISHIFTQB    | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 83 /r ]        | AVX512VL,AVX512VBMI      |
| VPMULTISHIFTQB    | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 83 /r ]        | AVX512VBMI               |
| VPMULUDQ          | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 f4 /r ]          | AVX512VL,AVX512          |
| VPMULUDQ          | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 f4 /r ]          | AVX512VL,AVX512          |
| VPMULUDQ          | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 f4 /r ]          | AVX512                   |
| VPORD             | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 eb /r ]          | AVX512VL,AVX512          |
| VPORD             | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 eb /r ]          | AVX512VL,AVX512          |
| VPORD             | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 eb /r ]          | AVX512                   |
| VPORQ             | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 eb /r ]          | AVX512VL,AVX512          |
| VPORQ             | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 eb /r ]          | AVX512VL,AVX512          |
| VPORQ             | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 eb /r ]          | AVX512                   |
| VPROLD            | xmmreg^mask^z,xmmrm128^b32*,imm8            | [vmi:fv: evex.nds.128.66.0f.w0 72 /1 ib ]       | AVX512VL,AVX512          |
| VPROLD            | ymmreg^mask^z,ymmrm256^b32*,imm8            | [vmi:fv: evex.nds.256.66.0f.w0 72 /1 ib ]       | AVX512VL,AVX512          |
| VPROLD            | zmmreg^mask^z,zmmrm512^b32*,imm8            | [vmi:fv: evex.nds.512.66.0f.w0 72 /1 ib ]       | AVX512                   |
| VPROLQ            | xmmreg^mask^z,xmmrm128^b64*,imm8            | [vmi:fv: evex.nds.128.66.0f.w1 72 /1 ib ]       | AVX512VL,AVX512          |
| VPROLQ            | ymmreg^mask^z,ymmrm256^b64*,imm8            | [vmi:fv: evex.nds.256.66.0f.w1 72 /1 ib ]       | AVX512VL,AVX512          |
| VPROLQ            | zmmreg^mask^z,zmmrm512^b64*,imm8            | [vmi:fv: evex.nds.512.66.0f.w1 72 /1 ib ]       | AVX512                   |
| VPROLVD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 15 /r ]        | AVX512VL,AVX512          |
| VPROLVD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 15 /r ]        | AVX512VL,AVX512          |
| VPROLVD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 15 /r ]        | AVX512                   |
| VPROLVQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 15 /r ]        | AVX512VL,AVX512          |
| VPROLVQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 15 /r ]        | AVX512VL,AVX512          |
| VPROLVQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 15 /r ]        | AVX512                   |
| VPRORD            | xmmreg^mask^z,xmmrm128^b32*,imm8            | [vmi:fv: evex.nds.128.66.0f.w0 72 /0 ib ]       | AVX512VL,AVX512          |
| VPRORD            | ymmreg^mask^z,ymmrm256^b32*,imm8            | [vmi:fv: evex.nds.256.66.0f.w0 72 /0 ib ]       | AVX512VL,AVX512          |
| VPRORD            | zmmreg^mask^z,zmmrm512^b32*,imm8            | [vmi:fv: evex.nds.512.66.0f.w0 72 /0 ib ]       | AVX512                   |
| VPRORQ            | xmmreg^mask^z,xmmrm128^b64*,imm8            | [vmi:fv: evex.nds.128.66.0f.w1 72 /0 ib ]       | AVX512VL,AVX512          |
| VPRORQ            | ymmreg^mask^z,ymmrm256^b64*,imm8            | [vmi:fv: evex.nds.256.66.0f.w1 72 /0 ib ]       | AVX512VL,AVX512          |
| VPRORQ            | zmmreg^mask^z,zmmrm512^b64*,imm8            | [vmi:fv: evex.nds.512.66.0f.w1 72 /0 ib ]       | AVX512                   |
| VPRORVD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 14 /r ]        | AVX512VL,AVX512          |
| VPRORVD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 14 /r ]        | AVX512VL,AVX512          |
| VPRORVD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 14 /r ]        | AVX512                   |
| VPRORVQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 14 /r ]        | AVX512VL,AVX512          |
| VPRORVQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 14 /r ]        | AVX512VL,AVX512          |
| VPRORVQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 14 /r ]        | AVX512                   |
| VPSADBW           | xmmreg,xmmreg*,xmmrm128                     | [rvm:fvm: evex.nds.128.66.0f.wig f6 /r ]        | AVX512VL,AVX512BW        |
| VPSADBW           | ymmreg,ymmreg*,ymmrm256                     | [rvm:fvm: evex.nds.256.66.0f.wig f6 /r ]        | AVX512VL,AVX512BW        |
| VPSADBW           | zmmreg,zmmreg*,zmmrm512                     | [rvm:fvm: evex.nds.512.66.0f.wig f6 /r ]        | AVX512BW                 |
| VPSCATTERDD       | xmem32^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w0 a0 /r ]      | AVX512VL,AVX512          |
| VPSCATTERDD       | ymem32^mask,ymmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w0 a0 /r ]      | AVX512VL,AVX512          |
| VPSCATTERDD       | zmem32^mask,zmmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w0 a0 /r ]      | AVX512                   |
| VPSCATTERDQ       | xmem64^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w1 a0 /r ]      | AVX512VL,AVX512          |
| VPSCATTERDQ       | xmem64^mask,ymmreg                          | [mr:t1s: vsibx evex.256.66.0f38.w1 a0 /r ]      | AVX512VL,AVX512          |
| VPSCATTERDQ       | ymem64^mask,zmmreg                          | [mr:t1s: vsiby evex.512.66.0f38.w1 a0 /r ]      | AVX512                   |
| VPSCATTERQD       | xmem32^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w0 a1 /r ]      | AVX512VL,AVX512          |
| VPSCATTERQD       | ymem32^mask,xmmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w0 a1 /r ]      | AVX512VL,AVX512          |
| VPSCATTERQD       | zmem32^mask,ymmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w0 a1 /r ]      | AVX512                   |
| VPSCATTERQQ       | xmem64^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w1 a1 /r ]      | AVX512VL,AVX512          |
| VPSCATTERQQ       | ymem64^mask,ymmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w1 a1 /r ]      | AVX512VL,AVX512          |
| VPSCATTERQQ       | zmem64^mask,zmmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w1 a1 /r ]      | AVX512                   |
| VPSHUFB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.wig 00 /r ]      | AVX512VL,AVX512BW        |
| VPSHUFB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.wig 00 /r ]      | AVX512VL,AVX512BW        |
| VPSHUFB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.wig 00 /r ]      | AVX512BW                 |
| VPSHUFD           | xmmreg^mask^z,xmmrm128^b32,imm8             | [rmi:fv: evex.128.66.0f.w0 70 /r ib ]           | AVX512VL,AVX512          |
| VPSHUFD           | ymmreg^mask^z,ymmrm256^b32,imm8             | [rmi:fv: evex.256.66.0f.w0 70 /r ib ]           | AVX512VL,AVX512          |
| VPSHUFD           | zmmreg^mask^z,zmmrm512^b32,imm8             | [rmi:fv: evex.512.66.0f.w0 70 /r ib ]           | AVX512                   |
| VPSHUFHW          | xmmreg^mask^z,xmmrm128,imm8                 | [rmi:fvm: evex.128.f3.0f.wig 70 /r ib ]         | AVX512VL,AVX512BW        |
| VPSHUFHW          | ymmreg^mask^z,ymmrm256,imm8                 | [rmi:fvm: evex.256.f3.0f.wig 70 /r ib ]         | AVX512VL,AVX512BW        |
| VPSHUFHW          | zmmreg^mask^z,zmmrm512,imm8                 | [rmi:fvm: evex.512.f3.0f.wig 70 /r ib ]         | AVX512BW                 |
| VPSHUFLW          | xmmreg^mask^z,xmmrm128,imm8                 | [rmi:fvm: evex.128.f2.0f.wig 70 /r ib ]         | AVX512VL,AVX512BW        |
| VPSHUFLW          | ymmreg^mask^z,ymmrm256,imm8                 | [rmi:fvm: evex.256.f2.0f.wig 70 /r ib ]         | AVX512VL,AVX512BW        |
| VPSHUFLW          | zmmreg^mask^z,zmmrm512,imm8                 | [rmi:fvm: evex.512.f2.0f.wig 70 /r ib ]         | AVX512BW                 |
| VPSLLD            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w0 f2 /r ]        | AVX512VL,AVX512          |
| VPSLLD            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w0 f2 /r ]        | AVX512VL,AVX512          |
| VPSLLD            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w0 f2 /r ]        | AVX512                   |
| VPSLLD            | xmmreg^mask^z,xmmrm128^b32*,imm8            | [vmi:fv: evex.nds.128.66.0f.w0 72 /6 ib ]       | AVX512VL,AVX512          |
| VPSLLD            | ymmreg^mask^z,ymmrm256^b32*,imm8            | [vmi:fv: evex.nds.256.66.0f.w0 72 /6 ib ]       | AVX512VL,AVX512          |
| VPSLLD            | zmmreg^mask^z,zmmrm512^b32*,imm8            | [vmi:fv: evex.nds.512.66.0f.w0 72 /6 ib ]       | AVX512                   |
| VPSLLDQ           | xmmreg,xmmrm128*,imm8                       | [vmi:fvm: evex.nds.128.66.0f.wig 73 /7 ib ]     | AVX512VL,AVX512BW        |
| VPSLLDQ           | ymmreg,ymmrm256*,imm8                       | [vmi:fvm: evex.nds.256.66.0f.wig 73 /7 ib ]     | AVX512VL,AVX512BW        |
| VPSLLDQ           | zmmreg,zmmrm512*,imm8                       | [vmi:fvm: evex.nds.512.66.0f.wig 73 /7 ib ]     | AVX512BW                 |
| VPSLLQ            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w1 f3 /r ]        | AVX512VL,AVX512          |
| VPSLLQ            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w1 f3 /r ]        | AVX512VL,AVX512          |
| VPSLLQ            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w1 f3 /r ]        | AVX512                   |
| VPSLLQ            | xmmreg^mask^z,xmmrm128^b64*,imm8            | [vmi:fv: evex.nds.128.66.0f.w1 73 /6 ib ]       | AVX512VL,AVX512          |
| VPSLLQ            | ymmreg^mask^z,ymmrm256^b64*,imm8            | [vmi:fv: evex.nds.256.66.0f.w1 73 /6 ib ]       | AVX512VL,AVX512          |
| VPSLLQ            | zmmreg^mask^z,zmmrm512^b64*,imm8            | [vmi:fv: evex.nds.512.66.0f.w1 73 /6 ib ]       | AVX512                   |
| VPSLLVD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 47 /r ]        | AVX512VL,AVX512          |
| VPSLLVD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 47 /r ]        | AVX512VL,AVX512          |
| VPSLLVD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 47 /r ]        | AVX512                   |
| VPSLLVQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 47 /r ]        | AVX512VL,AVX512          |
| VPSLLVQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 47 /r ]        | AVX512VL,AVX512          |
| VPSLLVQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 47 /r ]        | AVX512                   |
| VPSLLVW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w1 12 /r ]       | AVX512VL,AVX512BW        |
| VPSLLVW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w1 12 /r ]       | AVX512VL,AVX512BW        |
| VPSLLVW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w1 12 /r ]       | AVX512BW                 |
| VPSLLW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.wig f1 /r ]       | AVX512VL,AVX512BW        |
| VPSLLW            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.wig f1 /r ]       | AVX512VL,AVX512BW        |
| VPSLLW            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.wig f1 /r ]       | AVX512BW                 |
| VPSLLW            | xmmreg^mask^z,xmmrm128*,imm8                | [vmi:fvm: evex.nds.128.66.0f.wig 71 /6 ib ]     | AVX512VL,AVX512BW        |
| VPSLLW            | ymmreg^mask^z,ymmrm256*,imm8                | [vmi:fvm: evex.nds.256.66.0f.wig 71 /6 ib ]     | AVX512VL,AVX512BW        |
| VPSLLW            | zmmreg^mask^z,zmmrm512*,imm8                | [vmi:fvm: evex.nds.512.66.0f.wig 71 /6 ib ]     | AVX512BW                 |
| VPSRAD            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w0 e2 /r ]        | AVX512VL,AVX512          |
| VPSRAD            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w0 e2 /r ]        | AVX512VL,AVX512          |
| VPSRAD            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w0 e2 /r ]        | AVX512                   |
| VPSRAD            | xmmreg^mask^z,xmmrm128^b32*,imm8            | [vmi:fv: evex.nds.128.66.0f.w0 72 /4 ib ]       | AVX512VL,AVX512          |
| VPSRAD            | ymmreg^mask^z,ymmrm256^b32*,imm8            | [vmi:fv: evex.nds.256.66.0f.w0 72 /4 ib ]       | AVX512VL,AVX512          |
| VPSRAD            | zmmreg^mask^z,zmmrm512^b32*,imm8            | [vmi:fv: evex.nds.512.66.0f.w0 72 /4 ib ]       | AVX512                   |
| VPSRAQ            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w1 e2 /r ]        | AVX512VL,AVX512          |
| VPSRAQ            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w1 e2 /r ]        | AVX512VL,AVX512          |
| VPSRAQ            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w1 e2 /r ]        | AVX512                   |
| VPSRAQ            | xmmreg^mask^z,xmmrm128^b64*,imm8            | [vmi:fv: evex.nds.128.66.0f.w1 72 /4 ib ]       | AVX512VL,AVX512          |
| VPSRAQ            | ymmreg^mask^z,ymmrm256^b64*,imm8            | [vmi:fv: evex.nds.256.66.0f.w1 72 /4 ib ]       | AVX512VL,AVX512          |
| VPSRAQ            | zmmreg^mask^z,zmmrm512^b64*,imm8            | [vmi:fv: evex.nds.512.66.0f.w1 72 /4 ib ]       | AVX512                   |
| VPSRAVD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 46 /r ]        | AVX512VL,AVX512          |
| VPSRAVD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 46 /r ]        | AVX512VL,AVX512          |
| VPSRAVD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 46 /r ]        | AVX512                   |
| VPSRAVQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 46 /r ]        | AVX512VL,AVX512          |
| VPSRAVQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 46 /r ]        | AVX512VL,AVX512          |
| VPSRAVQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 46 /r ]        | AVX512                   |
| VPSRAVW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w1 11 /r ]       | AVX512VL,AVX512BW        |
| VPSRAVW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w1 11 /r ]       | AVX512VL,AVX512BW        |
| VPSRAVW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w1 11 /r ]       | AVX512BW                 |
| VPSRAW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.wig e1 /r ]       | AVX512VL,AVX512BW        |
| VPSRAW            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.wig e1 /r ]       | AVX512VL,AVX512BW        |
| VPSRAW            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.wig e1 /r ]       | AVX512BW                 |
| VPSRAW            | xmmreg^mask^z,xmmrm128*,imm8                | [vmi:fvm: evex.nds.128.66.0f.wig 71 /4 ib ]     | AVX512VL,AVX512BW        |
| VPSRAW            | ymmreg^mask^z,ymmrm256*,imm8                | [vmi:fvm: evex.nds.256.66.0f.wig 71 /4 ib ]     | AVX512VL,AVX512BW        |
| VPSRAW            | zmmreg^mask^z,zmmrm512*,imm8                | [vmi:fvm: evex.nds.512.66.0f.wig 71 /4 ib ]     | AVX512BW                 |
| VPSRLD            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w0 d2 /r ]        | AVX512VL,AVX512          |
| VPSRLD            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w0 d2 /r ]        | AVX512VL,AVX512          |
| VPSRLD            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w0 d2 /r ]        | AVX512                   |
| VPSRLD            | xmmreg^mask^z,xmmrm128^b32*,imm8            | [vmi:fv: evex.nds.128.66.0f.w0 72 /2 ib ]       | AVX512VL,AVX512          |
| VPSRLD            | ymmreg^mask^z,ymmrm256^b32*,imm8            | [vmi:fv: evex.nds.256.66.0f.w0 72 /2 ib ]       | AVX512VL,AVX512          |
| VPSRLD            | zmmreg^mask^z,zmmrm512^b32*,imm8            | [vmi:fv: evex.nds.512.66.0f.w0 72 /2 ib ]       | AVX512                   |
| VPSRLDQ           | xmmreg,xmmrm128*,imm8                       | [vmi:fvm: evex.nds.128.66.0f.wig 73 /3 ib ]     | AVX512VL,AVX512BW        |
| VPSRLDQ           | ymmreg,ymmrm256*,imm8                       | [vmi:fvm: evex.nds.256.66.0f.wig 73 /3 ib ]     | AVX512VL,AVX512BW        |
| VPSRLDQ           | zmmreg,zmmrm512*,imm8                       | [vmi:fvm: evex.nds.512.66.0f.wig 73 /3 ib ]     | AVX512BW                 |
| VPSRLQ            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.w1 d3 /r ]        | AVX512VL,AVX512          |
| VPSRLQ            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.w1 d3 /r ]        | AVX512VL,AVX512          |
| VPSRLQ            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.w1 d3 /r ]        | AVX512                   |
| VPSRLQ            | xmmreg^mask^z,xmmrm128^b64*,imm8            | [vmi:fv: evex.nds.128.66.0f.w1 73 /2 ib ]       | AVX512VL,AVX512          |
| VPSRLQ            | ymmreg^mask^z,ymmrm256^b64*,imm8            | [vmi:fv: evex.nds.256.66.0f.w1 73 /2 ib ]       | AVX512VL,AVX512          |
| VPSRLQ            | zmmreg^mask^z,zmmrm512^b64*,imm8            | [vmi:fv: evex.nds.512.66.0f.w1 73 /2 ib ]       | AVX512                   |
| VPSRLVD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 45 /r ]        | AVX512VL,AVX512          |
| VPSRLVD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 45 /r ]        | AVX512VL,AVX512          |
| VPSRLVD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f38.w0 45 /r ]        | AVX512                   |
| VPSRLVQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 45 /r ]        | AVX512VL,AVX512          |
| VPSRLVQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 45 /r ]        | AVX512VL,AVX512          |
| VPSRLVQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f38.w1 45 /r ]        | AVX512                   |
| VPSRLVW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w1 10 /r ]       | AVX512VL,AVX512BW        |
| VPSRLVW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w1 10 /r ]       | AVX512VL,AVX512BW        |
| VPSRLVW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w1 10 /r ]       | AVX512BW                 |
| VPSRLW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:m128: evex.nds.128.66.0f.wig d1 /r ]       | AVX512VL,AVX512BW        |
| VPSRLW            | ymmreg^mask^z,ymmreg*,xmmrm128              | [rvm:m128: evex.nds.256.66.0f.wig d1 /r ]       | AVX512VL,AVX512BW        |
| VPSRLW            | zmmreg^mask^z,zmmreg*,xmmrm128              | [rvm:m128: evex.nds.512.66.0f.wig d1 /r ]       | AVX512BW                 |
| VPSRLW            | xmmreg^mask^z,xmmrm128*,imm8                | [vmi:fvm: evex.nds.128.66.0f.wig 71 /2 ib ]     | AVX512VL,AVX512BW        |
| VPSRLW            | ymmreg^mask^z,ymmrm256*,imm8                | [vmi:fvm: evex.nds.256.66.0f.wig 71 /2 ib ]     | AVX512VL,AVX512BW        |
| VPSRLW            | zmmreg^mask^z,zmmrm512*,imm8                | [vmi:fvm: evex.nds.512.66.0f.wig 71 /2 ib ]     | AVX512BW                 |
| VPSUBB            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig f8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBB            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig f8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBB            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig f8 /r ]        | AVX512BW                 |
| VPSUBD            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 fa /r ]          | AVX512VL,AVX512          |
| VPSUBD            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 fa /r ]          | AVX512VL,AVX512          |
| VPSUBD            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 fa /r ]          | AVX512                   |
| VPSUBQ            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 fb /r ]          | AVX512VL,AVX512          |
| VPSUBQ            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 fb /r ]          | AVX512VL,AVX512          |
| VPSUBQ            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 fb /r ]          | AVX512                   |
| VPSUBSB           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBSB           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBSB           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e8 /r ]        | AVX512BW                 |
| VPSUBSW           | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig e9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBSW           | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig e9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBSW           | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig e9 /r ]        | AVX512BW                 |
| VPSUBUSB          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig d8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBUSB          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig d8 /r ]        | AVX512VL,AVX512BW        |
| VPSUBUSB          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig d8 /r ]        | AVX512BW                 |
| VPSUBUSW          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig d9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBUSW          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig d9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBUSW          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig d9 /r ]        | AVX512BW                 |
| VPSUBW            | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig f9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBW            | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig f9 /r ]        | AVX512VL,AVX512BW        |
| VPSUBW            | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig f9 /r ]        | AVX512BW                 |
| VPTERNLOGD        | xmmreg^mask^z,xmmreg,xmmrm128^b32,imm8      | [rvmi:fv: evex.nds.128.66.0f3a.w0 25 /r ib ]    | AVX512VL,AVX512          |
| VPTERNLOGD        | ymmreg^mask^z,ymmreg,ymmrm256^b32,imm8      | [rvmi:fv: evex.nds.256.66.0f3a.w0 25 /r ib ]    | AVX512VL,AVX512          |
| VPTERNLOGD        | zmmreg^mask^z,zmmreg,zmmrm512^b32,imm8      | [rvmi:fv: evex.nds.512.66.0f3a.w0 25 /r ib ]    | AVX512                   |
| VPTERNLOGQ        | xmmreg^mask^z,xmmreg,xmmrm128^b64,imm8      | [rvmi:fv: evex.nds.128.66.0f3a.w1 25 /r ib ]    | AVX512VL,AVX512          |
| VPTERNLOGQ        | ymmreg^mask^z,ymmreg,ymmrm256^b64,imm8      | [rvmi:fv: evex.nds.256.66.0f3a.w1 25 /r ib ]    | AVX512VL,AVX512          |
| VPTERNLOGQ        | zmmreg^mask^z,zmmreg,zmmrm512^b64,imm8      | [rvmi:fv: evex.nds.512.66.0f3a.w1 25 /r ib ]    | AVX512                   |
| VPTESTMB          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f38.w0 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTMB          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f38.w0 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTMB          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f38.w0 26 /r ]       | AVX512BW                 |
| VPTESTMD          | kreg^mask,xmmreg,xmmrm128^b32               | [rvm:fv: evex.nds.128.66.0f38.w0 27 /r ]        | AVX512VL,AVX512          |
| VPTESTMD          | kreg^mask,ymmreg,ymmrm256^b32               | [rvm:fv: evex.nds.256.66.0f38.w0 27 /r ]        | AVX512VL,AVX512          |
| VPTESTMD          | kreg^mask,zmmreg,zmmrm512^b32               | [rvm:fv: evex.nds.512.66.0f38.w0 27 /r ]        | AVX512                   |
| VPTESTMQ          | kreg^mask,xmmreg,xmmrm128^b64               | [rvm:fv: evex.nds.128.66.0f38.w1 27 /r ]        | AVX512VL,AVX512          |
| VPTESTMQ          | kreg^mask,ymmreg,ymmrm256^b64               | [rvm:fv: evex.nds.256.66.0f38.w1 27 /r ]        | AVX512VL,AVX512          |
| VPTESTMQ          | kreg^mask,zmmreg,zmmrm512^b64               | [rvm:fv: evex.nds.512.66.0f38.w1 27 /r ]        | AVX512                   |
| VPTESTMW          | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f38.w1 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTMW          | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f38.w1 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTMW          | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f38.w1 26 /r ]       | AVX512BW                 |
| VPTESTNMB         | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.f3.0f38.w0 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTNMB         | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.f3.0f38.w0 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTNMB         | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.f3.0f38.w0 26 /r ]       | AVX512BW                 |
| VPTESTNMD         | kreg^mask,xmmreg,xmmrm128^b32               | [rvm:fv: evex.nds.128.f3.0f38.w0 27 /r ]        | AVX512VL,AVX512          |
| VPTESTNMD         | kreg^mask,ymmreg,ymmrm256^b32               | [rvm:fv: evex.nds.256.f3.0f38.w0 27 /r ]        | AVX512VL,AVX512          |
| VPTESTNMD         | kreg^mask,zmmreg,zmmrm512^b32               | [rvm:fv: evex.nds.512.f3.0f38.w0 27 /r ]        | AVX512                   |
| VPTESTNMQ         | kreg^mask,xmmreg,xmmrm128^b64               | [rvm:fv: evex.nds.128.f3.0f38.w1 27 /r ]        | AVX512VL,AVX512          |
| VPTESTNMQ         | kreg^mask,ymmreg,ymmrm256^b64               | [rvm:fv: evex.nds.256.f3.0f38.w1 27 /r ]        | AVX512VL,AVX512          |
| VPTESTNMQ         | kreg^mask,zmmreg,zmmrm512^b64               | [rvm:fv: evex.nds.512.f3.0f38.w1 27 /r ]        | AVX512                   |
| VPTESTNMW         | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.f3.0f38.w1 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTNMW         | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.f3.0f38.w1 26 /r ]       | AVX512VL,AVX512BW        |
| VPTESTNMW         | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.f3.0f38.w1 26 /r ]       | AVX512BW                 |
| VPUNPCKHBW        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 68 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKHBW        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 68 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKHBW        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 68 /r ]        | AVX512BW                 |
| VPUNPCKHDQ        | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 6a /r ]          | AVX512VL,AVX512          |
| VPUNPCKHDQ        | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 6a /r ]          | AVX512VL,AVX512          |
| VPUNPCKHDQ        | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 6a /r ]          | AVX512                   |
| VPUNPCKHQDQ       | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 6d /r ]          | AVX512VL,AVX512          |
| VPUNPCKHQDQ       | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 6d /r ]          | AVX512VL,AVX512          |
| VPUNPCKHQDQ       | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 6d /r ]          | AVX512                   |
| VPUNPCKHWD        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 69 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKHWD        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 69 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKHWD        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 69 /r ]        | AVX512BW                 |
| VPUNPCKLBW        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 60 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKLBW        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 60 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKLBW        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 60 /r ]        | AVX512BW                 |
| VPUNPCKLDQ        | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 62 /r ]          | AVX512VL,AVX512          |
| VPUNPCKLDQ        | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 62 /r ]          | AVX512VL,AVX512          |
| VPUNPCKLDQ        | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 62 /r ]          | AVX512                   |
| VPUNPCKLQDQ       | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 6c /r ]          | AVX512VL,AVX512          |
| VPUNPCKLQDQ       | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 6c /r ]          | AVX512VL,AVX512          |
| VPUNPCKLQDQ       | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 6c /r ]          | AVX512                   |
| VPUNPCKLWD        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f.wig 61 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKLWD        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f.wig 61 /r ]        | AVX512VL,AVX512BW        |
| VPUNPCKLWD        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f.wig 61 /r ]        | AVX512BW                 |
| VPXORD            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f.w0 ef /r ]          | AVX512VL,AVX512          |
| VPXORD            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f.w0 ef /r ]          | AVX512VL,AVX512          |
| VPXORD            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.66.0f.w0 ef /r ]          | AVX512                   |
| VPXORQ            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 ef /r ]          | AVX512VL,AVX512          |
| VPXORQ            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 ef /r ]          | AVX512VL,AVX512          |
| VPXORQ            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 ef /r ]          | AVX512                   |
| VRANGEPD          | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w1 50 /r ib ]    | AVX512VL,AVX512DQ        |
| VRANGEPD          | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 50 /r ib ]    | AVX512VL,AVX512DQ        |
| VRANGEPD          | zmmreg^mask^z,zmmreg*,zmmrm512^b64^sae,imm8 | [rvmi:fv: evex.nds.512.66.0f3a.w1 50 /r ib ]    | AVX512DQ                 |
| VRANGEPS          | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w0 50 /r ib ]    | AVX512VL,AVX512DQ        |
| VRANGEPS          | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w0 50 /r ib ]    | AVX512VL,AVX512DQ        |
| VRANGEPS          | zmmreg^mask^z,zmmreg*,zmmrm512^b32^sae,imm8 | [rvmi:fv: evex.nds.512.66.0f3a.w0 50 /r ib ]    | AVX512DQ                 |
| VRANGESD          | xmmreg^mask^z,xmmreg*,xmmrm64^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w1 51 /r ib ]   | AVX512DQ                 |
| VRANGESS          | xmmreg^mask^z,xmmreg*,xmmrm32^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w0 51 /r ib ]   | AVX512DQ                 |
| VRCP14PD          | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 4c /r ]             | AVX512VL,AVX512          |
| VRCP14PD          | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 4c /r ]             | AVX512VL,AVX512          |
| VRCP14PD          | zmmreg^mask^z,zmmrm512^b64                  | [rm:fv: evex.512.66.0f38.w1 4c /r ]             | AVX512                   |
| VRCP14PS          | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 4c /r ]             | AVX512VL,AVX512          |
| VRCP14PS          | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 4c /r ]             | AVX512VL,AVX512          |
| VRCP14PS          | zmmreg^mask^z,zmmrm512^b32                  | [rm:fv: evex.512.66.0f38.w0 4c /r ]             | AVX512                   |
| VRCP14SD          | xmmreg^mask^z,xmmreg*,xmmrm64               | [rvm:t1s: evex.nds.128.66.0f38.w1 4d /r ]       | AVX512                   |
| VRCP14SS          | xmmreg^mask^z,xmmreg*,xmmrm32               | [rvm:t1s: evex.nds.128.66.0f38.w0 4d /r ]       | AVX512                   |
| VRCP28PD          | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f38.w1 ca /r ]             | AVX512ER                 |
| VRCP28PS          | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.66.0f38.w0 ca /r ]             | AVX512ER                 |
| VRCP28SD          | xmmreg^mask^z,xmmreg*,xmmrm64^sae           | [rvm:t1s: evex.nds.128.66.0f38.w1 cb /r ]       | AVX512ER                 |
| VRCP28SS          | xmmreg^mask^z,xmmreg*,xmmrm32^sae           | [rvm:t1s: evex.nds.128.66.0f38.w0 cb /r ]       | AVX512ER                 |
| VREDUCEPD         | xmmreg^mask^z,xmmrm128^b64,imm8             | [rmi:fv: evex.128.66.0f3a.w1 56 /r ib ]         | AVX512VL,AVX512DQ        |
| VREDUCEPD         | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 56 /r ib ]         | AVX512VL,AVX512DQ        |
| VREDUCEPD         | zmmreg^mask^z,zmmrm512^b64^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w1 56 /r ib ]         | AVX512DQ                 |
| VREDUCEPS         | xmmreg^mask^z,xmmrm128^b32,imm8             | [rmi:fv: evex.128.66.0f3a.w0 56 /r ib ]         | AVX512VL,AVX512DQ        |
| VREDUCEPS         | ymmreg^mask^z,ymmrm256^b32,imm8             | [rmi:fv: evex.256.66.0f3a.w0 56 /r ib ]         | AVX512VL,AVX512DQ        |
| VREDUCEPS         | zmmreg^mask^z,zmmrm512^b32^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w0 56 /r ib ]         | AVX512DQ                 |
| VREDUCESD         | xmmreg^mask^z,xmmreg*,xmmrm64^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w1 57 /r ib ]   | AVX512DQ                 |
| VREDUCESS         | xmmreg^mask^z,xmmreg*,xmmrm32^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w0 57 /r ib ]   | AVX512DQ                 |
| VRNDSCALEPD       | xmmreg^mask^z,xmmrm128^b64,imm8             | [rmi:fv: evex.128.66.0f3a.w1 09 /r ib ]         | AVX512VL,AVX512          |
| VRNDSCALEPD       | ymmreg^mask^z,ymmrm256^b64,imm8             | [rmi:fv: evex.256.66.0f3a.w1 09 /r ib ]         | AVX512VL,AVX512          |
| VRNDSCALEPD       | zmmreg^mask^z,zmmrm512^b64^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w1 09 /r ib ]         | AVX512                   |
| VRNDSCALEPS       | xmmreg^mask^z,xmmrm128^b32,imm8             | [rmi:fv: evex.128.66.0f3a.w0 08 /r ib ]         | AVX512VL,AVX512          |
| VRNDSCALEPS       | ymmreg^mask^z,ymmrm256^b32,imm8             | [rmi:fv: evex.256.66.0f3a.w0 08 /r ib ]         | AVX512VL,AVX512          |
| VRNDSCALEPS       | zmmreg^mask^z,zmmrm512^b32^sae,imm8         | [rmi:fv: evex.512.66.0f3a.w0 08 /r ib ]         | AVX512                   |
| VRNDSCALESD       | xmmreg^mask^z,xmmreg*,xmmrm64^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w1 0b /r ib ]   | AVX512                   |
| VRNDSCALESS       | xmmreg^mask^z,xmmreg*,xmmrm32^sae,imm8      | [rvmi:t1s: evex.nds.128.66.0f3a.w0 0a /r ib ]   | AVX512                   |
| VRSQRT14PD        | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f38.w1 4e /r ]             | AVX512VL,AVX512          |
| VRSQRT14PD        | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f38.w1 4e /r ]             | AVX512VL,AVX512          |
| VRSQRT14PD        | zmmreg^mask^z,zmmrm512^b64                  | [rm:fv: evex.512.66.0f38.w1 4e /r ]             | AVX512                   |
| VRSQRT14PS        | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.66.0f38.w0 4e /r ]             | AVX512VL,AVX512          |
| VRSQRT14PS        | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.66.0f38.w0 4e /r ]             | AVX512VL,AVX512          |
| VRSQRT14PS        | zmmreg^mask^z,zmmrm512^b32                  | [rm:fv: evex.512.66.0f38.w0 4e /r ]             | AVX512                   |
| VRSQRT14SD        | xmmreg^mask^z,xmmreg*,xmmrm64               | [rvm:t1s: evex.nds.128.66.0f38.w1 4f /r ]       | AVX512                   |
| VRSQRT14SS        | xmmreg^mask^z,xmmreg*,xmmrm32               | [rvm:t1s: evex.nds.128.66.0f38.w0 4f /r ]       | AVX512                   |
| VRSQRT28PD        | zmmreg^mask^z,zmmrm512^b64^sae              | [rm:fv: evex.512.66.0f38.w1 cc /r ]             | AVX512ER                 |
| VRSQRT28PS        | zmmreg^mask^z,zmmrm512^b32^sae              | [rm:fv: evex.512.66.0f38.w0 cc /r ]             | AVX512ER                 |
| VRSQRT28SD        | xmmreg^mask^z,xmmreg*,xmmrm64^sae           | [rvm:t1s: evex.nds.128.66.0f38.w1 cd /r ]       | AVX512ER                 |
| VRSQRT28SS        | xmmreg^mask^z,xmmreg*,xmmrm32^sae           | [rvm:t1s: evex.nds.128.66.0f38.w0 cd /r ]       | AVX512ER                 |
| VSCALEFPD         | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f38.w1 2c /r ]        | AVX512VL,AVX512          |
| VSCALEFPD         | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f38.w1 2c /r ]        | AVX512VL,AVX512          |
| VSCALEFPD         | zmmreg^mask^z,zmmreg*,zmmrm512^b64^er       | [rvm:fv: evex.nds.512.66.0f38.w1 2c /r ]        | AVX512                   |
| VSCALEFPS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.66.0f38.w0 2c /r ]        | AVX512VL,AVX512          |
| VSCALEFPS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.66.0f38.w0 2c /r ]        | AVX512VL,AVX512          |
| VSCALEFPS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32^er       | [rvm:fv: evex.nds.512.66.0f38.w0 2c /r ]        | AVX512                   |
| VSCALEFSD         | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.66.0f38.w1 2d /r ]       | AVX512                   |
| VSCALEFSS         | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.66.0f38.w0 2d /r ]       | AVX512                   |
| VSCATTERDPD       | xmem64^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w1 a2 /r ]      | AVX512VL,AVX512          |
| VSCATTERDPD       | xmem64^mask,ymmreg                          | [mr:t1s: vsibx evex.256.66.0f38.w1 a2 /r ]      | AVX512VL,AVX512          |
| VSCATTERDPD       | ymem64^mask,zmmreg                          | [mr:t1s: vsiby evex.512.66.0f38.w1 a2 /r ]      | AVX512                   |
| VSCATTERDPS       | xmem32^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w0 a2 /r ]      | AVX512VL,AVX512          |
| VSCATTERDPS       | ymem32^mask,ymmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w0 a2 /r ]      | AVX512VL,AVX512          |
| VSCATTERDPS       | zmem32^mask,zmmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w0 a2 /r ]      | AVX512                   |
| VSCATTERPF0DPD    | ymem64^mask                                 | [m:t1s: vsiby evex.512.66.0f38.w1 c6 /5 ]       | AVX512PF                 |
| VSCATTERPF0DPS    | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c6 /5 ]       | AVX512PF                 |
| VSCATTERPF0QPD    | zmem64^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w1 c7 /5 ]       | AVX512PF                 |
| VSCATTERPF0QPS    | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c7 /5 ]       | AVX512PF                 |
| VSCATTERPF1DPD    | ymem64^mask                                 | [m:t1s: vsiby evex.512.66.0f38.w1 c6 /6 ]       | AVX512PF                 |
| VSCATTERPF1DPS    | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c6 /6 ]       | AVX512PF                 |
| VSCATTERPF1QPD    | zmem64^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w1 c7 /6 ]       | AVX512PF                 |
| VSCATTERPF1QPS    | zmem32^mask                                 | [m:t1s: vsibz evex.512.66.0f38.w0 c7 /6 ]       | AVX512PF                 |
| VSCATTERQPD       | xmem64^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w1 a3 /r ]      | AVX512VL,AVX512          |
| VSCATTERQPD       | ymem64^mask,ymmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w1 a3 /r ]      | AVX512VL,AVX512          |
| VSCATTERQPD       | zmem64^mask,zmmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w1 a3 /r ]      | AVX512                   |
| VSCATTERQPS       | xmem32^mask,xmmreg                          | [mr:t1s: vsibx evex.128.66.0f38.w0 a3 /r ]      | AVX512VL,AVX512          |
| VSCATTERQPS       | ymem32^mask,xmmreg                          | [mr:t1s: vsiby evex.256.66.0f38.w0 a3 /r ]      | AVX512VL,AVX512          |
| VSCATTERQPS       | zmem32^mask,ymmreg                          | [mr:t1s: vsibz evex.512.66.0f38.w0 a3 /r ]      | AVX512                   |
| VSHUFF32X4        | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w0 23 /r ib ]    | AVX512VL,AVX512          |
| VSHUFF32X4        | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w0 23 /r ib ]    | AVX512                   |
| VSHUFF64X2        | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 23 /r ib ]    | AVX512VL,AVX512          |
| VSHUFF64X2        | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w1 23 /r ib ]    | AVX512                   |
| VSHUFI32X4        | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w0 43 /r ib ]    | AVX512VL,AVX512          |
| VSHUFI32X4        | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w0 43 /r ib ]    | AVX512                   |
| VSHUFI64X2        | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 43 /r ib ]    | AVX512VL,AVX512          |
| VSHUFI64X2        | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w1 43 /r ib ]    | AVX512                   |
| VSHUFPD           | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f.w1 c6 /r ib ]      | AVX512VL,AVX512          |
| VSHUFPD           | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f.w1 c6 /r ib ]      | AVX512VL,AVX512          |
| VSHUFPD           | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f.w1 c6 /r ib ]      | AVX512                   |
| VSHUFPS           | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv: evex.nds.128.0f.w0 c6 /r ib ]         | AVX512VL,AVX512          |
| VSHUFPS           | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv: evex.nds.256.0f.w0 c6 /r ib ]         | AVX512VL,AVX512          |
| VSHUFPS           | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv: evex.nds.512.0f.w0 c6 /r ib ]         | AVX512                   |
| VSQRTPD           | xmmreg^mask^z,xmmrm128^b64                  | [rm:fv: evex.128.66.0f.w1 51 /r ]               | AVX512VL,AVX512          |
| VSQRTPD           | ymmreg^mask^z,ymmrm256^b64                  | [rm:fv: evex.256.66.0f.w1 51 /r ]               | AVX512VL,AVX512          |
| VSQRTPD           | zmmreg^mask^z,zmmrm512^b64^er               | [rm:fv: evex.512.66.0f.w1 51 /r ]               | AVX512                   |
| VSQRTPS           | xmmreg^mask^z,xmmrm128^b32                  | [rm:fv: evex.128.0f.w0 51 /r ]                  | AVX512VL,AVX512          |
| VSQRTPS           | ymmreg^mask^z,ymmrm256^b32                  | [rm:fv: evex.256.0f.w0 51 /r ]                  | AVX512VL,AVX512          |
| VSQRTPS           | zmmreg^mask^z,zmmrm512^b32^er               | [rm:fv: evex.512.0f.w0 51 /r ]                  | AVX512                   |
| VSQRTSD           | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.f2.0f.w1 51 /r ]         | AVX512                   |
| VSQRTSS           | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.f3.0f.w0 51 /r ]         | AVX512                   |
| VSUBPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 5c /r ]          | AVX512VL,AVX512          |
| VSUBPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 5c /r ]          | AVX512VL,AVX512          |
| VSUBPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64^er       | [rvm:fv: evex.nds.512.66.0f.w1 5c /r ]          | AVX512                   |
| VSUBPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 5c /r ]             | AVX512VL,AVX512          |
| VSUBPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 5c /r ]             | AVX512VL,AVX512          |
| VSUBPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32^er       | [rvm:fv: evex.nds.512.0f.w0 5c /r ]             | AVX512                   |
| VSUBSD            | xmmreg^mask^z,xmmreg*,xmmrm64^er            | [rvm:t1s: evex.nds.128.f2.0f.w1 5c /r ]         | AVX512                   |
| VSUBSS            | xmmreg^mask^z,xmmreg*,xmmrm32^er            | [rvm:t1s: evex.nds.128.f3.0f.w0 5c /r ]         | AVX512                   |
| VUCOMISD          | xmmreg,xmmrm64^sae                          | [rm:t1s: evex.128.66.0f.w1 2e /r ]              | AVX512                   |
| VUCOMISS          | xmmreg,xmmrm32^sae                          | [rm:t1s: evex.128.0f.w0 2e /r ]                 | AVX512                   |
| VUNPCKHPD         | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 15 /r ]          | AVX512VL,AVX512          |
| VUNPCKHPD         | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 15 /r ]          | AVX512VL,AVX512          |
| VUNPCKHPD         | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 15 /r ]          | AVX512                   |
| VUNPCKHPS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 15 /r ]             | AVX512VL,AVX512          |
| VUNPCKHPS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 15 /r ]             | AVX512VL,AVX512          |
| VUNPCKHPS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 15 /r ]             | AVX512                   |
| VUNPCKLPD         | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 14 /r ]          | AVX512VL,AVX512          |
| VUNPCKLPD         | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 14 /r ]          | AVX512VL,AVX512          |
| VUNPCKLPD         | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 14 /r ]          | AVX512                   |
| VUNPCKLPS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 14 /r ]             | AVX512VL,AVX512          |
| VUNPCKLPS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 14 /r ]             | AVX512VL,AVX512          |
| VUNPCKLPS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 14 /r ]             | AVX512                   |
| VXORPD            | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvm:fv: evex.nds.128.66.0f.w1 57 /r ]          | AVX512VL,AVX512DQ        |
| VXORPD            | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvm:fv: evex.nds.256.66.0f.w1 57 /r ]          | AVX512VL,AVX512DQ        |
| VXORPD            | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvm:fv: evex.nds.512.66.0f.w1 57 /r ]          | AVX512DQ                 |
| VXORPS            | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv: evex.nds.128.0f.w0 57 /r ]             | AVX512VL,AVX512DQ        |
| VXORPS            | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv: evex.nds.256.0f.w0 57 /r ]             | AVX512VL,AVX512DQ        |
| VXORPS            | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv: evex.nds.512.0f.w0 57 /r ]             | AVX512DQ                 |
| RDPKRU            | void                                        | [0f 01 ee]                                      | X64                      |
| WRPKRU            | void                                        | [0f 01 ef]                                      | X64                      |
| RDPID             | reg32                                       | [m: f3 0f c7 /7]                                | NOLONG                   |
| RDPID             | reg64                                       | [m: o64nw f3 0f c7 /7]                          | X64                      |
| RDPID             | reg32                                       | [m: f3 0f c7 /7]                                | X64,UNDOC                |
| CLFLUSHOPT        | mem                                         | [m: 66 0f ae /7]                                | FUTURE                   |
| CLWB              | mem                                         | [m:  66 0f ae /6]                               | FUTURE                   |
| CLZERO            | void                                        | [0f 01 fc]                                      | FUTURE,AMD               |
| CLZERO            | reg_ax                                      | [-: a16 0f 01 fc]                               | FUTURE,AMD,ND,NOLONG     |
| CLZERO            | reg_eax                                     | [-: a32 0f 01 fc]                               | FUTURE,AMD,ND            |
| CLZERO            | reg_rax                                     | [-: a64 0f 01 fc]                               | FUTURE,AMD,ND,X64        |
| PTWRITE           | rm32                                        | [m: np 0f ae /4]                                | FUTURE                   |
| PTWRITE           | rm64                                        | [m: o64 np 0f ae /4]                            | X64                      |
| CLDEMOTE          | mem                                         | [m: np 0f 1c /0]                                | FUTURE                   |
| MOVDIRI           | mem32,reg32                                 | [mr: np 0f 38 f9 /r]                            | FUTURE,SD                |
| MOVDIRI           | mem64,reg64                                 | [mr: o64 0f 38 f9 /r]                           | FUTURE,X64,SQ            |
| MOVDIR64B         | reg16,mem512                                | [rm: a16 66 0f 38 f8 /r]                        | FUTURE,NOLONG            |
| MOVDIR64B         | reg32,mem512                                | [rm: a32 66 0f 38 f8 /r]                        | FUTURE                   |
| MOVDIR64B         | reg64,mem512                                | [rm: a64 66 0f 38 f8 /r]                        | FUTURE,X64               |
| PCONFIG           | void                                        | [np 0f 01 c5]                                   | FUTURE                   |
| TPAUSE            | reg32                                       | [m: 66 0f ae /6]                                | FUTURE                   |
| TPAUSE            | reg32,reg_edx,reg_eax                       | [m--: 66 0f ae /6]                              | FUTURE,ND                |
| UMONITOR          | reg16                                       | [m: a16 f3 0f ae /6]                            | FUTURE,NOLONG            |
| UMONITOR          | reg32                                       | [m: a32 f3 0f ae /6]                            | FUTURE                   |
| UMONITOR          | reg64                                       | [m: a64 f3 0f ae /6]                            | FUTURE,X64               |
| UMWAIT            | reg32                                       | [m: f2 0f ae /6]                                | FUTURE                   |
| UMWAIT            | reg32,reg_edx,reg_eax                       | [m--: f2 0f ae /6]                              | FUTURE,ND                |
| WBNOINVD          | void                                        | [f3 0f 09]                                      | FUTURE                   |
| GF2P8AFFINEINVQB  | xmmreg,xmmrm128,imm8                        | [rmi:   66 0f 3a cf /r ib]                      | GFNI,SSE                 |
| VGF2P8AFFINEINVQB | xmmreg,xmmreg*,xmmrm128,imm8                | [rvmi:   vex.nds.128.66.0f3a.w1 cf /r ib]       | GFNI,AVX                 |
| VGF2P8AFFINEINVQB | ymmreg,ymmreg*,ymmrm256,imm8                | [rvmi:   vex.nds.256.66.0f3a.w1 cf /r ib]       | GFNI,AVX                 |
| VGF2P8AFFINEINVQB | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w1 cf /r ib]     | GFNI,AVX512VL            |
| VGF2P8AFFINEINVQB | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 cf /r ib]     | GFNI,AVX512VL            |
| VGF2P8AFFINEINVQB | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w1 cf /r ib]     | GFNI,AVX512              |
| GF2P8AFFINEQB     | xmmreg,xmmrm128,imm8                        | [rmi:   66 0f 3a ce /r ib]                      | GFNI,SSE                 |
| VGF2P8AFFINEQB    | xmmreg,xmmreg*,xmmrm128,imm8                | [rvmi:   vex.nds.128.66.0f3a.w1 ce /r ib]       | GFNI,AVX                 |
| VGF2P8AFFINEQB    | ymmreg,ymmreg*,ymmrm256,imm8                | [rvmi:   vex.nds.256.66.0f3a.w1 ce /r ib]       | GFNI,AVX                 |
| VGF2P8AFFINEQB    | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv: evex.nds.128.66.0f3a.w1 ce /r ib]     | GFNI,AVX512VL            |
| VGF2P8AFFINEQB    | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv: evex.nds.256.66.0f3a.w1 ce /r ib]     | GFNI,AVX512VL            |
| VGF2P8AFFINEQB    | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv: evex.nds.512.66.0f3a.w1 ce /r ib]     | GFNI,AVX512              |
| GF2P8MULB         | xmmreg,xmmrm128                             | [rm:   66 0f 38 cf /r]                          | GFNI,SSE                 |
| VGF2P8MULB        | xmmreg,xmmreg*,xmmrm128                     | [rvm:  vex.nds.128.66.0f38.w0 cf /r]            | GFNI,AVX                 |
| VGF2P8MULB        | ymmreg,ymmreg*,ymmrm256                     | [rvm:  vex.nds.256.66.0f38.w0 cf /r]            | GFNI,AVX                 |
| VGF2P8MULB        | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvm:fvm: evex.nds.128.66.0f38.w0 cf /r]        | GFNI,AVX512VL            |
| VGF2P8MULB        | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvm:fvm: evex.nds.256.66.0f38.w0 cf /r]        | GFNI,AVX512VL            |
| VGF2P8MULB        | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvm:fvm: evex.nds.512.66.0f38.w0 cf /r]        | GFNI,AVX512              |
| VPCOMPRESSB       | mem128^mask,xmmreg                          | [mr:t1s:   evex.128.66.0f38.w0 63 /r]           | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSB       | mem256^mask,ymmreg                          | [mr:t1s:   evex.256.66.0f38.w0 63 /r]           | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSB       | zmem512^mask,zmmreg                         | [mr:t1s:   evex.512.66.0f38.w0 63 /r]           | AVX512VBMI2              |
| VPCOMPRESSB       | xmmreg^mask^z,xmmreg                        | [mr:    evex.128.66.0f38.w0 63 /r]              | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSB       | ymmreg^mask^z,ymmreg                        | [mr:    evex.256.66.0f38.w0 63 /r]              | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSB       | zmmreg^mask^z,zmmreg                        | [mr:    evex.512.66.0f38.w0 63 /r]              | AVX512VBMI2              |
| VPCOMPRESSW       | mem128^mask,xmmreg                          | [mr:t1s:   evex.128.66.0f38.w1 63 /r]           | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSW       | mem256^mask,ymmreg                          | [mr:t1s:   evex.256.66.0f38.w1 63 /r]           | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSW       | zmem512^mask,zmmreg                         | [mr:t1s:   evex.512.66.0f38.w1 63 /r]           | AVX512VBMI2              |
| VPCOMPRESSW       | xmmreg^mask^z,xmmreg                        | [mr:    evex.128.66.0f38.w1 63 /r]              | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSW       | ymmreg^mask^z,ymmreg                        | [mr:    evex.256.66.0f38.w1 63 /r]              | AVX512VBMI2,AVX512VL     |
| VPCOMPRESSW       | zmmreg^mask^z,zmmreg                        | [mr:    evex.512.66.0f38.w1 63 /r]              | AVX512VBMI2              |
| VPEXPANDB         | mem128^mask,xmmreg                          | [mr:t1s:   evex.128.66.0f38.w0 62 /r]           | AVX512VBMI2,AVX512VL     |
| VPEXPANDB         | mem256^mask,ymmreg                          | [mr:t1s:   evex.256.66.0f38.w0 62 /r]           | AVX512VBMI2,AVX512VL     |
| VPEXPANDB         | zmem512^mask,zmmreg                         | [mr:t1s:   evex.512.66.0f38.w0 62 /r]           | AVX512VBMI2              |
| VPEXPANDB         | xmmreg^mask^z,xmmreg                        | [mr:    evex.128.66.0f38.w0 62 /r]              | AVX512VBMI2,AVX512VL     |
| VPEXPANDB         | ymmreg^mask^z,ymmreg                        | [mr:    evex.256.66.0f38.w0 62 /r]              | AVX512VBMI2,AVX512VL     |
| VPEXPANDB         | zmmreg^mask^z,zmmreg                        | [mr:    evex.512.66.0f38.w0 62 /r]              | AVX512VBMI2              |
| VPEXPANDW         | mem128^mask,xmmreg                          | [mr:t1s:   evex.128.66.0f38.w1 62 /r]           | AVX512VBMI2,AVX512VL     |
| VPEXPANDW         | mem256^mask,ymmreg                          | [mr:t1s:   evex.256.66.0f38.w1 62 /r]           | AVX512VBMI2,AVX512VL     |
| VPEXPANDW         | zmem512^mask,zmmreg                         | [mr:t1s:   evex.512.66.0f38.w1 62 /r]           | AVX512VBMI2              |
| VPEXPANDW         | xmmreg^mask^z,xmmreg                        | [mr:    evex.128.66.0f38.w1 62 /r]              | AVX512VBMI2,AVX512VL     |
| VPEXPANDW         | ymmreg^mask^z,ymmreg                        | [mr:    evex.256.66.0f38.w1 62 /r]              | AVX512VBMI2,AVX512VL     |
| VPEXPANDW         | zmmreg^mask^z,zmmreg                        | [mr:    evex.512.66.0f38.w1 62 /r]              | AVX512VBMI2              |
| VPSHLDW           | xmmreg^mask^z,xmmreg*,xmmrm128,imm8         | [rvmi:fvm: evex.nds.128.66.0f3a.w1 70 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDW           | ymmreg^mask^z,ymmreg*,ymmrm256,imm8         | [rvmi:fvm: evex.nds.256.66.0f3a.w1 70 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDW           | zmmreg^mask^z,zmmreg*,zmmrm512,imm8         | [rvmi:fvm: evex.nds.512.66.0f3a.w1 70 /r ib]    | AVX512VBMI2              |
| VPSHLDD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv:  evex.nds.128.66.0f3a.w0 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv:  evex.nds.256.66.0f3a.w0 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv:  evex.nds.512.66.0f3a.w0 71 /r ib]    | AVX512VBMI2              |
| VPSHLDQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv:  evex.nds.128.66.0f3a.w1 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv:  evex.nds.256.66.0f3a.w1 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv:  evex.nds.512.66.0f3a.w1 71 /r ib]    | AVX512VBMI2              |
| VPSHLDVW          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvmi:fvm: evex.dds.128.66.0f38.w1 70 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVW          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvmi:fvm: evex.dds.256.66.0f38.w1 70 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVW          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvmi:fvm: evex.dds.512.66.0f38.w1 70 /r ib]    | AVX512VBMI2              |
| VPSHLDVD          | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvmi:fv:  evex.dds.128.66.0f38.w0 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVD          | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvmi:fv:  evex.dds.256.66.0f38.w0 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVD          | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvmi:fv:  evex.dds.512.66.0f38.w0 71 /r ib]    | AVX512VBMI2              |
| VPSHLDVQ          | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvmi:fv:  evex.dds.128.66.0f38.w1 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVQ          | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvmi:fv:  evex.dds.256.66.0f38.w1 71 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHLDVQ          | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvmi:fv:  evex.dds.512.66.0f38.w1 71 /r ib]    | AVX512VBMI2              |
| VPSHRDW           | xmmreg^mask^z,xmmreg*,xmmrm128,imm8         | [rvmi:fvm: evex.nds.128.66.0f3a.w1 72 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDW           | ymmreg^mask^z,ymmreg*,ymmrm256,imm8         | [rvmi:fvm: evex.nds.256.66.0f3a.w1 72 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDW           | zmmreg^mask^z,zmmreg*,zmmrm512,imm8         | [rvmi:fvm: evex.nds.512.66.0f3a.w1 72 /r ib]    | AVX512VBMI2              |
| VPSHRDD           | xmmreg^mask^z,xmmreg*,xmmrm128^b32,imm8     | [rvmi:fv:  evex.nds.128.66.0f3a.w0 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDD           | ymmreg^mask^z,ymmreg*,ymmrm256^b32,imm8     | [rvmi:fv:  evex.nds.256.66.0f3a.w0 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDD           | zmmreg^mask^z,zmmreg*,zmmrm512^b32,imm8     | [rvmi:fv:  evex.nds.512.66.0f3a.w0 73 /r ib]    | AVX512VBMI2              |
| VPSHRDQ           | xmmreg^mask^z,xmmreg*,xmmrm128^b64,imm8     | [rvmi:fv:  evex.nds.128.66.0f3a.w1 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDQ           | ymmreg^mask^z,ymmreg*,ymmrm256^b64,imm8     | [rvmi:fv:  evex.nds.256.66.0f3a.w1 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDQ           | zmmreg^mask^z,zmmreg*,zmmrm512^b64,imm8     | [rvmi:fv:  evex.nds.512.66.0f3a.w1 73 /r ib]    | AVX512VBMI2              |
| VPSHRDVW          | xmmreg^mask^z,xmmreg*,xmmrm128              | [rvmi:fvm: evex.dds.128.66.0f38.w1 72 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVW          | ymmreg^mask^z,ymmreg*,ymmrm256              | [rvmi:fvm: evex.dds.256.66.0f38.w1 72 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVW          | zmmreg^mask^z,zmmreg*,zmmrm512              | [rvmi:fvm: evex.dds.512.66.0f38.w1 72 /r ib]    | AVX512VBMI2              |
| VPSHRDVD          | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvmi:fv:  evex.dds.128.66.0f38.w0 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVD          | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvmi:fv:  evex.dds.256.66.0f38.w0 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVD          | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvmi:fv:  evex.dds.512.66.0f38.w0 73 /r ib]    | AVX512VBMI2              |
| VPSHRDVQ          | xmmreg^mask^z,xmmreg*,xmmrm128^b64          | [rvmi:fv:  evex.dds.128.66.0f38.w1 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVQ          | ymmreg^mask^z,ymmreg*,ymmrm256^b64          | [rvmi:fv:  evex.dds.256.66.0f38.w1 73 /r ib]    | AVX512VBMI2,AVX512VL     |
| VPSHRDVQ          | zmmreg^mask^z,zmmreg*,zmmrm512^b64          | [rvmi:fv:  evex.dds.512.66.0f38.w1 73 /r ib]    | AVX512VBMI2              |
| VPDPBUSD          | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv:  evex.dds.128.66.0f38.w0 50 /r]        | AVX512VNNI,AVX512VL      |
| VPDPBUSD          | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv:  evex.dds.256.66.0f38.w0 50 /r]        | AVX512VNNI,AVX512VL      |
| VPDPBUSD          | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv:  evex.dds.512.66.0f38.w0 50 /r]        | AVX512VNNI               |
| VPDPBUSDS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv:  evex.dds.128.66.0f38.w0 51 /r]        | AVX512VNNI,AVX512VL      |
| VPDPBUSDS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv:  evex.dds.256.66.0f38.w0 51 /r]        | AVX512VNNI,AVX512VL      |
| VPDPBUSDS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv:  evex.dds.512.66.0f38.w0 51 /r]        | AVX512VNNI               |
| VPDPWSSD          | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv:  evex.dds.128.66.0f38.w0 52 /r]        | AVX512VNNI,AVX512VL      |
| VPDPWSSD          | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv:  evex.dds.256.66.0f38.w0 52 /r]        | AVX512VNNI,AVX512VL      |
| VPDPWSSD          | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv:  evex.dds.512.66.0f38.w0 52 /r]        | AVX512VNNI               |
| VPDPWSSDS         | xmmreg^mask^z,xmmreg*,xmmrm128^b32          | [rvm:fv:  evex.dds.128.66.0f38.w0 53 /r]        | AVX512VNNI,AVX512VL      |
| VPDPWSSDS         | ymmreg^mask^z,ymmreg*,ymmrm256^b32          | [rvm:fv:  evex.dds.256.66.0f38.w0 53 /r]        | AVX512VNNI,AVX512VL      |
| VPDPWSSDS         | zmmreg^mask^z,zmmreg*,zmmrm512^b32          | [rvm:fv:  evex.dds.512.66.0f38.w0 53 /r]        | AVX512VNNI               |
| VPOPCNTB          | xmmreg^mask^z,xmmrm128                      | [rm:fvm:  evex.128.66.0f38.w0 54 /r]            | AVX512BITALG,AVX512VL    |
| VPOPCNTB          | ymmreg^mask^z,ymmrm256                      | [rm:fvm:  evex.256.66.0f38.w0 54 /r]            | AVX512BITALG,AVX512VL    |
| VPOPCNTB          | zmmreg^mask^z,zmmrm512                      | [rm:fvm:  evex.512.66.0f38.w0 54 /r]            | AVX512BITALG             |
| VPOPCNTW          | xmmreg^mask^z,xmmrm128                      | [rm:fvm:  evex.128.66.0f38.w1 54 /r]            | AVX512BITALG,AVX512VL    |
| VPOPCNTW          | ymmreg^mask^z,ymmrm256                      | [rm:fvm:  evex.256.66.0f38.w1 54 /r]            | AVX512BITALG,AVX512VL    |
| VPOPCNTW          | zmmreg^mask^z,zmmrm512                      | [rm:fvm:  evex.512.66.0f38.w1 54 /r]            | AVX512BITALG             |
| VPOPCNTD          | xmmreg^mask^z,xmmrm128                      | [rm:fv:   evex.128.66.0f38.w0 55 /r]            | AVX512VPOPCNTDQ,AVX512VL |
| VPOPCNTD          | ymmreg^mask^z,ymmrm256                      | [rm:fv:   evex.256.66.0f38.w0 55 /r]            | AVX512VPOPCNTDQ,AVX512VL |
| VPOPCNTD          | zmmreg^mask^z,zmmrm512                      | [rm:fv:   evex.512.66.0f38.w0 55 /r]            | AVX512VPOPCNTDQ          |
| VPOPCNTQ          | xmmreg^mask^z,xmmrm128                      | [rm:fv:   evex.128.66.0f38.w1 55 /r]            | AVX512VPOPCNTDQ,AVX512VL |
| VPOPCNTQ          | ymmreg^mask^z,ymmrm256                      | [rm:fv:   evex.256.66.0f38.w1 55 /r]            | AVX512VPOPCNTDQ,AVX512VL |
| VPOPCNTQ          | zmmreg^mask^z,zmmrm512                      | [rm:fv:   evex.512.66.0f38.w1 55 /r]            | AVX512VPOPCNTDQ          |
| VPSHUFBITQMB      | kreg^mask,xmmreg,xmmrm128                   | [rvm:fvm: evex.nds.128.66.0f38.w0 8f /r]        | AVX512BITALG,AVX512VL    |
| VPSHUFBITQMB      | kreg^mask,ymmreg,ymmrm256                   | [rvm:fvm: evex.nds.256.66.0f38.w0 8f /r]        | AVX512BITALG,AVX512VL    |
| VPSHUFBITQMB      | kreg^mask,zmmreg,zmmrm512                   | [rvm:fvm: evex.nds.512.66.0f38.w0 8f /r]        | AVX512BITALG             |
| V4FMADDPS         | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.512.f2.0f38.w0 9a /r]        | AVX5124FMAPS,FUTURE,SO   |
| V4FNMADDPS        | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.512.f2.0f38.w0 aa /r]        | AVX5124FMAPS,FUTURE,SO   |
| V4FMADDSS         | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.lig.f2.0f38.w0 9b /r]        | AVX5124FMAPS,FUTURE,SO   |
| V4FNMADDSS        | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.lig.f2.0f38.w0 ab /r]        | AVX5124FMAPS,FUTURE,SO   |
| V4DPWSSDS         | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.512.f2.0f38.w0 53 /r]        | AVX5124VNNIW,FUTURE,SO   |
| V4DPWSSD          | zmmreg^mask^z, zmmreg^rs4,mem               | [rvm:m128:evex.dds.512.f2.0f38.w0 52 /r]        | AVX5124VNNIW,FUTURE,SO   |
| ENCLS             | void                                        | [     np 0f 01 cf]                              | SGX                      |
| ENCLU             | void                                        | [   np 0f 01 d7]                                | SGX                      |
| ENCLV             | void                                        | [  np 0f 01 c0]                                 | SGX                      |
